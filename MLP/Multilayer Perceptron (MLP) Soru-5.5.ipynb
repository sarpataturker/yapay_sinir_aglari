{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddacb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d46d43",
   "metadata": {},
   "source": [
    "Seed değerimi giriyorum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa622c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10783f5f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(190401015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e166a2",
   "metadata": {},
   "source": [
    "MLP için class oluşturuyoruz.\n",
    "\n",
    "Creating new class for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039fdb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, insize, hidden1, hidden2, outputsize):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layer1 = nn.Linear(insize, hidden1)\n",
    "        self.hidden_layer2 = nn.Linear(hidden1, hidden2)\n",
    "        self.output_layer = nn.Linear(hidden2, outputsize)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.relu(self.hidden_layer1(x))\n",
    "        output = self.relu(self.hidden_layer2(output))\n",
    "        output = self.sigmoid(self.output_layer(output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c90a50d",
   "metadata": {},
   "source": [
    "csv verimizi okuma \n",
    "\n",
    "reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6403f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"./cure_the_princess_train.csv\")\n",
    "val_data = pd.read_csv(\"./cure_the_princess_validation.csv\")\n",
    "test_data = pd.read_csv(\"./cure_the_princess_test.csv\")\n",
    "labels = training_data.columns.tolist()\n",
    "num_of_classes = len(labels)\n",
    "train_x = training_data.iloc[:, :-1].values\n",
    "train_y = training_data.iloc[:, -1].values\n",
    "val_x = val_data.iloc[:, :-1].values\n",
    "val_y = val_data.iloc[:, -1].values\n",
    "test_x = test_data.iloc[:, :-1].values\n",
    "test_y = test_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2639f",
   "metadata": {},
   "source": [
    "CustomData adında class oluşturup okunan verilerimizi işleme\n",
    "\n",
    "Creating new class called CustomData for using our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7049747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomData(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_data = CustomData(train_x, train_y)\n",
    "validation_data = CustomData(val_x, val_y)\n",
    "test_data = CustomData(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dadfee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002786\n",
    "epochnum = 2000\n",
    "bsize = 16\n",
    "insize = 13\n",
    "hidden1 = 100\n",
    "hidden2 = 50\n",
    "outsize = 1\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d40e9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(insize, hidden1, hidden2, outsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81d20af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss fonksiyonunu belirlemek / Determining loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer'ı belirlemek / Determining optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62cab5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=bsize, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validation_data, batch_size=bsize, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=bsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db714c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "valid_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b001247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.734405 \tValidation Loss: 0.696810\n",
      "Epoch: 2 \tTraining Loss: 0.702557 \tValidation Loss: 0.667388\n",
      "Epoch: 3 \tTraining Loss: 0.676456 \tValidation Loss: 0.645193\n",
      "Epoch: 4 \tTraining Loss: 0.655148 \tValidation Loss: 0.620331\n",
      "Epoch: 5 \tTraining Loss: 0.633830 \tValidation Loss: 0.599972\n",
      "Epoch: 6 \tTraining Loss: 0.618530 \tValidation Loss: 0.581816\n",
      "Epoch: 7 \tTraining Loss: 0.602851 \tValidation Loss: 0.566221\n",
      "Epoch: 8 \tTraining Loss: 0.590376 \tValidation Loss: 0.553089\n",
      "Epoch: 9 \tTraining Loss: 0.579019 \tValidation Loss: 0.540538\n",
      "Epoch: 10 \tTraining Loss: 0.567324 \tValidation Loss: 0.528441\n",
      "Epoch: 11 \tTraining Loss: 0.558875 \tValidation Loss: 0.519926\n",
      "Epoch: 12 \tTraining Loss: 0.549942 \tValidation Loss: 0.508993\n",
      "Epoch: 13 \tTraining Loss: 0.540281 \tValidation Loss: 0.498593\n",
      "Epoch: 14 \tTraining Loss: 0.533203 \tValidation Loss: 0.494444\n",
      "Epoch: 15 \tTraining Loss: 0.522945 \tValidation Loss: 0.482640\n",
      "Epoch: 16 \tTraining Loss: 0.518159 \tValidation Loss: 0.475905\n",
      "Epoch: 17 \tTraining Loss: 0.511013 \tValidation Loss: 0.466277\n",
      "Epoch: 18 \tTraining Loss: 0.501392 \tValidation Loss: 0.456939\n",
      "Epoch: 19 \tTraining Loss: 0.490953 \tValidation Loss: 0.449311\n",
      "Epoch: 20 \tTraining Loss: 0.486685 \tValidation Loss: 0.442367\n",
      "Epoch: 21 \tTraining Loss: 0.481339 \tValidation Loss: 0.435976\n",
      "Epoch: 22 \tTraining Loss: 0.471866 \tValidation Loss: 0.429240\n",
      "Epoch: 23 \tTraining Loss: 0.463337 \tValidation Loss: 0.425408\n",
      "Epoch: 24 \tTraining Loss: 0.460108 \tValidation Loss: 0.419107\n",
      "Epoch: 25 \tTraining Loss: 0.453815 \tValidation Loss: 0.411192\n",
      "Epoch: 26 \tTraining Loss: 0.447572 \tValidation Loss: 0.406102\n",
      "Epoch: 27 \tTraining Loss: 0.446382 \tValidation Loss: 0.401001\n",
      "Epoch: 28 \tTraining Loss: 0.439928 \tValidation Loss: 0.394639\n",
      "Epoch: 29 \tTraining Loss: 0.437235 \tValidation Loss: 0.391373\n",
      "Epoch: 30 \tTraining Loss: 0.427944 \tValidation Loss: 0.383911\n",
      "Epoch: 31 \tTraining Loss: 0.424768 \tValidation Loss: 0.379011\n",
      "Epoch: 32 \tTraining Loss: 0.423262 \tValidation Loss: 0.374925\n",
      "Epoch: 33 \tTraining Loss: 0.414511 \tValidation Loss: 0.369771\n",
      "Epoch: 34 \tTraining Loss: 0.407499 \tValidation Loss: 0.364739\n",
      "Epoch: 35 \tTraining Loss: 0.406163 \tValidation Loss: 0.363464\n",
      "Epoch: 36 \tTraining Loss: 0.400485 \tValidation Loss: 0.355629\n",
      "Epoch: 37 \tTraining Loss: 0.397368 \tValidation Loss: 0.351979\n",
      "Epoch: 38 \tTraining Loss: 0.398191 \tValidation Loss: 0.347535\n",
      "Epoch: 39 \tTraining Loss: 0.391390 \tValidation Loss: 0.345128\n",
      "Epoch: 40 \tTraining Loss: 0.387155 \tValidation Loss: 0.343472\n",
      "Epoch: 41 \tTraining Loss: 0.383564 \tValidation Loss: 0.336251\n",
      "Epoch: 42 \tTraining Loss: 0.376583 \tValidation Loss: 0.332040\n",
      "Epoch: 43 \tTraining Loss: 0.370319 \tValidation Loss: 0.330263\n",
      "Epoch: 44 \tTraining Loss: 0.369006 \tValidation Loss: 0.325150\n",
      "Epoch: 45 \tTraining Loss: 0.366202 \tValidation Loss: 0.321773\n",
      "Epoch: 46 \tTraining Loss: 0.361168 \tValidation Loss: 0.318923\n",
      "Epoch: 47 \tTraining Loss: 0.360057 \tValidation Loss: 0.315477\n",
      "Epoch: 48 \tTraining Loss: 0.357131 \tValidation Loss: 0.314814\n",
      "Epoch: 49 \tTraining Loss: 0.352626 \tValidation Loss: 0.309075\n",
      "Epoch: 50 \tTraining Loss: 0.352677 \tValidation Loss: 0.306900\n",
      "Epoch: 51 \tTraining Loss: 0.345883 \tValidation Loss: 0.304017\n",
      "Epoch: 52 \tTraining Loss: 0.342700 \tValidation Loss: 0.300991\n",
      "Epoch: 53 \tTraining Loss: 0.341163 \tValidation Loss: 0.298246\n",
      "Epoch: 54 \tTraining Loss: 0.336189 \tValidation Loss: 0.296015\n",
      "Epoch: 55 \tTraining Loss: 0.336801 \tValidation Loss: 0.293442\n",
      "Epoch: 56 \tTraining Loss: 0.334444 \tValidation Loss: 0.293030\n",
      "Epoch: 57 \tTraining Loss: 0.329908 \tValidation Loss: 0.289194\n",
      "Epoch: 58 \tTraining Loss: 0.328337 \tValidation Loss: 0.285525\n",
      "Epoch: 59 \tTraining Loss: 0.325554 \tValidation Loss: 0.285078\n",
      "Epoch: 60 \tTraining Loss: 0.322696 \tValidation Loss: 0.281229\n",
      "Epoch: 61 \tTraining Loss: 0.324786 \tValidation Loss: 0.281551\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 62 \tTraining Loss: 0.319631 \tValidation Loss: 0.279760\n",
      "Epoch: 63 \tTraining Loss: 0.315521 \tValidation Loss: 0.274880\n",
      "Epoch: 64 \tTraining Loss: 0.313378 \tValidation Loss: 0.279925\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 65 \tTraining Loss: 0.313865 \tValidation Loss: 0.272024\n",
      "Epoch: 66 \tTraining Loss: 0.311188 \tValidation Loss: 0.270923\n",
      "Epoch: 67 \tTraining Loss: 0.306910 \tValidation Loss: 0.268821\n",
      "Epoch: 68 \tTraining Loss: 0.307583 \tValidation Loss: 0.266201\n",
      "Epoch: 69 \tTraining Loss: 0.309172 \tValidation Loss: 0.265884\n",
      "Epoch: 70 \tTraining Loss: 0.302758 \tValidation Loss: 0.266093\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 71 \tTraining Loss: 0.298578 \tValidation Loss: 0.261530\n",
      "Epoch: 72 \tTraining Loss: 0.298283 \tValidation Loss: 0.258603\n",
      "Epoch: 73 \tTraining Loss: 0.294188 \tValidation Loss: 0.258363\n",
      "Epoch: 74 \tTraining Loss: 0.297814 \tValidation Loss: 0.256510\n",
      "Epoch: 75 \tTraining Loss: 0.292100 \tValidation Loss: 0.254442\n",
      "Epoch: 76 \tTraining Loss: 0.290209 \tValidation Loss: 0.252927\n",
      "Epoch: 77 \tTraining Loss: 0.289987 \tValidation Loss: 0.254036\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 78 \tTraining Loss: 0.287223 \tValidation Loss: 0.251915\n",
      "Epoch: 79 \tTraining Loss: 0.282938 \tValidation Loss: 0.250005\n",
      "Epoch: 80 \tTraining Loss: 0.283236 \tValidation Loss: 0.248124\n",
      "Epoch: 81 \tTraining Loss: 0.283268 \tValidation Loss: 0.247290\n",
      "Epoch: 82 \tTraining Loss: 0.279757 \tValidation Loss: 0.245349\n",
      "Epoch: 83 \tTraining Loss: 0.280809 \tValidation Loss: 0.244467\n",
      "Epoch: 84 \tTraining Loss: 0.278371 \tValidation Loss: 0.243432\n",
      "Epoch: 85 \tTraining Loss: 0.276306 \tValidation Loss: 0.241948\n",
      "Epoch: 86 \tTraining Loss: 0.276233 \tValidation Loss: 0.240513\n",
      "Epoch: 87 \tTraining Loss: 0.273528 \tValidation Loss: 0.239291\n",
      "Epoch: 88 \tTraining Loss: 0.276048 \tValidation Loss: 0.240077\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 89 \tTraining Loss: 0.272035 \tValidation Loss: 0.238695\n",
      "Epoch: 90 \tTraining Loss: 0.268244 \tValidation Loss: 0.236576\n",
      "Epoch: 91 \tTraining Loss: 0.268965 \tValidation Loss: 0.237810\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 92 \tTraining Loss: 0.267042 \tValidation Loss: 0.235191\n",
      "Epoch: 93 \tTraining Loss: 0.263980 \tValidation Loss: 0.234030\n",
      "Epoch: 94 \tTraining Loss: 0.266316 \tValidation Loss: 0.232865\n",
      "Epoch: 95 \tTraining Loss: 0.264075 \tValidation Loss: 0.232240\n",
      "Epoch: 96 \tTraining Loss: 0.260964 \tValidation Loss: 0.231199\n",
      "Epoch: 97 \tTraining Loss: 0.263746 \tValidation Loss: 0.230111\n",
      "Epoch: 98 \tTraining Loss: 0.260260 \tValidation Loss: 0.229524\n",
      "Epoch: 99 \tTraining Loss: 0.258415 \tValidation Loss: 0.228742\n",
      "Epoch: 100 \tTraining Loss: 0.257583 \tValidation Loss: 0.227757\n",
      "Epoch: 101 \tTraining Loss: 0.256014 \tValidation Loss: 0.226808\n",
      "Epoch: 102 \tTraining Loss: 0.253554 \tValidation Loss: 0.226702\n",
      "Epoch: 103 \tTraining Loss: 0.254054 \tValidation Loss: 0.225440\n",
      "Epoch: 104 \tTraining Loss: 0.254435 \tValidation Loss: 0.224367\n",
      "Epoch: 105 \tTraining Loss: 0.251411 \tValidation Loss: 0.223611\n",
      "Epoch: 106 \tTraining Loss: 0.250861 \tValidation Loss: 0.223611\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 107 \tTraining Loss: 0.249561 \tValidation Loss: 0.222181\n",
      "Epoch: 108 \tTraining Loss: 0.249396 \tValidation Loss: 0.222704\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 109 \tTraining Loss: 0.251071 \tValidation Loss: 0.221095\n",
      "Epoch: 110 \tTraining Loss: 0.246687 \tValidation Loss: 0.224382\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 111 \tTraining Loss: 0.246806 \tValidation Loss: 0.219588\n",
      "Epoch: 112 \tTraining Loss: 0.245374 \tValidation Loss: 0.219056\n",
      "Epoch: 113 \tTraining Loss: 0.246315 \tValidation Loss: 0.219002\n",
      "Epoch: 114 \tTraining Loss: 0.243934 \tValidation Loss: 0.218847\n",
      "Epoch: 115 \tTraining Loss: 0.242477 \tValidation Loss: 0.216894\n",
      "Epoch: 116 \tTraining Loss: 0.241233 \tValidation Loss: 0.217207\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 117 \tTraining Loss: 0.241410 \tValidation Loss: 0.217324\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 118 \tTraining Loss: 0.243933 \tValidation Loss: 0.220142\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 119 \tTraining Loss: 0.240017 \tValidation Loss: 0.215511\n",
      "Epoch: 120 \tTraining Loss: 0.240595 \tValidation Loss: 0.214298\n",
      "Epoch: 121 \tTraining Loss: 0.239719 \tValidation Loss: 0.213612\n",
      "Epoch: 122 \tTraining Loss: 0.239235 \tValidation Loss: 0.214633\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 123 \tTraining Loss: 0.238384 \tValidation Loss: 0.213902\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 124 \tTraining Loss: 0.237087 \tValidation Loss: 0.212243\n",
      "Epoch: 125 \tTraining Loss: 0.234920 \tValidation Loss: 0.212954\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 126 \tTraining Loss: 0.236591 \tValidation Loss: 0.211663\n",
      "Epoch: 127 \tTraining Loss: 0.232714 \tValidation Loss: 0.210479\n",
      "Epoch: 128 \tTraining Loss: 0.233675 \tValidation Loss: 0.209854\n",
      "Epoch: 129 \tTraining Loss: 0.233529 \tValidation Loss: 0.209749\n",
      "Epoch: 130 \tTraining Loss: 0.231707 \tValidation Loss: 0.209767\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 131 \tTraining Loss: 0.235098 \tValidation Loss: 0.214113\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 132 \tTraining Loss: 0.230613 \tValidation Loss: 0.208010\n",
      "Epoch: 133 \tTraining Loss: 0.231359 \tValidation Loss: 0.208005\n",
      "Epoch: 134 \tTraining Loss: 0.229726 \tValidation Loss: 0.206826\n",
      "Epoch: 135 \tTraining Loss: 0.228268 \tValidation Loss: 0.209915\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 136 \tTraining Loss: 0.229627 \tValidation Loss: 0.208142\n",
      "Earlystopping Patience Counter: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137 \tTraining Loss: 0.225936 \tValidation Loss: 0.205483\n",
      "Epoch: 138 \tTraining Loss: 0.226190 \tValidation Loss: 0.205512\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 139 \tTraining Loss: 0.225730 \tValidation Loss: 0.204768\n",
      "Epoch: 140 \tTraining Loss: 0.223528 \tValidation Loss: 0.205692\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 141 \tTraining Loss: 0.223382 \tValidation Loss: 0.204248\n",
      "Epoch: 142 \tTraining Loss: 0.222639 \tValidation Loss: 0.204214\n",
      "Epoch: 143 \tTraining Loss: 0.224982 \tValidation Loss: 0.206059\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 144 \tTraining Loss: 0.221930 \tValidation Loss: 0.203008\n",
      "Epoch: 145 \tTraining Loss: 0.222546 \tValidation Loss: 0.203668\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 146 \tTraining Loss: 0.219968 \tValidation Loss: 0.202042\n",
      "Epoch: 147 \tTraining Loss: 0.220073 \tValidation Loss: 0.201804\n",
      "Epoch: 148 \tTraining Loss: 0.222830 \tValidation Loss: 0.201762\n",
      "Epoch: 149 \tTraining Loss: 0.218872 \tValidation Loss: 0.201390\n",
      "Epoch: 150 \tTraining Loss: 0.221509 \tValidation Loss: 0.201158\n",
      "Epoch: 151 \tTraining Loss: 0.217628 \tValidation Loss: 0.200964\n",
      "Epoch: 152 \tTraining Loss: 0.217647 \tValidation Loss: 0.200505\n",
      "Epoch: 153 \tTraining Loss: 0.218387 \tValidation Loss: 0.200821\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 154 \tTraining Loss: 0.215306 \tValidation Loss: 0.199572\n",
      "Epoch: 155 \tTraining Loss: 0.217147 \tValidation Loss: 0.199409\n",
      "Epoch: 156 \tTraining Loss: 0.217063 \tValidation Loss: 0.199254\n",
      "Epoch: 157 \tTraining Loss: 0.215692 \tValidation Loss: 0.199366\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 158 \tTraining Loss: 0.213435 \tValidation Loss: 0.201569\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 159 \tTraining Loss: 0.214017 \tValidation Loss: 0.199216\n",
      "Epoch: 160 \tTraining Loss: 0.218091 \tValidation Loss: 0.202017\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 161 \tTraining Loss: 0.214015 \tValidation Loss: 0.197990\n",
      "Epoch: 162 \tTraining Loss: 0.211103 \tValidation Loss: 0.197998\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 163 \tTraining Loss: 0.209921 \tValidation Loss: 0.197010\n",
      "Epoch: 164 \tTraining Loss: 0.208876 \tValidation Loss: 0.199517\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 165 \tTraining Loss: 0.220645 \tValidation Loss: 0.197484\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 166 \tTraining Loss: 0.207912 \tValidation Loss: 0.196238\n",
      "Epoch: 167 \tTraining Loss: 0.208966 \tValidation Loss: 0.196023\n",
      "Epoch: 168 \tTraining Loss: 0.208694 \tValidation Loss: 0.196098\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 169 \tTraining Loss: 0.208724 \tValidation Loss: 0.196269\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 170 \tTraining Loss: 0.207307 \tValidation Loss: 0.195669\n",
      "Epoch: 171 \tTraining Loss: 0.206616 \tValidation Loss: 0.197849\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 172 \tTraining Loss: 0.206168 \tValidation Loss: 0.194435\n",
      "Epoch: 173 \tTraining Loss: 0.205746 \tValidation Loss: 0.195775\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 174 \tTraining Loss: 0.206176 \tValidation Loss: 0.194532\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 175 \tTraining Loss: 0.204011 \tValidation Loss: 0.194877\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 176 \tTraining Loss: 0.204235 \tValidation Loss: 0.193413\n",
      "Epoch: 177 \tTraining Loss: 0.203960 \tValidation Loss: 0.193427\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 178 \tTraining Loss: 0.205922 \tValidation Loss: 0.193072\n",
      "Epoch: 179 \tTraining Loss: 0.204370 \tValidation Loss: 0.192780\n",
      "Epoch: 180 \tTraining Loss: 0.202567 \tValidation Loss: 0.192334\n",
      "Epoch: 181 \tTraining Loss: 0.201517 \tValidation Loss: 0.191638\n",
      "Epoch: 182 \tTraining Loss: 0.202188 \tValidation Loss: 0.192292\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 183 \tTraining Loss: 0.201548 \tValidation Loss: 0.191092\n",
      "Epoch: 184 \tTraining Loss: 0.200284 \tValidation Loss: 0.191000\n",
      "Epoch: 185 \tTraining Loss: 0.198765 \tValidation Loss: 0.190774\n",
      "Epoch: 186 \tTraining Loss: 0.198574 \tValidation Loss: 0.190466\n",
      "Epoch: 187 \tTraining Loss: 0.198350 \tValidation Loss: 0.190204\n",
      "Epoch: 188 \tTraining Loss: 0.198831 \tValidation Loss: 0.193172\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 189 \tTraining Loss: 0.199944 \tValidation Loss: 0.189895\n",
      "Epoch: 190 \tTraining Loss: 0.197913 \tValidation Loss: 0.189790\n",
      "Epoch: 191 \tTraining Loss: 0.196223 \tValidation Loss: 0.189093\n",
      "Epoch: 192 \tTraining Loss: 0.196789 \tValidation Loss: 0.188860\n",
      "Epoch: 193 \tTraining Loss: 0.197425 \tValidation Loss: 0.188772\n",
      "Epoch: 194 \tTraining Loss: 0.195595 \tValidation Loss: 0.189986\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 195 \tTraining Loss: 0.194488 \tValidation Loss: 0.188182\n",
      "Epoch: 196 \tTraining Loss: 0.194597 \tValidation Loss: 0.187924\n",
      "Epoch: 197 \tTraining Loss: 0.193525 \tValidation Loss: 0.188930\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 198 \tTraining Loss: 0.193892 \tValidation Loss: 0.187224\n",
      "Epoch: 199 \tTraining Loss: 0.192641 \tValidation Loss: 0.187885\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 200 \tTraining Loss: 0.192446 \tValidation Loss: 0.187158\n",
      "Epoch: 201 \tTraining Loss: 0.192724 \tValidation Loss: 0.187397\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 202 \tTraining Loss: 0.191536 \tValidation Loss: 0.187041\n",
      "Epoch: 203 \tTraining Loss: 0.194841 \tValidation Loss: 0.187433\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 204 \tTraining Loss: 0.192127 \tValidation Loss: 0.185897\n",
      "Epoch: 205 \tTraining Loss: 0.191202 \tValidation Loss: 0.185991\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 206 \tTraining Loss: 0.191075 \tValidation Loss: 0.185735\n",
      "Epoch: 207 \tTraining Loss: 0.193060 \tValidation Loss: 0.185995\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 208 \tTraining Loss: 0.189263 \tValidation Loss: 0.186665\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 209 \tTraining Loss: 0.188556 \tValidation Loss: 0.184904\n",
      "Epoch: 210 \tTraining Loss: 0.189487 \tValidation Loss: 0.186329\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 211 \tTraining Loss: 0.187900 \tValidation Loss: 0.190002\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 212 \tTraining Loss: 0.187748 \tValidation Loss: 0.184474\n",
      "Epoch: 213 \tTraining Loss: 0.186815 \tValidation Loss: 0.186567\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 214 \tTraining Loss: 0.186597 \tValidation Loss: 0.183971\n",
      "Epoch: 215 \tTraining Loss: 0.187096 \tValidation Loss: 0.183840\n",
      "Epoch: 216 \tTraining Loss: 0.186126 \tValidation Loss: 0.185484\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 217 \tTraining Loss: 0.185321 \tValidation Loss: 0.183392\n",
      "Epoch: 218 \tTraining Loss: 0.184958 \tValidation Loss: 0.183732\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 219 \tTraining Loss: 0.191853 \tValidation Loss: 0.183557\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 220 \tTraining Loss: 0.184655 \tValidation Loss: 0.182581\n",
      "Epoch: 221 \tTraining Loss: 0.184472 \tValidation Loss: 0.182205\n",
      "Epoch: 222 \tTraining Loss: 0.184980 \tValidation Loss: 0.181852\n",
      "Epoch: 223 \tTraining Loss: 0.185250 \tValidation Loss: 0.182776\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 224 \tTraining Loss: 0.183495 \tValidation Loss: 0.181986\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 225 \tTraining Loss: 0.183097 \tValidation Loss: 0.181864\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 226 \tTraining Loss: 0.183624 \tValidation Loss: 0.181207\n",
      "Epoch: 227 \tTraining Loss: 0.181932 \tValidation Loss: 0.182281\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 228 \tTraining Loss: 0.181467 \tValidation Loss: 0.182541\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 229 \tTraining Loss: 0.181029 \tValidation Loss: 0.182907\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 230 \tTraining Loss: 0.179913 \tValidation Loss: 0.183435\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 231 \tTraining Loss: 0.182483 \tValidation Loss: 0.181962\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 232 \tTraining Loss: 0.179931 \tValidation Loss: 0.180254\n",
      "Epoch: 233 \tTraining Loss: 0.178999 \tValidation Loss: 0.181178\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 234 \tTraining Loss: 0.178815 \tValidation Loss: 0.180820\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 235 \tTraining Loss: 0.179079 \tValidation Loss: 0.180315\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 236 \tTraining Loss: 0.178935 \tValidation Loss: 0.180248\n",
      "Epoch: 237 \tTraining Loss: 0.177217 \tValidation Loss: 0.180211\n",
      "Epoch: 238 \tTraining Loss: 0.179878 \tValidation Loss: 0.179699\n",
      "Epoch: 239 \tTraining Loss: 0.180223 \tValidation Loss: 0.178904\n",
      "Epoch: 240 \tTraining Loss: 0.176783 \tValidation Loss: 0.178975\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 241 \tTraining Loss: 0.176903 \tValidation Loss: 0.179082\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 242 \tTraining Loss: 0.176394 \tValidation Loss: 0.178448\n",
      "Epoch: 243 \tTraining Loss: 0.178217 \tValidation Loss: 0.178794\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 244 \tTraining Loss: 0.177760 \tValidation Loss: 0.178014\n",
      "Epoch: 245 \tTraining Loss: 0.174768 \tValidation Loss: 0.180307\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 246 \tTraining Loss: 0.174781 \tValidation Loss: 0.177507\n",
      "Epoch: 247 \tTraining Loss: 0.176306 \tValidation Loss: 0.177302\n",
      "Epoch: 248 \tTraining Loss: 0.175114 \tValidation Loss: 0.179060\n",
      "Earlystopping Patience Counter: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 249 \tTraining Loss: 0.175223 \tValidation Loss: 0.177922\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 250 \tTraining Loss: 0.173446 \tValidation Loss: 0.177517\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 251 \tTraining Loss: 0.173290 \tValidation Loss: 0.177304\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 252 \tTraining Loss: 0.174544 \tValidation Loss: 0.179541\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 253 \tTraining Loss: 0.172072 \tValidation Loss: 0.178568\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 254 \tTraining Loss: 0.172465 \tValidation Loss: 0.177240\n",
      "Epoch: 255 \tTraining Loss: 0.177229 \tValidation Loss: 0.179295\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 256 \tTraining Loss: 0.172132 \tValidation Loss: 0.176920\n",
      "Epoch: 257 \tTraining Loss: 0.175535 \tValidation Loss: 0.182231\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 258 \tTraining Loss: 0.172126 \tValidation Loss: 0.176201\n",
      "Epoch: 259 \tTraining Loss: 0.177987 \tValidation Loss: 0.177847\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 260 \tTraining Loss: 0.169545 \tValidation Loss: 0.181226\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 261 \tTraining Loss: 0.169568 \tValidation Loss: 0.178625\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 262 \tTraining Loss: 0.169733 \tValidation Loss: 0.175627\n",
      "Epoch: 263 \tTraining Loss: 0.169472 \tValidation Loss: 0.175263\n",
      "Epoch: 264 \tTraining Loss: 0.170302 \tValidation Loss: 0.174940\n",
      "Epoch: 265 \tTraining Loss: 0.171893 \tValidation Loss: 0.175218\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 266 \tTraining Loss: 0.169252 \tValidation Loss: 0.176708\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 267 \tTraining Loss: 0.168321 \tValidation Loss: 0.174288\n",
      "Epoch: 268 \tTraining Loss: 0.167782 \tValidation Loss: 0.175515\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 269 \tTraining Loss: 0.180262 \tValidation Loss: 0.178997\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 270 \tTraining Loss: 0.168052 \tValidation Loss: 0.174401\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 271 \tTraining Loss: 0.166477 \tValidation Loss: 0.174625\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 272 \tTraining Loss: 0.167976 \tValidation Loss: 0.176205\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 273 \tTraining Loss: 0.169521 \tValidation Loss: 0.173783\n",
      "Epoch: 274 \tTraining Loss: 0.168692 \tValidation Loss: 0.175514\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 275 \tTraining Loss: 0.166076 \tValidation Loss: 0.173890\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 276 \tTraining Loss: 0.164810 \tValidation Loss: 0.174208\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 277 \tTraining Loss: 0.165985 \tValidation Loss: 0.173611\n",
      "Epoch: 278 \tTraining Loss: 0.165924 \tValidation Loss: 0.174196\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 279 \tTraining Loss: 0.164438 \tValidation Loss: 0.173463\n",
      "Epoch: 280 \tTraining Loss: 0.164772 \tValidation Loss: 0.173360\n",
      "Epoch: 281 \tTraining Loss: 0.169082 \tValidation Loss: 0.172456\n",
      "Epoch: 282 \tTraining Loss: 0.163509 \tValidation Loss: 0.172493\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 283 \tTraining Loss: 0.164041 \tValidation Loss: 0.172603\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 284 \tTraining Loss: 0.163133 \tValidation Loss: 0.172567\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 285 \tTraining Loss: 0.164610 \tValidation Loss: 0.172643\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 286 \tTraining Loss: 0.166152 \tValidation Loss: 0.172292\n",
      "Epoch: 287 \tTraining Loss: 0.164114 \tValidation Loss: 0.172916\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 288 \tTraining Loss: 0.162237 \tValidation Loss: 0.172229\n",
      "Epoch: 289 \tTraining Loss: 0.163151 \tValidation Loss: 0.172915\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 290 \tTraining Loss: 0.163173 \tValidation Loss: 0.171420\n",
      "Epoch: 291 \tTraining Loss: 0.161580 \tValidation Loss: 0.170858\n",
      "Epoch: 292 \tTraining Loss: 0.162106 \tValidation Loss: 0.170486\n",
      "Epoch: 293 \tTraining Loss: 0.160854 \tValidation Loss: 0.170812\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 294 \tTraining Loss: 0.159913 \tValidation Loss: 0.172670\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 295 \tTraining Loss: 0.160388 \tValidation Loss: 0.172724\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 296 \tTraining Loss: 0.160318 \tValidation Loss: 0.170193\n",
      "Epoch: 297 \tTraining Loss: 0.159635 \tValidation Loss: 0.172293\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 298 \tTraining Loss: 0.159567 \tValidation Loss: 0.170543\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 299 \tTraining Loss: 0.158704 \tValidation Loss: 0.170842\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 300 \tTraining Loss: 0.161732 \tValidation Loss: 0.171435\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 301 \tTraining Loss: 0.158654 \tValidation Loss: 0.170438\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 302 \tTraining Loss: 0.158121 \tValidation Loss: 0.170706\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 303 \tTraining Loss: 0.157975 \tValidation Loss: 0.172097\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 304 \tTraining Loss: 0.158164 \tValidation Loss: 0.169755\n",
      "Epoch: 305 \tTraining Loss: 0.160060 \tValidation Loss: 0.174140\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 306 \tTraining Loss: 0.164874 \tValidation Loss: 0.169058\n",
      "Epoch: 307 \tTraining Loss: 0.158030 \tValidation Loss: 0.169603\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 308 \tTraining Loss: 0.157970 \tValidation Loss: 0.169085\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 309 \tTraining Loss: 0.157592 \tValidation Loss: 0.170083\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 310 \tTraining Loss: 0.158223 \tValidation Loss: 0.170173\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 311 \tTraining Loss: 0.155885 \tValidation Loss: 0.169924\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 312 \tTraining Loss: 0.155808 \tValidation Loss: 0.168551\n",
      "Epoch: 313 \tTraining Loss: 0.155629 \tValidation Loss: 0.168570\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 314 \tTraining Loss: 0.155119 \tValidation Loss: 0.168682\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 315 \tTraining Loss: 0.160385 \tValidation Loss: 0.167459\n",
      "Epoch: 316 \tTraining Loss: 0.155737 \tValidation Loss: 0.167763\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 317 \tTraining Loss: 0.156660 \tValidation Loss: 0.168393\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 318 \tTraining Loss: 0.156746 \tValidation Loss: 0.169407\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 319 \tTraining Loss: 0.155105 \tValidation Loss: 0.168671\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 320 \tTraining Loss: 0.153884 \tValidation Loss: 0.168291\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 321 \tTraining Loss: 0.153470 \tValidation Loss: 0.167738\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 322 \tTraining Loss: 0.153330 \tValidation Loss: 0.167987\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 323 \tTraining Loss: 0.153058 \tValidation Loss: 0.170700\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 324 \tTraining Loss: 0.154447 \tValidation Loss: 0.167772\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 325 \tTraining Loss: 0.154398 \tValidation Loss: 0.167675\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 326 \tTraining Loss: 0.153281 \tValidation Loss: 0.166706\n",
      "Epoch: 327 \tTraining Loss: 0.153626 \tValidation Loss: 0.167392\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 328 \tTraining Loss: 0.152375 \tValidation Loss: 0.169040\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 329 \tTraining Loss: 0.151625 \tValidation Loss: 0.167884\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 330 \tTraining Loss: 0.151674 \tValidation Loss: 0.166607\n",
      "Epoch: 331 \tTraining Loss: 0.151186 \tValidation Loss: 0.166707\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 332 \tTraining Loss: 0.150633 \tValidation Loss: 0.167026\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 333 \tTraining Loss: 0.149763 \tValidation Loss: 0.168266\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 334 \tTraining Loss: 0.151540 \tValidation Loss: 0.169458\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 335 \tTraining Loss: 0.150861 \tValidation Loss: 0.166476\n",
      "Epoch: 336 \tTraining Loss: 0.149465 \tValidation Loss: 0.166232\n",
      "Epoch: 337 \tTraining Loss: 0.149544 \tValidation Loss: 0.165983\n",
      "Epoch: 338 \tTraining Loss: 0.151106 \tValidation Loss: 0.166456\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 339 \tTraining Loss: 0.149417 \tValidation Loss: 0.165902\n",
      "Epoch: 340 \tTraining Loss: 0.149245 \tValidation Loss: 0.165858\n",
      "Epoch: 341 \tTraining Loss: 0.151432 \tValidation Loss: 0.165098\n",
      "Epoch: 342 \tTraining Loss: 0.147928 \tValidation Loss: 0.165805\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 343 \tTraining Loss: 0.153282 \tValidation Loss: 0.168087\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 344 \tTraining Loss: 0.150897 \tValidation Loss: 0.166237\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 345 \tTraining Loss: 0.148364 \tValidation Loss: 0.165100\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 346 \tTraining Loss: 0.149953 \tValidation Loss: 0.164510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 347 \tTraining Loss: 0.148414 \tValidation Loss: 0.164661\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 348 \tTraining Loss: 0.148036 \tValidation Loss: 0.164968\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 349 \tTraining Loss: 0.147005 \tValidation Loss: 0.165819\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 350 \tTraining Loss: 0.146999 \tValidation Loss: 0.164805\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 351 \tTraining Loss: 0.146766 \tValidation Loss: 0.164253\n",
      "Epoch: 352 \tTraining Loss: 0.146279 \tValidation Loss: 0.164082\n",
      "Epoch: 353 \tTraining Loss: 0.146692 \tValidation Loss: 0.165902\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 354 \tTraining Loss: 0.145533 \tValidation Loss: 0.165307\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 355 \tTraining Loss: 0.145957 \tValidation Loss: 0.164796\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 356 \tTraining Loss: 0.146017 \tValidation Loss: 0.165138\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 357 \tTraining Loss: 0.144736 \tValidation Loss: 0.164911\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 358 \tTraining Loss: 0.145988 \tValidation Loss: 0.165874\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 359 \tTraining Loss: 0.152126 \tValidation Loss: 0.164705\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 360 \tTraining Loss: 0.144697 \tValidation Loss: 0.164649\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 361 \tTraining Loss: 0.144360 \tValidation Loss: 0.167007\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 362 \tTraining Loss: 0.144399 \tValidation Loss: 0.164356\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 363 \tTraining Loss: 0.158184 \tValidation Loss: 0.167507\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 364 \tTraining Loss: 0.144652 \tValidation Loss: 0.164744\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 365 \tTraining Loss: 0.145551 \tValidation Loss: 0.164877\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 366 \tTraining Loss: 0.143099 \tValidation Loss: 0.164552\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 367 \tTraining Loss: 0.148386 \tValidation Loss: 0.166493\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 368 \tTraining Loss: 0.145436 \tValidation Loss: 0.165904\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 369 \tTraining Loss: 0.142631 \tValidation Loss: 0.164796\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 370 \tTraining Loss: 0.144108 \tValidation Loss: 0.164133\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 371 \tTraining Loss: 0.142653 \tValidation Loss: 0.164063\n",
      "Epoch: 372 \tTraining Loss: 0.142152 \tValidation Loss: 0.163937\n",
      "Epoch: 373 \tTraining Loss: 0.142451 \tValidation Loss: 0.164388\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 374 \tTraining Loss: 0.140858 \tValidation Loss: 0.163870\n",
      "Epoch: 375 \tTraining Loss: 0.142371 \tValidation Loss: 0.164684\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 376 \tTraining Loss: 0.147685 \tValidation Loss: 0.163725\n",
      "Epoch: 377 \tTraining Loss: 0.140939 \tValidation Loss: 0.163657\n",
      "Epoch: 378 \tTraining Loss: 0.141639 \tValidation Loss: 0.162613\n",
      "Epoch: 379 \tTraining Loss: 0.141241 \tValidation Loss: 0.164001\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 380 \tTraining Loss: 0.140084 \tValidation Loss: 0.163420\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 381 \tTraining Loss: 0.143277 \tValidation Loss: 0.162171\n",
      "Epoch: 382 \tTraining Loss: 0.140257 \tValidation Loss: 0.162101\n",
      "Epoch: 383 \tTraining Loss: 0.140648 \tValidation Loss: 0.163239\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 384 \tTraining Loss: 0.139478 \tValidation Loss: 0.162516\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 385 \tTraining Loss: 0.140081 \tValidation Loss: 0.162097\n",
      "Epoch: 386 \tTraining Loss: 0.139491 \tValidation Loss: 0.162481\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 387 \tTraining Loss: 0.138805 \tValidation Loss: 0.162158\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 388 \tTraining Loss: 0.138705 \tValidation Loss: 0.162779\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 389 \tTraining Loss: 0.138535 \tValidation Loss: 0.162812\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 390 \tTraining Loss: 0.137805 \tValidation Loss: 0.162692\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 391 \tTraining Loss: 0.137787 \tValidation Loss: 0.162873\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 392 \tTraining Loss: 0.140038 \tValidation Loss: 0.162061\n",
      "Epoch: 393 \tTraining Loss: 0.137439 \tValidation Loss: 0.161865\n",
      "Epoch: 394 \tTraining Loss: 0.144698 \tValidation Loss: 0.165004\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 395 \tTraining Loss: 0.137934 \tValidation Loss: 0.163052\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 396 \tTraining Loss: 0.137512 \tValidation Loss: 0.161878\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 397 \tTraining Loss: 0.136536 \tValidation Loss: 0.161669\n",
      "Epoch: 398 \tTraining Loss: 0.136279 \tValidation Loss: 0.162153\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 399 \tTraining Loss: 0.136846 \tValidation Loss: 0.161769\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 400 \tTraining Loss: 0.136303 \tValidation Loss: 0.161441\n",
      "Epoch: 401 \tTraining Loss: 0.139793 \tValidation Loss: 0.162770\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 402 \tTraining Loss: 0.135985 \tValidation Loss: 0.162195\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 403 \tTraining Loss: 0.139756 \tValidation Loss: 0.161357\n",
      "Epoch: 404 \tTraining Loss: 0.135739 \tValidation Loss: 0.161170\n",
      "Epoch: 405 \tTraining Loss: 0.140994 \tValidation Loss: 0.168818\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 406 \tTraining Loss: 0.135801 \tValidation Loss: 0.161375\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 407 \tTraining Loss: 0.135209 \tValidation Loss: 0.160623\n",
      "Epoch: 408 \tTraining Loss: 0.134982 \tValidation Loss: 0.160428\n",
      "Epoch: 409 \tTraining Loss: 0.135160 \tValidation Loss: 0.160320\n",
      "Epoch: 410 \tTraining Loss: 0.135409 \tValidation Loss: 0.161262\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 411 \tTraining Loss: 0.134074 \tValidation Loss: 0.162864\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 412 \tTraining Loss: 0.134596 \tValidation Loss: 0.160502\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 413 \tTraining Loss: 0.134121 \tValidation Loss: 0.160758\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 414 \tTraining Loss: 0.140792 \tValidation Loss: 0.161598\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 415 \tTraining Loss: 0.133613 \tValidation Loss: 0.160149\n",
      "Epoch: 416 \tTraining Loss: 0.133574 \tValidation Loss: 0.160662\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 417 \tTraining Loss: 0.133032 \tValidation Loss: 0.160913\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 418 \tTraining Loss: 0.133057 \tValidation Loss: 0.162888\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 419 \tTraining Loss: 0.138662 \tValidation Loss: 0.160194\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 420 \tTraining Loss: 0.137815 \tValidation Loss: 0.162981\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 421 \tTraining Loss: 0.132241 \tValidation Loss: 0.159825\n",
      "Epoch: 422 \tTraining Loss: 0.132648 \tValidation Loss: 0.159406\n",
      "Epoch: 423 \tTraining Loss: 0.137276 \tValidation Loss: 0.159166\n",
      "Epoch: 424 \tTraining Loss: 0.131208 \tValidation Loss: 0.160419\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 425 \tTraining Loss: 0.130811 \tValidation Loss: 0.159879\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 426 \tTraining Loss: 0.134311 \tValidation Loss: 0.161104\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 427 \tTraining Loss: 0.131749 \tValidation Loss: 0.159573\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 428 \tTraining Loss: 0.131279 \tValidation Loss: 0.161912\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 429 \tTraining Loss: 0.131835 \tValidation Loss: 0.159251\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 430 \tTraining Loss: 0.130721 \tValidation Loss: 0.159585\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 431 \tTraining Loss: 0.130546 \tValidation Loss: 0.159402\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 432 \tTraining Loss: 0.130986 \tValidation Loss: 0.159784\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 433 \tTraining Loss: 0.130635 \tValidation Loss: 0.159939\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 434 \tTraining Loss: 0.130762 \tValidation Loss: 0.159455\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 435 \tTraining Loss: 0.141255 \tValidation Loss: 0.164043\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 436 \tTraining Loss: 0.137368 \tValidation Loss: 0.160881\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 437 \tTraining Loss: 0.129738 \tValidation Loss: 0.160454\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 438 \tTraining Loss: 0.129990 \tValidation Loss: 0.159394\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 439 \tTraining Loss: 0.129168 \tValidation Loss: 0.158885\n",
      "Epoch: 440 \tTraining Loss: 0.128432 \tValidation Loss: 0.158549\n",
      "Epoch: 441 \tTraining Loss: 0.127659 \tValidation Loss: 0.160981\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 442 \tTraining Loss: 0.128760 \tValidation Loss: 0.158019\n",
      "Epoch: 443 \tTraining Loss: 0.127893 \tValidation Loss: 0.157955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 444 \tTraining Loss: 0.129340 \tValidation Loss: 0.158181\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 445 \tTraining Loss: 0.128678 \tValidation Loss: 0.160363\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 446 \tTraining Loss: 0.127812 \tValidation Loss: 0.158266\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 447 \tTraining Loss: 0.128936 \tValidation Loss: 0.159221\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 448 \tTraining Loss: 0.129569 \tValidation Loss: 0.159356\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 449 \tTraining Loss: 0.127446 \tValidation Loss: 0.157837\n",
      "Epoch: 450 \tTraining Loss: 0.126734 \tValidation Loss: 0.158419\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 451 \tTraining Loss: 0.129209 \tValidation Loss: 0.157641\n",
      "Epoch: 452 \tTraining Loss: 0.130765 \tValidation Loss: 0.157815\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 453 \tTraining Loss: 0.126632 \tValidation Loss: 0.158211\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 454 \tTraining Loss: 0.126566 \tValidation Loss: 0.158139\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 455 \tTraining Loss: 0.126084 \tValidation Loss: 0.157993\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 456 \tTraining Loss: 0.125595 \tValidation Loss: 0.158206\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 457 \tTraining Loss: 0.125657 \tValidation Loss: 0.158578\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 458 \tTraining Loss: 0.125889 \tValidation Loss: 0.157836\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 459 \tTraining Loss: 0.127235 \tValidation Loss: 0.160354\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 460 \tTraining Loss: 0.125567 \tValidation Loss: 0.158398\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 461 \tTraining Loss: 0.126662 \tValidation Loss: 0.157579\n",
      "Epoch: 462 \tTraining Loss: 0.125509 \tValidation Loss: 0.156845\n",
      "Epoch: 463 \tTraining Loss: 0.125710 \tValidation Loss: 0.157568\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 464 \tTraining Loss: 0.127775 \tValidation Loss: 0.159059\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 465 \tTraining Loss: 0.125251 \tValidation Loss: 0.160192\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 466 \tTraining Loss: 0.124185 \tValidation Loss: 0.157525\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 467 \tTraining Loss: 0.124672 \tValidation Loss: 0.157778\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 468 \tTraining Loss: 0.124326 \tValidation Loss: 0.158482\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 469 \tTraining Loss: 0.124327 \tValidation Loss: 0.158592\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 470 \tTraining Loss: 0.124056 \tValidation Loss: 0.157463\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 471 \tTraining Loss: 0.123569 \tValidation Loss: 0.156801\n",
      "Epoch: 472 \tTraining Loss: 0.124324 \tValidation Loss: 0.156891\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 473 \tTraining Loss: 0.123160 \tValidation Loss: 0.156610\n",
      "Epoch: 474 \tTraining Loss: 0.124515 \tValidation Loss: 0.156122\n",
      "Epoch: 475 \tTraining Loss: 0.123086 \tValidation Loss: 0.156093\n",
      "Epoch: 476 \tTraining Loss: 0.122588 \tValidation Loss: 0.155930\n",
      "Epoch: 477 \tTraining Loss: 0.123184 \tValidation Loss: 0.156240\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 478 \tTraining Loss: 0.122958 \tValidation Loss: 0.157392\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 479 \tTraining Loss: 0.121199 \tValidation Loss: 0.156413\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 480 \tTraining Loss: 0.122199 \tValidation Loss: 0.156179\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 481 \tTraining Loss: 0.121812 \tValidation Loss: 0.155841\n",
      "Epoch: 482 \tTraining Loss: 0.124115 \tValidation Loss: 0.161253\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 483 \tTraining Loss: 0.121622 \tValidation Loss: 0.157737\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 484 \tTraining Loss: 0.121640 \tValidation Loss: 0.158294\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 485 \tTraining Loss: 0.122673 \tValidation Loss: 0.157710\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 486 \tTraining Loss: 0.122269 \tValidation Loss: 0.156205\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 487 \tTraining Loss: 0.121027 \tValidation Loss: 0.155829\n",
      "Epoch: 488 \tTraining Loss: 0.120582 \tValidation Loss: 0.155549\n",
      "Epoch: 489 \tTraining Loss: 0.121965 \tValidation Loss: 0.155728\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 490 \tTraining Loss: 0.120995 \tValidation Loss: 0.154915\n",
      "Epoch: 491 \tTraining Loss: 0.120995 \tValidation Loss: 0.156297\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 492 \tTraining Loss: 0.120987 \tValidation Loss: 0.156435\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 493 \tTraining Loss: 0.120176 \tValidation Loss: 0.154915\n",
      "Epoch: 494 \tTraining Loss: 0.120124 \tValidation Loss: 0.154889\n",
      "Epoch: 495 \tTraining Loss: 0.119564 \tValidation Loss: 0.156012\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 496 \tTraining Loss: 0.120389 \tValidation Loss: 0.155989\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 497 \tTraining Loss: 0.118813 \tValidation Loss: 0.155586\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 498 \tTraining Loss: 0.119132 \tValidation Loss: 0.154945\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 499 \tTraining Loss: 0.120885 \tValidation Loss: 0.154750\n",
      "Epoch: 500 \tTraining Loss: 0.120271 \tValidation Loss: 0.155528\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 501 \tTraining Loss: 0.118578 \tValidation Loss: 0.155229\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 502 \tTraining Loss: 0.119050 \tValidation Loss: 0.154649\n",
      "Epoch: 503 \tTraining Loss: 0.119250 \tValidation Loss: 0.155232\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 504 \tTraining Loss: 0.118402 \tValidation Loss: 0.157427\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 505 \tTraining Loss: 0.118453 \tValidation Loss: 0.154812\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 506 \tTraining Loss: 0.119214 \tValidation Loss: 0.155397\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 507 \tTraining Loss: 0.117916 \tValidation Loss: 0.154710\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 508 \tTraining Loss: 0.117205 \tValidation Loss: 0.154622\n",
      "Epoch: 509 \tTraining Loss: 0.117137 \tValidation Loss: 0.155848\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 510 \tTraining Loss: 0.122324 \tValidation Loss: 0.155950\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 511 \tTraining Loss: 0.116998 \tValidation Loss: 0.154417\n",
      "Epoch: 512 \tTraining Loss: 0.118615 \tValidation Loss: 0.155311\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 513 \tTraining Loss: 0.118259 \tValidation Loss: 0.153916\n",
      "Epoch: 514 \tTraining Loss: 0.117407 \tValidation Loss: 0.153600\n",
      "Epoch: 515 \tTraining Loss: 0.126870 \tValidation Loss: 0.161991\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 516 \tTraining Loss: 0.117852 \tValidation Loss: 0.153341\n",
      "Epoch: 517 \tTraining Loss: 0.119652 \tValidation Loss: 0.154955\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 518 \tTraining Loss: 0.116411 \tValidation Loss: 0.153532\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 519 \tTraining Loss: 0.116504 \tValidation Loss: 0.153366\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 520 \tTraining Loss: 0.115589 \tValidation Loss: 0.157569\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 521 \tTraining Loss: 0.116848 \tValidation Loss: 0.153725\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 522 \tTraining Loss: 0.115904 \tValidation Loss: 0.154610\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 523 \tTraining Loss: 0.115699 \tValidation Loss: 0.154110\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 524 \tTraining Loss: 0.115015 \tValidation Loss: 0.153861\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 525 \tTraining Loss: 0.119447 \tValidation Loss: 0.159627\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 526 \tTraining Loss: 0.115563 \tValidation Loss: 0.154139\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 527 \tTraining Loss: 0.115508 \tValidation Loss: 0.153829\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 528 \tTraining Loss: 0.118821 \tValidation Loss: 0.156981\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 529 \tTraining Loss: 0.114872 \tValidation Loss: 0.154517\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 530 \tTraining Loss: 0.114820 \tValidation Loss: 0.153703\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 531 \tTraining Loss: 0.114312 \tValidation Loss: 0.153291\n",
      "Epoch: 532 \tTraining Loss: 0.116584 \tValidation Loss: 0.153998\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 533 \tTraining Loss: 0.113865 \tValidation Loss: 0.154006\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 534 \tTraining Loss: 0.113561 \tValidation Loss: 0.153043\n",
      "Epoch: 535 \tTraining Loss: 0.115798 \tValidation Loss: 0.153088\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 536 \tTraining Loss: 0.118725 \tValidation Loss: 0.157722\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 537 \tTraining Loss: 0.113900 \tValidation Loss: 0.152519\n",
      "Epoch: 538 \tTraining Loss: 0.113264 \tValidation Loss: 0.153135\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 539 \tTraining Loss: 0.112995 \tValidation Loss: 0.153323\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 540 \tTraining Loss: 0.113549 \tValidation Loss: 0.152735\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 541 \tTraining Loss: 0.112432 \tValidation Loss: 0.153701\n",
      "Earlystopping Patience Counter: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 542 \tTraining Loss: 0.112934 \tValidation Loss: 0.153006\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 543 \tTraining Loss: 0.112253 \tValidation Loss: 0.153391\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 544 \tTraining Loss: 0.112536 \tValidation Loss: 0.152706\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 545 \tTraining Loss: 0.111741 \tValidation Loss: 0.154640\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 546 \tTraining Loss: 0.112018 \tValidation Loss: 0.153417\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 547 \tTraining Loss: 0.114657 \tValidation Loss: 0.152779\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 548 \tTraining Loss: 0.111708 \tValidation Loss: 0.152822\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 549 \tTraining Loss: 0.112338 \tValidation Loss: 0.152582\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 550 \tTraining Loss: 0.111426 \tValidation Loss: 0.152820\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 551 \tTraining Loss: 0.113093 \tValidation Loss: 0.154763\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 552 \tTraining Loss: 0.111450 \tValidation Loss: 0.153867\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 553 \tTraining Loss: 0.112040 \tValidation Loss: 0.153044\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 554 \tTraining Loss: 0.111558 \tValidation Loss: 0.151976\n",
      "Epoch: 555 \tTraining Loss: 0.110840 \tValidation Loss: 0.152311\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 556 \tTraining Loss: 0.111996 \tValidation Loss: 0.152344\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 557 \tTraining Loss: 0.114835 \tValidation Loss: 0.158112\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 558 \tTraining Loss: 0.110837 \tValidation Loss: 0.151800\n",
      "Epoch: 559 \tTraining Loss: 0.110410 \tValidation Loss: 0.155213\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 560 \tTraining Loss: 0.109970 \tValidation Loss: 0.151903\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 561 \tTraining Loss: 0.110643 \tValidation Loss: 0.152827\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 562 \tTraining Loss: 0.110014 \tValidation Loss: 0.152763\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 563 \tTraining Loss: 0.109996 \tValidation Loss: 0.152668\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 564 \tTraining Loss: 0.110621 \tValidation Loss: 0.151874\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 565 \tTraining Loss: 0.110967 \tValidation Loss: 0.153229\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 566 \tTraining Loss: 0.110612 \tValidation Loss: 0.152704\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 567 \tTraining Loss: 0.110800 \tValidation Loss: 0.152190\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 568 \tTraining Loss: 0.109929 \tValidation Loss: 0.152145\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 569 \tTraining Loss: 0.110037 \tValidation Loss: 0.152894\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 570 \tTraining Loss: 0.108918 \tValidation Loss: 0.152523\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 571 \tTraining Loss: 0.117374 \tValidation Loss: 0.151284\n",
      "Epoch: 572 \tTraining Loss: 0.108459 \tValidation Loss: 0.151892\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 573 \tTraining Loss: 0.108779 \tValidation Loss: 0.152846\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 574 \tTraining Loss: 0.108896 \tValidation Loss: 0.152621\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 575 \tTraining Loss: 0.108418 \tValidation Loss: 0.152860\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 576 \tTraining Loss: 0.108307 \tValidation Loss: 0.153503\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 577 \tTraining Loss: 0.109014 \tValidation Loss: 0.152587\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 578 \tTraining Loss: 0.108842 \tValidation Loss: 0.152697\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 579 \tTraining Loss: 0.108412 \tValidation Loss: 0.151782\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 580 \tTraining Loss: 0.107574 \tValidation Loss: 0.153304\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 581 \tTraining Loss: 0.107351 \tValidation Loss: 0.152608\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 582 \tTraining Loss: 0.108389 \tValidation Loss: 0.153119\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 583 \tTraining Loss: 0.107018 \tValidation Loss: 0.154634\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 584 \tTraining Loss: 0.107381 \tValidation Loss: 0.151520\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 585 \tTraining Loss: 0.108509 \tValidation Loss: 0.155972\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 586 \tTraining Loss: 0.108005 \tValidation Loss: 0.151388\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 587 \tTraining Loss: 0.107841 \tValidation Loss: 0.153232\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 588 \tTraining Loss: 0.107291 \tValidation Loss: 0.152357\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 589 \tTraining Loss: 0.108999 \tValidation Loss: 0.150344\n",
      "Epoch: 590 \tTraining Loss: 0.106565 \tValidation Loss: 0.152497\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 591 \tTraining Loss: 0.107000 \tValidation Loss: 0.151299\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 592 \tTraining Loss: 0.106570 \tValidation Loss: 0.151569\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 593 \tTraining Loss: 0.106706 \tValidation Loss: 0.150977\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 594 \tTraining Loss: 0.106042 \tValidation Loss: 0.150826\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 595 \tTraining Loss: 0.105664 \tValidation Loss: 0.150959\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 596 \tTraining Loss: 0.111392 \tValidation Loss: 0.157427\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 597 \tTraining Loss: 0.107431 \tValidation Loss: 0.151353\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 598 \tTraining Loss: 0.106791 \tValidation Loss: 0.151027\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 599 \tTraining Loss: 0.105925 \tValidation Loss: 0.151163\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 600 \tTraining Loss: 0.105773 \tValidation Loss: 0.150407\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 601 \tTraining Loss: 0.105567 \tValidation Loss: 0.150663\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 602 \tTraining Loss: 0.110830 \tValidation Loss: 0.155798\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 603 \tTraining Loss: 0.106104 \tValidation Loss: 0.150968\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 604 \tTraining Loss: 0.104606 \tValidation Loss: 0.150563\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 605 \tTraining Loss: 0.104272 \tValidation Loss: 0.153018\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 606 \tTraining Loss: 0.104694 \tValidation Loss: 0.150952\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 607 \tTraining Loss: 0.112142 \tValidation Loss: 0.153330\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 608 \tTraining Loss: 0.104592 \tValidation Loss: 0.149929\n",
      "Epoch: 609 \tTraining Loss: 0.105188 \tValidation Loss: 0.151390\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 610 \tTraining Loss: 0.104495 \tValidation Loss: 0.151231\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 611 \tTraining Loss: 0.104787 \tValidation Loss: 0.151178\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 612 \tTraining Loss: 0.112084 \tValidation Loss: 0.150901\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 613 \tTraining Loss: 0.104398 \tValidation Loss: 0.150643\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 614 \tTraining Loss: 0.104534 \tValidation Loss: 0.152195\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 615 \tTraining Loss: 0.104853 \tValidation Loss: 0.151405\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 616 \tTraining Loss: 0.102270 \tValidation Loss: 0.150199\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 617 \tTraining Loss: 0.102852 \tValidation Loss: 0.150031\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 618 \tTraining Loss: 0.104570 \tValidation Loss: 0.150417\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 619 \tTraining Loss: 0.104274 \tValidation Loss: 0.151371\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 620 \tTraining Loss: 0.108938 \tValidation Loss: 0.152962\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 621 \tTraining Loss: 0.105302 \tValidation Loss: 0.153946\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 622 \tTraining Loss: 0.102450 \tValidation Loss: 0.150355\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 623 \tTraining Loss: 0.101986 \tValidation Loss: 0.150573\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 624 \tTraining Loss: 0.102409 \tValidation Loss: 0.151046\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 625 \tTraining Loss: 0.103059 \tValidation Loss: 0.150971\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 626 \tTraining Loss: 0.101934 \tValidation Loss: 0.150813\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 627 \tTraining Loss: 0.103128 \tValidation Loss: 0.150011\n",
      "Earlystopping Patience Counter: 19\n",
      "Epoch: 628 \tTraining Loss: 0.102320 \tValidation Loss: 0.151738\n",
      "Earlystopping Patience Counter: 20\n",
      "Epoch: 629 \tTraining Loss: 0.102653 \tValidation Loss: 0.150600\n",
      "Earlystopping Patience Counter: 21\n",
      "Epoch: 630 \tTraining Loss: 0.101426 \tValidation Loss: 0.150393\n",
      "Earlystopping Patience Counter: 22\n",
      "Epoch: 631 \tTraining Loss: 0.101660 \tValidation Loss: 0.150869\n",
      "Earlystopping Patience Counter: 23\n",
      "Epoch: 632 \tTraining Loss: 0.105006 \tValidation Loss: 0.152948\n",
      "Earlystopping Patience Counter: 24\n",
      "Epoch: 633 \tTraining Loss: 0.102303 \tValidation Loss: 0.150380\n",
      "Earlystopping Patience Counter: 25\n",
      "Epoch: 634 \tTraining Loss: 0.101386 \tValidation Loss: 0.149716\n",
      "Epoch: 635 \tTraining Loss: 0.100800 \tValidation Loss: 0.150909\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 636 \tTraining Loss: 0.100760 \tValidation Loss: 0.150285\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 637 \tTraining Loss: 0.100297 \tValidation Loss: 0.151664\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 638 \tTraining Loss: 0.100780 \tValidation Loss: 0.150500\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 639 \tTraining Loss: 0.101378 \tValidation Loss: 0.149658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 640 \tTraining Loss: 0.100021 \tValidation Loss: 0.149612\n",
      "Epoch: 641 \tTraining Loss: 0.100279 \tValidation Loss: 0.149669\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 642 \tTraining Loss: 0.100915 \tValidation Loss: 0.149409\n",
      "Epoch: 643 \tTraining Loss: 0.100116 \tValidation Loss: 0.149503\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 644 \tTraining Loss: 0.099226 \tValidation Loss: 0.149828\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 645 \tTraining Loss: 0.100495 \tValidation Loss: 0.149039\n",
      "Epoch: 646 \tTraining Loss: 0.100205 \tValidation Loss: 0.149462\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 647 \tTraining Loss: 0.104158 \tValidation Loss: 0.161308\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 648 \tTraining Loss: 0.100776 \tValidation Loss: 0.150561\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 649 \tTraining Loss: 0.100568 \tValidation Loss: 0.150808\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 650 \tTraining Loss: 0.099484 \tValidation Loss: 0.149862\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 651 \tTraining Loss: 0.109478 \tValidation Loss: 0.153674\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 652 \tTraining Loss: 0.100060 \tValidation Loss: 0.149804\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 653 \tTraining Loss: 0.100771 \tValidation Loss: 0.150163\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 654 \tTraining Loss: 0.102247 \tValidation Loss: 0.154115\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 655 \tTraining Loss: 0.099070 \tValidation Loss: 0.148760\n",
      "Epoch: 656 \tTraining Loss: 0.097745 \tValidation Loss: 0.150400\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 657 \tTraining Loss: 0.099244 \tValidation Loss: 0.148628\n",
      "Epoch: 658 \tTraining Loss: 0.097800 \tValidation Loss: 0.149250\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 659 \tTraining Loss: 0.101066 \tValidation Loss: 0.149156\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 660 \tTraining Loss: 0.099335 \tValidation Loss: 0.148958\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 661 \tTraining Loss: 0.098049 \tValidation Loss: 0.149412\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 662 \tTraining Loss: 0.097938 \tValidation Loss: 0.149558\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 663 \tTraining Loss: 0.097885 \tValidation Loss: 0.150374\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 664 \tTraining Loss: 0.098448 \tValidation Loss: 0.149165\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 665 \tTraining Loss: 0.097879 \tValidation Loss: 0.148634\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 666 \tTraining Loss: 0.097156 \tValidation Loss: 0.148782\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 667 \tTraining Loss: 0.097200 \tValidation Loss: 0.151052\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 668 \tTraining Loss: 0.096915 \tValidation Loss: 0.149066\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 669 \tTraining Loss: 0.098038 \tValidation Loss: 0.148714\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 670 \tTraining Loss: 0.096819 \tValidation Loss: 0.148489\n",
      "Epoch: 671 \tTraining Loss: 0.105350 \tValidation Loss: 0.153344\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 672 \tTraining Loss: 0.097313 \tValidation Loss: 0.148887\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 673 \tTraining Loss: 0.096592 \tValidation Loss: 0.148489\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 674 \tTraining Loss: 0.096469 \tValidation Loss: 0.150505\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 675 \tTraining Loss: 0.099034 \tValidation Loss: 0.149007\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 676 \tTraining Loss: 0.095456 \tValidation Loss: 0.151394\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 677 \tTraining Loss: 0.096497 \tValidation Loss: 0.148586\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 678 \tTraining Loss: 0.096257 \tValidation Loss: 0.149156\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 679 \tTraining Loss: 0.097257 \tValidation Loss: 0.149406\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 680 \tTraining Loss: 0.096920 \tValidation Loss: 0.148127\n",
      "Epoch: 681 \tTraining Loss: 0.095749 \tValidation Loss: 0.147784\n",
      "Epoch: 682 \tTraining Loss: 0.095779 \tValidation Loss: 0.148168\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 683 \tTraining Loss: 0.096184 \tValidation Loss: 0.148170\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 684 \tTraining Loss: 0.096306 \tValidation Loss: 0.149325\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 685 \tTraining Loss: 0.095866 \tValidation Loss: 0.148541\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 686 \tTraining Loss: 0.095520 \tValidation Loss: 0.147561\n",
      "Epoch: 687 \tTraining Loss: 0.096436 \tValidation Loss: 0.147592\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 688 \tTraining Loss: 0.095688 \tValidation Loss: 0.150087\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 689 \tTraining Loss: 0.094912 \tValidation Loss: 0.148634\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 690 \tTraining Loss: 0.094918 \tValidation Loss: 0.148652\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 691 \tTraining Loss: 0.095736 \tValidation Loss: 0.148287\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 692 \tTraining Loss: 0.094499 \tValidation Loss: 0.147928\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 693 \tTraining Loss: 0.093834 \tValidation Loss: 0.150240\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 694 \tTraining Loss: 0.094609 \tValidation Loss: 0.148501\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 695 \tTraining Loss: 0.094872 \tValidation Loss: 0.147602\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 696 \tTraining Loss: 0.095710 \tValidation Loss: 0.147196\n",
      "Epoch: 697 \tTraining Loss: 0.093994 \tValidation Loss: 0.147923\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 698 \tTraining Loss: 0.094376 \tValidation Loss: 0.147425\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 699 \tTraining Loss: 0.099918 \tValidation Loss: 0.153865\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 700 \tTraining Loss: 0.094228 \tValidation Loss: 0.148491\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 701 \tTraining Loss: 0.093830 \tValidation Loss: 0.148049\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 702 \tTraining Loss: 0.093029 \tValidation Loss: 0.148299\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 703 \tTraining Loss: 0.093756 \tValidation Loss: 0.148087\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 704 \tTraining Loss: 0.093341 \tValidation Loss: 0.147225\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 705 \tTraining Loss: 0.094022 \tValidation Loss: 0.147383\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 706 \tTraining Loss: 0.093867 \tValidation Loss: 0.148802\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 707 \tTraining Loss: 0.093099 \tValidation Loss: 0.149260\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 708 \tTraining Loss: 0.093259 \tValidation Loss: 0.147885\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 709 \tTraining Loss: 0.093253 \tValidation Loss: 0.147700\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 710 \tTraining Loss: 0.098673 \tValidation Loss: 0.151676\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 711 \tTraining Loss: 0.093376 \tValidation Loss: 0.148813\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 712 \tTraining Loss: 0.093214 \tValidation Loss: 0.147804\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 713 \tTraining Loss: 0.092898 \tValidation Loss: 0.147636\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 714 \tTraining Loss: 0.094025 \tValidation Loss: 0.146903\n",
      "Epoch: 715 \tTraining Loss: 0.092022 \tValidation Loss: 0.147503\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 716 \tTraining Loss: 0.091872 \tValidation Loss: 0.148330\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 717 \tTraining Loss: 0.093510 \tValidation Loss: 0.147752\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 718 \tTraining Loss: 0.092374 \tValidation Loss: 0.147237\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 719 \tTraining Loss: 0.092909 \tValidation Loss: 0.147659\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 720 \tTraining Loss: 0.092370 \tValidation Loss: 0.147179\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 721 \tTraining Loss: 0.094843 \tValidation Loss: 0.145820\n",
      "Epoch: 722 \tTraining Loss: 0.091695 \tValidation Loss: 0.148516\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 723 \tTraining Loss: 0.091270 \tValidation Loss: 0.146555\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 724 \tTraining Loss: 0.091209 \tValidation Loss: 0.146226\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 725 \tTraining Loss: 0.091464 \tValidation Loss: 0.146543\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 726 \tTraining Loss: 0.091908 \tValidation Loss: 0.147167\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 727 \tTraining Loss: 0.091684 \tValidation Loss: 0.146839\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 728 \tTraining Loss: 0.091215 \tValidation Loss: 0.146870\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 729 \tTraining Loss: 0.090647 \tValidation Loss: 0.147154\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 730 \tTraining Loss: 0.091497 \tValidation Loss: 0.150341\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 731 \tTraining Loss: 0.094927 \tValidation Loss: 0.148461\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 732 \tTraining Loss: 0.090985 \tValidation Loss: 0.147224\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 733 \tTraining Loss: 0.091055 \tValidation Loss: 0.148120\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 734 \tTraining Loss: 0.090012 \tValidation Loss: 0.148011\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 735 \tTraining Loss: 0.090198 \tValidation Loss: 0.146654\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 736 \tTraining Loss: 0.090588 \tValidation Loss: 0.149468\n",
      "Earlystopping Patience Counter: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 737 \tTraining Loss: 0.090341 \tValidation Loss: 0.151093\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 738 \tTraining Loss: 0.090512 \tValidation Loss: 0.147098\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 739 \tTraining Loss: 0.089946 \tValidation Loss: 0.147348\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 740 \tTraining Loss: 0.089516 \tValidation Loss: 0.147788\n",
      "Earlystopping Patience Counter: 19\n",
      "Epoch: 741 \tTraining Loss: 0.090172 \tValidation Loss: 0.146547\n",
      "Earlystopping Patience Counter: 20\n",
      "Epoch: 742 \tTraining Loss: 0.090587 \tValidation Loss: 0.150211\n",
      "Earlystopping Patience Counter: 21\n",
      "Epoch: 743 \tTraining Loss: 0.090124 \tValidation Loss: 0.148055\n",
      "Earlystopping Patience Counter: 22\n",
      "Epoch: 744 \tTraining Loss: 0.089933 \tValidation Loss: 0.147377\n",
      "Earlystopping Patience Counter: 23\n",
      "Epoch: 745 \tTraining Loss: 0.089318 \tValidation Loss: 0.147580\n",
      "Earlystopping Patience Counter: 24\n",
      "Epoch: 746 \tTraining Loss: 0.091812 \tValidation Loss: 0.147244\n",
      "Earlystopping Patience Counter: 25\n",
      "Epoch: 747 \tTraining Loss: 0.089164 \tValidation Loss: 0.147378\n",
      "Earlystopping Patience Counter: 26\n",
      "Epoch: 748 \tTraining Loss: 0.088364 \tValidation Loss: 0.147131\n",
      "Earlystopping Patience Counter: 27\n",
      "Epoch: 749 \tTraining Loss: 0.090001 \tValidation Loss: 0.147229\n",
      "Earlystopping Patience Counter: 28\n",
      "Epoch: 750 \tTraining Loss: 0.088566 \tValidation Loss: 0.147141\n",
      "Earlystopping Patience Counter: 29\n",
      "Epoch: 751 \tTraining Loss: 0.089988 \tValidation Loss: 0.145687\n",
      "Epoch: 752 \tTraining Loss: 0.088691 \tValidation Loss: 0.146752\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 753 \tTraining Loss: 0.089373 \tValidation Loss: 0.146521\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 754 \tTraining Loss: 0.098428 \tValidation Loss: 0.158177\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 755 \tTraining Loss: 0.089025 \tValidation Loss: 0.148419\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 756 \tTraining Loss: 0.087968 \tValidation Loss: 0.147362\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 757 \tTraining Loss: 0.098236 \tValidation Loss: 0.147010\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 758 \tTraining Loss: 0.088465 \tValidation Loss: 0.146341\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 759 \tTraining Loss: 0.087775 \tValidation Loss: 0.147286\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 760 \tTraining Loss: 0.087255 \tValidation Loss: 0.146050\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 761 \tTraining Loss: 0.087294 \tValidation Loss: 0.147511\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 762 \tTraining Loss: 0.087671 \tValidation Loss: 0.146668\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 763 \tTraining Loss: 0.087377 \tValidation Loss: 0.147639\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 764 \tTraining Loss: 0.089264 \tValidation Loss: 0.147754\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 765 \tTraining Loss: 0.087587 \tValidation Loss: 0.147743\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 766 \tTraining Loss: 0.086920 \tValidation Loss: 0.148328\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 767 \tTraining Loss: 0.089597 \tValidation Loss: 0.149480\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 768 \tTraining Loss: 0.086883 \tValidation Loss: 0.147344\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 769 \tTraining Loss: 0.087841 \tValidation Loss: 0.148218\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 770 \tTraining Loss: 0.086957 \tValidation Loss: 0.147917\n",
      "Earlystopping Patience Counter: 19\n",
      "Epoch: 771 \tTraining Loss: 0.086238 \tValidation Loss: 0.146324\n",
      "Earlystopping Patience Counter: 20\n",
      "Epoch: 772 \tTraining Loss: 0.086991 \tValidation Loss: 0.146216\n",
      "Earlystopping Patience Counter: 21\n",
      "Epoch: 773 \tTraining Loss: 0.087303 \tValidation Loss: 0.147314\n",
      "Earlystopping Patience Counter: 22\n",
      "Epoch: 774 \tTraining Loss: 0.086781 \tValidation Loss: 0.146316\n",
      "Earlystopping Patience Counter: 23\n",
      "Epoch: 775 \tTraining Loss: 0.086277 \tValidation Loss: 0.146282\n",
      "Earlystopping Patience Counter: 24\n",
      "Epoch: 776 \tTraining Loss: 0.086107 \tValidation Loss: 0.146249\n",
      "Earlystopping Patience Counter: 25\n",
      "Epoch: 777 \tTraining Loss: 0.086424 \tValidation Loss: 0.146567\n",
      "Earlystopping Patience Counter: 26\n",
      "Epoch: 778 \tTraining Loss: 0.085701 \tValidation Loss: 0.151777\n",
      "Earlystopping Patience Counter: 27\n",
      "Epoch: 779 \tTraining Loss: 0.086445 \tValidation Loss: 0.147989\n",
      "Earlystopping Patience Counter: 28\n",
      "Epoch: 780 \tTraining Loss: 0.086469 \tValidation Loss: 0.147451\n",
      "Earlystopping Patience Counter: 29\n",
      "Epoch: 781 \tTraining Loss: 0.086080 \tValidation Loss: 0.147663\n",
      "Earlystopping Patience Counter: 30\n",
      "Epoch: 782 \tTraining Loss: 0.087582 \tValidation Loss: 0.147816\n",
      "Earlystopping Patience Counter: 31\n",
      "Epoch: 783 \tTraining Loss: 0.085743 \tValidation Loss: 0.147264\n",
      "Earlystopping Patience Counter: 32\n",
      "Epoch: 784 \tTraining Loss: 0.085192 \tValidation Loss: 0.147232\n",
      "Earlystopping Patience Counter: 33\n",
      "Epoch: 785 \tTraining Loss: 0.085160 \tValidation Loss: 0.146664\n",
      "Earlystopping Patience Counter: 34\n",
      "Epoch: 786 \tTraining Loss: 0.085375 \tValidation Loss: 0.146434\n",
      "Earlystopping Patience Counter: 35\n",
      "Epoch: 787 \tTraining Loss: 0.086997 \tValidation Loss: 0.146665\n",
      "Earlystopping Patience Counter: 36\n",
      "Epoch: 788 \tTraining Loss: 0.085223 \tValidation Loss: 0.145854\n",
      "Earlystopping Patience Counter: 37\n",
      "Epoch: 789 \tTraining Loss: 0.085329 \tValidation Loss: 0.145851\n",
      "Earlystopping Patience Counter: 38\n",
      "Epoch: 790 \tTraining Loss: 0.084966 \tValidation Loss: 0.146561\n",
      "Earlystopping Patience Counter: 39\n",
      "Epoch: 791 \tTraining Loss: 0.085177 \tValidation Loss: 0.146471\n",
      "Earlystopping Patience Counter: 40\n",
      "Epoch: 792 \tTraining Loss: 0.084261 \tValidation Loss: 0.146988\n",
      "Earlystopping Patience Counter: 41\n",
      "Epoch: 793 \tTraining Loss: 0.085173 \tValidation Loss: 0.146921\n",
      "Earlystopping Patience Counter: 42\n",
      "Epoch: 794 \tTraining Loss: 0.084874 \tValidation Loss: 0.149064\n",
      "Earlystopping Patience Counter: 43\n",
      "Epoch: 795 \tTraining Loss: 0.084843 \tValidation Loss: 0.147296\n",
      "Earlystopping Patience Counter: 44\n",
      "Epoch: 796 \tTraining Loss: 0.085197 \tValidation Loss: 0.146605\n",
      "Earlystopping Patience Counter: 45\n",
      "Epoch: 797 \tTraining Loss: 0.084642 \tValidation Loss: 0.146527\n",
      "Earlystopping Patience Counter: 46\n",
      "Epoch: 798 \tTraining Loss: 0.084774 \tValidation Loss: 0.146451\n",
      "Earlystopping Patience Counter: 47\n",
      "Epoch: 799 \tTraining Loss: 0.085434 \tValidation Loss: 0.146634\n",
      "Earlystopping Patience Counter: 48\n",
      "Epoch: 800 \tTraining Loss: 0.084824 \tValidation Loss: 0.147009\n",
      "Earlystopping Patience Counter: 49\n",
      "Epoch: 801 \tTraining Loss: 0.084203 \tValidation Loss: 0.146424\n",
      "Earlystopping Patience Counter: 50\n",
      "Epoch: 802 \tTraining Loss: 0.083916 \tValidation Loss: 0.148352\n",
      "Earlystopping Patience Counter: 51\n",
      "Epoch: 803 \tTraining Loss: 0.084106 \tValidation Loss: 0.146912\n",
      "Earlystopping Patience Counter: 52\n",
      "Epoch: 804 \tTraining Loss: 0.083995 \tValidation Loss: 0.147079\n",
      "Earlystopping Patience Counter: 53\n",
      "Epoch: 805 \tTraining Loss: 0.084638 \tValidation Loss: 0.146463\n",
      "Earlystopping Patience Counter: 54\n",
      "Epoch: 806 \tTraining Loss: 0.083744 \tValidation Loss: 0.147626\n",
      "Earlystopping Patience Counter: 55\n",
      "Epoch: 807 \tTraining Loss: 0.084368 \tValidation Loss: 0.145675\n",
      "Epoch: 808 \tTraining Loss: 0.084393 \tValidation Loss: 0.146349\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 809 \tTraining Loss: 0.083972 \tValidation Loss: 0.147034\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 810 \tTraining Loss: 0.083030 \tValidation Loss: 0.147791\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 811 \tTraining Loss: 0.084395 \tValidation Loss: 0.145926\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 812 \tTraining Loss: 0.083444 \tValidation Loss: 0.146462\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 813 \tTraining Loss: 0.083393 \tValidation Loss: 0.146443\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 814 \tTraining Loss: 0.082850 \tValidation Loss: 0.146776\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 815 \tTraining Loss: 0.082660 \tValidation Loss: 0.147039\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 816 \tTraining Loss: 0.082275 \tValidation Loss: 0.149901\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 817 \tTraining Loss: 0.083075 \tValidation Loss: 0.146210\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 818 \tTraining Loss: 0.082493 \tValidation Loss: 0.146660\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 819 \tTraining Loss: 0.082856 \tValidation Loss: 0.146542\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 820 \tTraining Loss: 0.081747 \tValidation Loss: 0.147303\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 821 \tTraining Loss: 0.082281 \tValidation Loss: 0.146751\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 822 \tTraining Loss: 0.082468 \tValidation Loss: 0.146522\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 823 \tTraining Loss: 0.081924 \tValidation Loss: 0.147392\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 824 \tTraining Loss: 0.082789 \tValidation Loss: 0.146169\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 825 \tTraining Loss: 0.082512 \tValidation Loss: 0.146079\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 826 \tTraining Loss: 0.082838 \tValidation Loss: 0.145987\n",
      "Earlystopping Patience Counter: 19\n",
      "Epoch: 827 \tTraining Loss: 0.081659 \tValidation Loss: 0.147333\n",
      "Earlystopping Patience Counter: 20\n",
      "Epoch: 828 \tTraining Loss: 0.081339 \tValidation Loss: 0.147650\n",
      "Earlystopping Patience Counter: 21\n",
      "Epoch: 829 \tTraining Loss: 0.082578 \tValidation Loss: 0.147110\n",
      "Earlystopping Patience Counter: 22\n",
      "Epoch: 830 \tTraining Loss: 0.082178 \tValidation Loss: 0.145920\n",
      "Earlystopping Patience Counter: 23\n",
      "Epoch: 831 \tTraining Loss: 0.080721 \tValidation Loss: 0.147587\n",
      "Earlystopping Patience Counter: 24\n",
      "Epoch: 832 \tTraining Loss: 0.082132 \tValidation Loss: 0.146648\n",
      "Earlystopping Patience Counter: 25\n",
      "Epoch: 833 \tTraining Loss: 0.082020 \tValidation Loss: 0.148056\n",
      "Earlystopping Patience Counter: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 834 \tTraining Loss: 0.081339 \tValidation Loss: 0.149887\n",
      "Earlystopping Patience Counter: 27\n",
      "Epoch: 835 \tTraining Loss: 0.083278 \tValidation Loss: 0.155534\n",
      "Earlystopping Patience Counter: 28\n",
      "Epoch: 836 \tTraining Loss: 0.082573 \tValidation Loss: 0.147021\n",
      "Earlystopping Patience Counter: 29\n",
      "Epoch: 837 \tTraining Loss: 0.082112 \tValidation Loss: 0.147209\n",
      "Earlystopping Patience Counter: 30\n",
      "Epoch: 838 \tTraining Loss: 0.081082 \tValidation Loss: 0.148158\n",
      "Earlystopping Patience Counter: 31\n",
      "Epoch: 839 \tTraining Loss: 0.081538 \tValidation Loss: 0.150227\n",
      "Earlystopping Patience Counter: 32\n",
      "Epoch: 840 \tTraining Loss: 0.084302 \tValidation Loss: 0.145661\n",
      "Epoch: 841 \tTraining Loss: 0.080245 \tValidation Loss: 0.145420\n",
      "Epoch: 842 \tTraining Loss: 0.080959 \tValidation Loss: 0.146209\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 843 \tTraining Loss: 0.080330 \tValidation Loss: 0.147226\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 844 \tTraining Loss: 0.081637 \tValidation Loss: 0.145741\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 845 \tTraining Loss: 0.080223 \tValidation Loss: 0.146663\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 846 \tTraining Loss: 0.081125 \tValidation Loss: 0.146255\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 847 \tTraining Loss: 0.082483 \tValidation Loss: 0.146243\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 848 \tTraining Loss: 0.080969 \tValidation Loss: 0.146846\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 849 \tTraining Loss: 0.080651 \tValidation Loss: 0.146175\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 850 \tTraining Loss: 0.080050 \tValidation Loss: 0.146975\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 851 \tTraining Loss: 0.079951 \tValidation Loss: 0.147569\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 852 \tTraining Loss: 0.079752 \tValidation Loss: 0.146626\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 853 \tTraining Loss: 0.081228 \tValidation Loss: 0.147823\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 854 \tTraining Loss: 0.081893 \tValidation Loss: 0.148166\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 855 \tTraining Loss: 0.079628 \tValidation Loss: 0.149031\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 856 \tTraining Loss: 0.080013 \tValidation Loss: 0.147596\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 857 \tTraining Loss: 0.080115 \tValidation Loss: 0.146685\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 858 \tTraining Loss: 0.079406 \tValidation Loss: 0.147468\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 859 \tTraining Loss: 0.079715 \tValidation Loss: 0.147037\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 860 \tTraining Loss: 0.079714 \tValidation Loss: 0.146525\n",
      "Earlystopping Patience Counter: 19\n",
      "Epoch: 861 \tTraining Loss: 0.079010 \tValidation Loss: 0.146761\n",
      "Earlystopping Patience Counter: 20\n",
      "Epoch: 862 \tTraining Loss: 0.078858 \tValidation Loss: 0.146702\n",
      "Earlystopping Patience Counter: 21\n",
      "Epoch: 863 \tTraining Loss: 0.079407 \tValidation Loss: 0.146175\n",
      "Earlystopping Patience Counter: 22\n",
      "Epoch: 864 \tTraining Loss: 0.079491 \tValidation Loss: 0.146567\n",
      "Earlystopping Patience Counter: 23\n",
      "Epoch: 865 \tTraining Loss: 0.079544 \tValidation Loss: 0.147288\n",
      "Earlystopping Patience Counter: 24\n",
      "Epoch: 866 \tTraining Loss: 0.078912 \tValidation Loss: 0.147498\n",
      "Earlystopping Patience Counter: 25\n",
      "Epoch: 867 \tTraining Loss: 0.078548 \tValidation Loss: 0.146156\n",
      "Earlystopping Patience Counter: 26\n",
      "Epoch: 868 \tTraining Loss: 0.078369 \tValidation Loss: 0.146589\n",
      "Earlystopping Patience Counter: 27\n",
      "Epoch: 869 \tTraining Loss: 0.079306 \tValidation Loss: 0.146704\n",
      "Earlystopping Patience Counter: 28\n",
      "Epoch: 870 \tTraining Loss: 0.082891 \tValidation Loss: 0.149698\n",
      "Earlystopping Patience Counter: 29\n",
      "Epoch: 871 \tTraining Loss: 0.079107 \tValidation Loss: 0.145652\n",
      "Earlystopping Patience Counter: 30\n",
      "Epoch: 872 \tTraining Loss: 0.078608 \tValidation Loss: 0.145331\n",
      "Epoch: 873 \tTraining Loss: 0.078581 \tValidation Loss: 0.145290\n",
      "Epoch: 874 \tTraining Loss: 0.078285 \tValidation Loss: 0.146013\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 875 \tTraining Loss: 0.078289 \tValidation Loss: 0.147444\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 876 \tTraining Loss: 0.077768 \tValidation Loss: 0.146240\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 877 \tTraining Loss: 0.079432 \tValidation Loss: 0.145978\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 878 \tTraining Loss: 0.078506 \tValidation Loss: 0.146167\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 879 \tTraining Loss: 0.078612 \tValidation Loss: 0.146270\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 880 \tTraining Loss: 0.077448 \tValidation Loss: 0.145711\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 881 \tTraining Loss: 0.079380 \tValidation Loss: 0.146909\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 882 \tTraining Loss: 0.077798 \tValidation Loss: 0.146388\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 883 \tTraining Loss: 0.077441 \tValidation Loss: 0.147181\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 884 \tTraining Loss: 0.077457 \tValidation Loss: 0.145558\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 885 \tTraining Loss: 0.077189 \tValidation Loss: 0.147068\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 886 \tTraining Loss: 0.077626 \tValidation Loss: 0.146725\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 887 \tTraining Loss: 0.078449 \tValidation Loss: 0.147447\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 888 \tTraining Loss: 0.077074 \tValidation Loss: 0.146094\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 889 \tTraining Loss: 0.078043 \tValidation Loss: 0.149766\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 890 \tTraining Loss: 0.077415 \tValidation Loss: 0.146476\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 891 \tTraining Loss: 0.077563 \tValidation Loss: 0.146691\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 892 \tTraining Loss: 0.076811 \tValidation Loss: 0.145865\n",
      "Earlystopping Patience Counter: 19\n",
      "Epoch: 893 \tTraining Loss: 0.076458 \tValidation Loss: 0.146765\n",
      "Earlystopping Patience Counter: 20\n",
      "Epoch: 894 \tTraining Loss: 0.076751 \tValidation Loss: 0.145644\n",
      "Earlystopping Patience Counter: 21\n",
      "Epoch: 895 \tTraining Loss: 0.076930 \tValidation Loss: 0.145936\n",
      "Earlystopping Patience Counter: 22\n",
      "Epoch: 896 \tTraining Loss: 0.077014 \tValidation Loss: 0.145710\n",
      "Earlystopping Patience Counter: 23\n",
      "Epoch: 897 \tTraining Loss: 0.076727 \tValidation Loss: 0.145351\n",
      "Earlystopping Patience Counter: 24\n",
      "Epoch: 898 \tTraining Loss: 0.077264 \tValidation Loss: 0.146056\n",
      "Earlystopping Patience Counter: 25\n",
      "Epoch: 899 \tTraining Loss: 0.076261 \tValidation Loss: 0.146630\n",
      "Earlystopping Patience Counter: 26\n",
      "Epoch: 900 \tTraining Loss: 0.076937 \tValidation Loss: 0.146652\n",
      "Earlystopping Patience Counter: 27\n",
      "Epoch: 901 \tTraining Loss: 0.076273 \tValidation Loss: 0.146082\n",
      "Earlystopping Patience Counter: 28\n",
      "Epoch: 902 \tTraining Loss: 0.076149 \tValidation Loss: 0.145562\n",
      "Earlystopping Patience Counter: 29\n",
      "Epoch: 903 \tTraining Loss: 0.076058 \tValidation Loss: 0.145246\n",
      "Epoch: 904 \tTraining Loss: 0.075473 \tValidation Loss: 0.145991\n",
      "Earlystopping Patience Counter: 1\n",
      "Epoch: 905 \tTraining Loss: 0.076283 \tValidation Loss: 0.145866\n",
      "Earlystopping Patience Counter: 2\n",
      "Epoch: 906 \tTraining Loss: 0.075352 \tValidation Loss: 0.145312\n",
      "Earlystopping Patience Counter: 3\n",
      "Epoch: 907 \tTraining Loss: 0.075272 \tValidation Loss: 0.146040\n",
      "Earlystopping Patience Counter: 4\n",
      "Epoch: 908 \tTraining Loss: 0.075476 \tValidation Loss: 0.146514\n",
      "Earlystopping Patience Counter: 5\n",
      "Epoch: 909 \tTraining Loss: 0.075161 \tValidation Loss: 0.146172\n",
      "Earlystopping Patience Counter: 6\n",
      "Epoch: 910 \tTraining Loss: 0.076868 \tValidation Loss: 0.151333\n",
      "Earlystopping Patience Counter: 7\n",
      "Epoch: 911 \tTraining Loss: 0.075131 \tValidation Loss: 0.147210\n",
      "Earlystopping Patience Counter: 8\n",
      "Epoch: 912 \tTraining Loss: 0.074820 \tValidation Loss: 0.148971\n",
      "Earlystopping Patience Counter: 9\n",
      "Epoch: 913 \tTraining Loss: 0.075722 \tValidation Loss: 0.147387\n",
      "Earlystopping Patience Counter: 10\n",
      "Epoch: 914 \tTraining Loss: 0.075080 \tValidation Loss: 0.146515\n",
      "Earlystopping Patience Counter: 11\n",
      "Epoch: 915 \tTraining Loss: 0.075445 \tValidation Loss: 0.146468\n",
      "Earlystopping Patience Counter: 12\n",
      "Epoch: 916 \tTraining Loss: 0.075317 \tValidation Loss: 0.145393\n",
      "Earlystopping Patience Counter: 13\n",
      "Epoch: 917 \tTraining Loss: 0.075120 \tValidation Loss: 0.145743\n",
      "Earlystopping Patience Counter: 14\n",
      "Epoch: 918 \tTraining Loss: 0.074894 \tValidation Loss: 0.145900\n",
      "Earlystopping Patience Counter: 15\n",
      "Epoch: 919 \tTraining Loss: 0.074814 \tValidation Loss: 0.145617\n",
      "Earlystopping Patience Counter: 16\n",
      "Epoch: 920 \tTraining Loss: 0.074807 \tValidation Loss: 0.146311\n",
      "Earlystopping Patience Counter: 17\n",
      "Epoch: 921 \tTraining Loss: 0.074368 \tValidation Loss: 0.145924\n",
      "Earlystopping Patience Counter: 18\n",
      "Epoch: 922 \tTraining Loss: 0.074528 \tValidation Loss: 0.147668\n",
      "Earlystopping Patience Counter: 19\n",
      "Epoch: 923 \tTraining Loss: 0.074309 \tValidation Loss: 0.150512\n",
      "Earlystopping Patience Counter: 20\n",
      "Epoch: 924 \tTraining Loss: 0.075586 \tValidation Loss: 0.147955\n",
      "Earlystopping Patience Counter: 21\n",
      "Epoch: 925 \tTraining Loss: 0.075046 \tValidation Loss: 0.148424\n",
      "Earlystopping Patience Counter: 22\n",
      "Epoch: 926 \tTraining Loss: 0.074429 \tValidation Loss: 0.146039\n",
      "Earlystopping Patience Counter: 23\n",
      "Epoch: 927 \tTraining Loss: 0.073692 \tValidation Loss: 0.147313\n",
      "Earlystopping Patience Counter: 24\n",
      "Epoch: 928 \tTraining Loss: 0.073826 \tValidation Loss: 0.148834\n",
      "Earlystopping Patience Counter: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 929 \tTraining Loss: 0.074119 \tValidation Loss: 0.146462\n",
      "Earlystopping Patience Counter: 26\n",
      "Epoch: 930 \tTraining Loss: 0.074770 \tValidation Loss: 0.148205\n",
      "Earlystopping Patience Counter: 27\n",
      "Epoch: 931 \tTraining Loss: 0.074219 \tValidation Loss: 0.147022\n",
      "Earlystopping Patience Counter: 28\n",
      "Epoch: 932 \tTraining Loss: 0.075823 \tValidation Loss: 0.146316\n",
      "Earlystopping Patience Counter: 29\n",
      "Epoch: 933 \tTraining Loss: 0.073666 \tValidation Loss: 0.148765\n",
      "Earlystopping Patience Counter: 30\n",
      "Epoch: 934 \tTraining Loss: 0.073468 \tValidation Loss: 0.146940\n",
      "Earlystopping Patience Counter: 31\n",
      "Epoch: 935 \tTraining Loss: 0.076052 \tValidation Loss: 0.150055\n",
      "Earlystopping Patience Counter: 32\n",
      "Epoch: 936 \tTraining Loss: 0.073972 \tValidation Loss: 0.147818\n",
      "Earlystopping Patience Counter: 33\n",
      "Epoch: 937 \tTraining Loss: 0.073447 \tValidation Loss: 0.146226\n",
      "Earlystopping Patience Counter: 34\n",
      "Epoch: 938 \tTraining Loss: 0.074072 \tValidation Loss: 0.146936\n",
      "Earlystopping Patience Counter: 35\n",
      "Epoch: 939 \tTraining Loss: 0.072669 \tValidation Loss: 0.146768\n",
      "Earlystopping Patience Counter: 36\n",
      "Epoch: 940 \tTraining Loss: 0.073597 \tValidation Loss: 0.146931\n",
      "Earlystopping Patience Counter: 37\n",
      "Epoch: 941 \tTraining Loss: 0.073712 \tValidation Loss: 0.148185\n",
      "Earlystopping Patience Counter: 38\n",
      "Epoch: 942 \tTraining Loss: 0.073498 \tValidation Loss: 0.146376\n",
      "Earlystopping Patience Counter: 39\n",
      "Epoch: 943 \tTraining Loss: 0.073364 \tValidation Loss: 0.145986\n",
      "Earlystopping Patience Counter: 40\n",
      "Epoch: 944 \tTraining Loss: 0.076853 \tValidation Loss: 0.146012\n",
      "Earlystopping Patience Counter: 41\n",
      "Epoch: 945 \tTraining Loss: 0.072606 \tValidation Loss: 0.146365\n",
      "Earlystopping Patience Counter: 42\n",
      "Epoch: 946 \tTraining Loss: 0.074604 \tValidation Loss: 0.149502\n",
      "Earlystopping Patience Counter: 43\n",
      "Epoch: 947 \tTraining Loss: 0.073311 \tValidation Loss: 0.147324\n",
      "Earlystopping Patience Counter: 44\n",
      "Epoch: 948 \tTraining Loss: 0.073077 \tValidation Loss: 0.146331\n",
      "Earlystopping Patience Counter: 45\n",
      "Epoch: 949 \tTraining Loss: 0.074486 \tValidation Loss: 0.147194\n",
      "Earlystopping Patience Counter: 46\n",
      "Epoch: 950 \tTraining Loss: 0.072853 \tValidation Loss: 0.148383\n",
      "Earlystopping Patience Counter: 47\n",
      "Epoch: 951 \tTraining Loss: 0.072435 \tValidation Loss: 0.146431\n",
      "Earlystopping Patience Counter: 48\n",
      "Epoch: 952 \tTraining Loss: 0.072342 \tValidation Loss: 0.148041\n",
      "Earlystopping Patience Counter: 49\n",
      "Epoch: 953 \tTraining Loss: 0.072817 \tValidation Loss: 0.146553\n",
      "Earlystopping Patience Counter: 50\n",
      "Epoch: 954 \tTraining Loss: 0.072800 \tValidation Loss: 0.145914\n",
      "Earlystopping Patience Counter: 51\n",
      "Epoch: 955 \tTraining Loss: 0.071622 \tValidation Loss: 0.148048\n",
      "Earlystopping Patience Counter: 52\n",
      "Epoch: 956 \tTraining Loss: 0.072535 \tValidation Loss: 0.151243\n",
      "Earlystopping Patience Counter: 53\n",
      "Epoch: 957 \tTraining Loss: 0.073428 \tValidation Loss: 0.147546\n",
      "Earlystopping Patience Counter: 54\n",
      "Epoch: 958 \tTraining Loss: 0.071947 \tValidation Loss: 0.146983\n",
      "Earlystopping Patience Counter: 55\n",
      "Epoch: 959 \tTraining Loss: 0.072767 \tValidation Loss: 0.147180\n",
      "Earlystopping Patience Counter: 56\n",
      "Epoch: 960 \tTraining Loss: 0.073897 \tValidation Loss: 0.148192\n",
      "Earlystopping Patience Counter: 57\n",
      "Epoch: 961 \tTraining Loss: 0.072009 \tValidation Loss: 0.147024\n",
      "Earlystopping Patience Counter: 58\n",
      "Epoch: 962 \tTraining Loss: 0.071726 \tValidation Loss: 0.147888\n",
      "Earlystopping Patience Counter: 59\n",
      "Epoch: 963 \tTraining Loss: 0.072340 \tValidation Loss: 0.147193\n",
      "Earlystopping Patience Counter: 60\n",
      "Epoch: 964 \tTraining Loss: 0.071649 \tValidation Loss: 0.148506\n",
      "Earlystopping Patience Counter: 61\n",
      "Epoch: 965 \tTraining Loss: 0.071309 \tValidation Loss: 0.146860\n",
      "Earlystopping Patience Counter: 62\n",
      "Epoch: 966 \tTraining Loss: 0.071008 \tValidation Loss: 0.146910\n",
      "Earlystopping Patience Counter: 63\n",
      "Epoch: 967 \tTraining Loss: 0.071675 \tValidation Loss: 0.147354\n",
      "Earlystopping Patience Counter: 64\n",
      "Epoch: 968 \tTraining Loss: 0.071157 \tValidation Loss: 0.146768\n",
      "Earlystopping Patience Counter: 65\n",
      "Epoch: 969 \tTraining Loss: 0.071783 \tValidation Loss: 0.146336\n",
      "Earlystopping Patience Counter: 66\n",
      "Epoch: 970 \tTraining Loss: 0.071262 \tValidation Loss: 0.147228\n",
      "Earlystopping Patience Counter: 67\n",
      "Epoch: 971 \tTraining Loss: 0.071697 \tValidation Loss: 0.147420\n",
      "Earlystopping Patience Counter: 68\n",
      "Epoch: 972 \tTraining Loss: 0.071775 \tValidation Loss: 0.148594\n",
      "Earlystopping Patience Counter: 69\n",
      "Epoch: 973 \tTraining Loss: 0.071080 \tValidation Loss: 0.146768\n",
      "Earlystopping Patience Counter: 70\n",
      "Epoch: 974 \tTraining Loss: 0.071291 \tValidation Loss: 0.146804\n",
      "Earlystopping Patience Counter: 71\n",
      "Epoch: 975 \tTraining Loss: 0.070739 \tValidation Loss: 0.147097\n",
      "Earlystopping Patience Counter: 72\n",
      "Epoch: 976 \tTraining Loss: 0.070930 \tValidation Loss: 0.147392\n",
      "Earlystopping Patience Counter: 73\n",
      "Epoch: 977 \tTraining Loss: 0.071213 \tValidation Loss: 0.147653\n",
      "Earlystopping Patience Counter: 74\n",
      "Epoch: 978 \tTraining Loss: 0.070849 \tValidation Loss: 0.147219\n",
      "Earlystopping Patience Counter: 75\n",
      "Epoch: 979 \tTraining Loss: 0.072629 \tValidation Loss: 0.149552\n",
      "Earlystopping Patience Counter: 76\n",
      "Epoch: 980 \tTraining Loss: 0.070624 \tValidation Loss: 0.148176\n",
      "Earlystopping Patience Counter: 77\n",
      "Epoch: 981 \tTraining Loss: 0.070521 \tValidation Loss: 0.149319\n",
      "Earlystopping Patience Counter: 78\n",
      "Epoch: 982 \tTraining Loss: 0.070349 \tValidation Loss: 0.147437\n",
      "Earlystopping Patience Counter: 79\n",
      "Epoch: 983 \tTraining Loss: 0.071161 \tValidation Loss: 0.146858\n",
      "Earlystopping Patience Counter: 80\n",
      "Epoch: 984 \tTraining Loss: 0.069455 \tValidation Loss: 0.148223\n",
      "Earlystopping Patience Counter: 81\n",
      "Epoch: 985 \tTraining Loss: 0.073237 \tValidation Loss: 0.147779\n",
      "Earlystopping Patience Counter: 82\n",
      "Epoch: 986 \tTraining Loss: 0.070828 \tValidation Loss: 0.147086\n",
      "Earlystopping Patience Counter: 83\n",
      "Epoch: 987 \tTraining Loss: 0.070573 \tValidation Loss: 0.146935\n",
      "Earlystopping Patience Counter: 84\n",
      "Epoch: 988 \tTraining Loss: 0.069999 \tValidation Loss: 0.146058\n",
      "Earlystopping Patience Counter: 85\n",
      "Epoch: 989 \tTraining Loss: 0.073350 \tValidation Loss: 0.146325\n",
      "Earlystopping Patience Counter: 86\n",
      "Epoch: 990 \tTraining Loss: 0.070162 \tValidation Loss: 0.147042\n",
      "Earlystopping Patience Counter: 87\n",
      "Epoch: 991 \tTraining Loss: 0.070240 \tValidation Loss: 0.145638\n",
      "Earlystopping Patience Counter: 88\n",
      "Epoch: 992 \tTraining Loss: 0.070441 \tValidation Loss: 0.146950\n",
      "Earlystopping Patience Counter: 89\n",
      "Epoch: 993 \tTraining Loss: 0.069186 \tValidation Loss: 0.145875\n",
      "Earlystopping Patience Counter: 90\n",
      "Epoch: 994 \tTraining Loss: 0.068985 \tValidation Loss: 0.147165\n",
      "Earlystopping Patience Counter: 91\n",
      "Epoch: 995 \tTraining Loss: 0.070700 \tValidation Loss: 0.149579\n",
      "Earlystopping Patience Counter: 92\n",
      "Epoch: 996 \tTraining Loss: 0.072234 \tValidation Loss: 0.152577\n",
      "Earlystopping Patience Counter: 93\n",
      "Epoch: 997 \tTraining Loss: 0.071370 \tValidation Loss: 0.147274\n",
      "Earlystopping Patience Counter: 94\n",
      "Epoch: 998 \tTraining Loss: 0.072031 \tValidation Loss: 0.147270\n",
      "Earlystopping Patience Counter: 95\n",
      "Epoch: 999 \tTraining Loss: 0.068760 \tValidation Loss: 0.149242\n",
      "Earlystopping Patience Counter: 96\n",
      "Epoch: 1000 \tTraining Loss: 0.068621 \tValidation Loss: 0.147378\n",
      "Earlystopping Patience Counter: 97\n",
      "Epoch: 1001 \tTraining Loss: 0.069705 \tValidation Loss: 0.147899\n",
      "Earlystopping Patience Counter: 98\n",
      "Epoch: 1002 \tTraining Loss: 0.068977 \tValidation Loss: 0.147257\n",
      "Earlystopping Patience Counter: 99\n",
      "Epoch: 1003 \tTraining Loss: 0.068474 \tValidation Loss: 0.152103\n",
      "Earlystopping Patience Counter: 100\n",
      "Epoch: 1004 \tTraining Loss: 0.068999 \tValidation Loss: 0.147373\n",
      "Earlystopping Patience Counter: 101\n",
      "Epoch: 1005 \tTraining Loss: 0.068898 \tValidation Loss: 0.147290\n",
      "Earlystopping Patience Counter: 102\n",
      "Epoch: 1006 \tTraining Loss: 0.069792 \tValidation Loss: 0.150611\n",
      "Earlystopping Patience Counter: 103\n",
      "Epoch: 1007 \tTraining Loss: 0.068583 \tValidation Loss: 0.148592\n",
      "Earlystopping Patience Counter: 104\n",
      "Epoch: 1008 \tTraining Loss: 0.068658 \tValidation Loss: 0.147820\n",
      "Earlystopping Patience Counter: 105\n",
      "Epoch: 1009 \tTraining Loss: 0.068374 \tValidation Loss: 0.147315\n",
      "Earlystopping Patience Counter: 106\n",
      "Epoch: 1010 \tTraining Loss: 0.068022 \tValidation Loss: 0.147486\n",
      "Earlystopping Patience Counter: 107\n",
      "Epoch: 1011 \tTraining Loss: 0.068209 \tValidation Loss: 0.146687\n",
      "Earlystopping Patience Counter: 108\n",
      "Epoch: 1012 \tTraining Loss: 0.067254 \tValidation Loss: 0.150136\n",
      "Earlystopping Patience Counter: 109\n",
      "Epoch: 1013 \tTraining Loss: 0.068084 \tValidation Loss: 0.148286\n",
      "Earlystopping Patience Counter: 110\n",
      "Epoch: 1014 \tTraining Loss: 0.067777 \tValidation Loss: 0.147284\n",
      "Earlystopping Patience Counter: 111\n",
      "Epoch: 1015 \tTraining Loss: 0.067668 \tValidation Loss: 0.148008\n",
      "Earlystopping Patience Counter: 112\n",
      "Epoch: 1016 \tTraining Loss: 0.068154 \tValidation Loss: 0.146894\n",
      "Earlystopping Patience Counter: 113\n",
      "Epoch: 1017 \tTraining Loss: 0.067833 \tValidation Loss: 0.148994\n",
      "Earlystopping Patience Counter: 114\n",
      "Epoch: 1018 \tTraining Loss: 0.068261 \tValidation Loss: 0.148517\n",
      "Earlystopping Patience Counter: 115\n",
      "Epoch: 1019 \tTraining Loss: 0.067697 \tValidation Loss: 0.148032\n",
      "Earlystopping Patience Counter: 116\n",
      "Epoch: 1020 \tTraining Loss: 0.067867 \tValidation Loss: 0.147566\n",
      "Earlystopping Patience Counter: 117\n",
      "Epoch: 1021 \tTraining Loss: 0.068614 \tValidation Loss: 0.151581\n",
      "Earlystopping Patience Counter: 118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1022 \tTraining Loss: 0.067501 \tValidation Loss: 0.147258\n",
      "Earlystopping Patience Counter: 119\n",
      "Epoch: 1023 \tTraining Loss: 0.067441 \tValidation Loss: 0.147019\n",
      "Earlystopping Patience Counter: 120\n",
      "Epoch: 1024 \tTraining Loss: 0.067057 \tValidation Loss: 0.147865\n",
      "Earlystopping Patience Counter: 121\n",
      "Epoch: 1025 \tTraining Loss: 0.069468 \tValidation Loss: 0.154262\n",
      "Earlystopping Patience Counter: 122\n",
      "Epoch: 1026 \tTraining Loss: 0.067779 \tValidation Loss: 0.148414\n",
      "Earlystopping Patience Counter: 123\n",
      "Epoch: 1027 \tTraining Loss: 0.067407 \tValidation Loss: 0.147146\n",
      "Earlystopping Patience Counter: 124\n",
      "Epoch: 1028 \tTraining Loss: 0.068257 \tValidation Loss: 0.146353\n",
      "Earlystopping Patience Counter: 125\n",
      "Epoch: 1029 \tTraining Loss: 0.066741 \tValidation Loss: 0.146070\n",
      "Earlystopping Patience Counter: 126\n",
      "Epoch: 1030 \tTraining Loss: 0.066949 \tValidation Loss: 0.147306\n",
      "Earlystopping Patience Counter: 127\n",
      "Epoch: 1031 \tTraining Loss: 0.067797 \tValidation Loss: 0.148905\n",
      "Earlystopping Patience Counter: 128\n",
      "Epoch: 1032 \tTraining Loss: 0.067837 \tValidation Loss: 0.148442\n",
      "Earlystopping Patience Counter: 129\n",
      "Epoch: 1033 \tTraining Loss: 0.066887 \tValidation Loss: 0.147100\n",
      "Earlystopping Patience Counter: 130\n",
      "Epoch: 1034 \tTraining Loss: 0.067020 \tValidation Loss: 0.146410\n",
      "Earlystopping Patience Counter: 131\n",
      "Epoch: 1035 \tTraining Loss: 0.066675 \tValidation Loss: 0.148190\n",
      "Earlystopping Patience Counter: 132\n",
      "Epoch: 1036 \tTraining Loss: 0.073651 \tValidation Loss: 0.150046\n",
      "Earlystopping Patience Counter: 133\n",
      "Epoch: 1037 \tTraining Loss: 0.067216 \tValidation Loss: 0.147449\n",
      "Earlystopping Patience Counter: 134\n",
      "Epoch: 1038 \tTraining Loss: 0.066932 \tValidation Loss: 0.147341\n",
      "Earlystopping Patience Counter: 135\n",
      "Epoch: 1039 \tTraining Loss: 0.066779 \tValidation Loss: 0.149556\n",
      "Earlystopping Patience Counter: 136\n",
      "Epoch: 1040 \tTraining Loss: 0.067174 \tValidation Loss: 0.148174\n",
      "Earlystopping Patience Counter: 137\n",
      "Epoch: 1041 \tTraining Loss: 0.066150 \tValidation Loss: 0.149897\n",
      "Earlystopping Patience Counter: 138\n",
      "Epoch: 1042 \tTraining Loss: 0.066249 \tValidation Loss: 0.148959\n",
      "Earlystopping Patience Counter: 139\n",
      "Epoch: 1043 \tTraining Loss: 0.066867 \tValidation Loss: 0.147402\n",
      "Earlystopping Patience Counter: 140\n",
      "Epoch: 1044 \tTraining Loss: 0.067067 \tValidation Loss: 0.147029\n",
      "Earlystopping Patience Counter: 141\n",
      "Epoch: 1045 \tTraining Loss: 0.070033 \tValidation Loss: 0.147365\n",
      "Earlystopping Patience Counter: 142\n",
      "Epoch: 1046 \tTraining Loss: 0.066011 \tValidation Loss: 0.148044\n",
      "Earlystopping Patience Counter: 143\n",
      "Epoch: 1047 \tTraining Loss: 0.066135 \tValidation Loss: 0.153298\n",
      "Earlystopping Patience Counter: 144\n",
      "Epoch: 1048 \tTraining Loss: 0.066569 \tValidation Loss: 0.147383\n",
      "Earlystopping Patience Counter: 145\n",
      "Epoch: 1049 \tTraining Loss: 0.065875 \tValidation Loss: 0.147431\n",
      "Earlystopping Patience Counter: 146\n",
      "Epoch: 1050 \tTraining Loss: 0.066015 \tValidation Loss: 0.147613\n",
      "Earlystopping Patience Counter: 147\n",
      "Epoch: 1051 \tTraining Loss: 0.065758 \tValidation Loss: 0.149058\n",
      "Earlystopping Patience Counter: 148\n",
      "Epoch: 1052 \tTraining Loss: 0.065661 \tValidation Loss: 0.148561\n",
      "Earlystopping Patience Counter: 149\n",
      "Epoch: 1053 \tTraining Loss: 0.065611 \tValidation Loss: 0.155422\n",
      "Earlystopping Patience Counter: 150\n",
      "Epoch: 1054 \tTraining Loss: 0.066777 \tValidation Loss: 0.149401\n",
      "Earlystopping Patience Counter: 151\n",
      "Epoch: 1055 \tTraining Loss: 0.066220 \tValidation Loss: 0.147901\n",
      "Earlystopping Patience Counter: 152\n",
      "Epoch: 1056 \tTraining Loss: 0.065526 \tValidation Loss: 0.147610\n",
      "Earlystopping Patience Counter: 153\n",
      "Epoch: 1057 \tTraining Loss: 0.066245 \tValidation Loss: 0.151120\n",
      "Earlystopping Patience Counter: 154\n",
      "Epoch: 1058 \tTraining Loss: 0.065628 \tValidation Loss: 0.149559\n",
      "Earlystopping Patience Counter: 155\n",
      "Epoch: 1059 \tTraining Loss: 0.064927 \tValidation Loss: 0.150283\n",
      "Earlystopping Patience Counter: 156\n",
      "Epoch: 1060 \tTraining Loss: 0.065216 \tValidation Loss: 0.148230\n",
      "Earlystopping Patience Counter: 157\n",
      "Epoch: 1061 \tTraining Loss: 0.064987 \tValidation Loss: 0.148288\n",
      "Earlystopping Patience Counter: 158\n",
      "Epoch: 1062 \tTraining Loss: 0.066060 \tValidation Loss: 0.146797\n",
      "Earlystopping Patience Counter: 159\n",
      "Epoch: 1063 \tTraining Loss: 0.065331 \tValidation Loss: 0.147341\n",
      "Earlystopping Patience Counter: 160\n",
      "Epoch: 1064 \tTraining Loss: 0.065302 \tValidation Loss: 0.147465\n",
      "Earlystopping Patience Counter: 161\n",
      "Epoch: 1065 \tTraining Loss: 0.064930 \tValidation Loss: 0.148300\n",
      "Earlystopping Patience Counter: 162\n",
      "Epoch: 1066 \tTraining Loss: 0.064461 \tValidation Loss: 0.150034\n",
      "Earlystopping Patience Counter: 163\n",
      "Epoch: 1067 \tTraining Loss: 0.064104 \tValidation Loss: 0.147792\n",
      "Earlystopping Patience Counter: 164\n",
      "Epoch: 1068 \tTraining Loss: 0.064728 \tValidation Loss: 0.150883\n",
      "Earlystopping Patience Counter: 165\n",
      "Epoch: 1069 \tTraining Loss: 0.065002 \tValidation Loss: 0.147548\n",
      "Earlystopping Patience Counter: 166\n",
      "Epoch: 1070 \tTraining Loss: 0.064282 \tValidation Loss: 0.148373\n",
      "Earlystopping Patience Counter: 167\n",
      "Epoch: 1071 \tTraining Loss: 0.064965 \tValidation Loss: 0.147938\n",
      "Earlystopping Patience Counter: 168\n",
      "Epoch: 1072 \tTraining Loss: 0.064525 \tValidation Loss: 0.148700\n",
      "Earlystopping Patience Counter: 169\n",
      "Epoch: 1073 \tTraining Loss: 0.064712 \tValidation Loss: 0.148216\n",
      "Earlystopping Patience Counter: 170\n",
      "Epoch: 1074 \tTraining Loss: 0.064942 \tValidation Loss: 0.148138\n",
      "Earlystopping Patience Counter: 171\n",
      "Epoch: 1075 \tTraining Loss: 0.064635 \tValidation Loss: 0.148318\n",
      "Earlystopping Patience Counter: 172\n",
      "Epoch: 1076 \tTraining Loss: 0.064190 \tValidation Loss: 0.148843\n",
      "Earlystopping Patience Counter: 173\n",
      "Epoch: 1077 \tTraining Loss: 0.064352 \tValidation Loss: 0.148390\n",
      "Earlystopping Patience Counter: 174\n",
      "Epoch: 1078 \tTraining Loss: 0.063984 \tValidation Loss: 0.150791\n",
      "Earlystopping Patience Counter: 175\n",
      "Epoch: 1079 \tTraining Loss: 0.064311 \tValidation Loss: 0.148513\n",
      "Earlystopping Patience Counter: 176\n",
      "Epoch: 1080 \tTraining Loss: 0.064091 \tValidation Loss: 0.151437\n",
      "Earlystopping Patience Counter: 177\n",
      "Epoch: 1081 \tTraining Loss: 0.063365 \tValidation Loss: 0.150259\n",
      "Earlystopping Patience Counter: 178\n",
      "Epoch: 1082 \tTraining Loss: 0.064611 \tValidation Loss: 0.148588\n",
      "Earlystopping Patience Counter: 179\n",
      "Epoch: 1083 \tTraining Loss: 0.067026 \tValidation Loss: 0.146636\n",
      "Earlystopping Patience Counter: 180\n",
      "Epoch: 1084 \tTraining Loss: 0.063993 \tValidation Loss: 0.147751\n",
      "Earlystopping Patience Counter: 181\n",
      "Epoch: 1085 \tTraining Loss: 0.063776 \tValidation Loss: 0.147938\n",
      "Earlystopping Patience Counter: 182\n",
      "Epoch: 1086 \tTraining Loss: 0.063217 \tValidation Loss: 0.149398\n",
      "Earlystopping Patience Counter: 183\n",
      "Epoch: 1087 \tTraining Loss: 0.063278 \tValidation Loss: 0.148291\n",
      "Earlystopping Patience Counter: 184\n",
      "Epoch: 1088 \tTraining Loss: 0.063878 \tValidation Loss: 0.147616\n",
      "Earlystopping Patience Counter: 185\n",
      "Epoch: 1089 \tTraining Loss: 0.063097 \tValidation Loss: 0.148432\n",
      "Earlystopping Patience Counter: 186\n",
      "Epoch: 1090 \tTraining Loss: 0.063920 \tValidation Loss: 0.149909\n",
      "Earlystopping Patience Counter: 187\n",
      "Epoch: 1091 \tTraining Loss: 0.063490 \tValidation Loss: 0.150270\n",
      "Earlystopping Patience Counter: 188\n",
      "Epoch: 1092 \tTraining Loss: 0.063550 \tValidation Loss: 0.149389\n",
      "Earlystopping Patience Counter: 189\n",
      "Epoch: 1093 \tTraining Loss: 0.063228 \tValidation Loss: 0.148704\n",
      "Earlystopping Patience Counter: 190\n",
      "Epoch: 1094 \tTraining Loss: 0.063486 \tValidation Loss: 0.147610\n",
      "Earlystopping Patience Counter: 191\n",
      "Epoch: 1095 \tTraining Loss: 0.063499 \tValidation Loss: 0.148400\n",
      "Earlystopping Patience Counter: 192\n",
      "Epoch: 1096 \tTraining Loss: 0.062889 \tValidation Loss: 0.152357\n",
      "Earlystopping Patience Counter: 193\n",
      "Epoch: 1097 \tTraining Loss: 0.063041 \tValidation Loss: 0.149446\n",
      "Earlystopping Patience Counter: 194\n",
      "Epoch: 1098 \tTraining Loss: 0.063667 \tValidation Loss: 0.149598\n",
      "Earlystopping Patience Counter: 195\n",
      "Epoch: 1099 \tTraining Loss: 0.065802 \tValidation Loss: 0.149167\n",
      "Earlystopping Patience Counter: 196\n",
      "Epoch: 1100 \tTraining Loss: 0.063205 \tValidation Loss: 0.148211\n",
      "Earlystopping Patience Counter: 197\n",
      "Epoch: 1101 \tTraining Loss: 0.062950 \tValidation Loss: 0.149130\n",
      "Earlystopping Patience Counter: 198\n",
      "Epoch: 1102 \tTraining Loss: 0.063071 \tValidation Loss: 0.147829\n",
      "Earlystopping Patience Counter: 199\n",
      "Epoch: 1103 \tTraining Loss: 0.062484 \tValidation Loss: 0.148552\n",
      "Earlystopping Patience Counter: 200\n",
      "Epoch: 1104 \tTraining Loss: 0.062754 \tValidation Loss: 0.149261\n",
      "Earlystopping Patience Counter: 201\n",
      "Epoch: 1105 \tTraining Loss: 0.062929 \tValidation Loss: 0.147889\n",
      "Earlystopping Patience Counter: 202\n",
      "Epoch: 1106 \tTraining Loss: 0.062926 \tValidation Loss: 0.148741\n",
      "Earlystopping Patience Counter: 203\n",
      "Epoch: 1107 \tTraining Loss: 0.062369 \tValidation Loss: 0.148367\n",
      "Earlystopping Patience Counter: 204\n",
      "Epoch: 1108 \tTraining Loss: 0.065928 \tValidation Loss: 0.146403\n",
      "Earlystopping Patience Counter: 205\n",
      "Epoch: 1109 \tTraining Loss: 0.062239 \tValidation Loss: 0.153673\n",
      "Earlystopping Patience Counter: 206\n",
      "Epoch: 1110 \tTraining Loss: 0.061972 \tValidation Loss: 0.147923\n",
      "Earlystopping Patience Counter: 207\n",
      "Epoch: 1111 \tTraining Loss: 0.062969 \tValidation Loss: 0.149015\n",
      "Earlystopping Patience Counter: 208\n",
      "Epoch: 1112 \tTraining Loss: 0.062742 \tValidation Loss: 0.147480\n",
      "Earlystopping Patience Counter: 209\n",
      "Epoch: 1113 \tTraining Loss: 0.061844 \tValidation Loss: 0.148100\n",
      "Earlystopping Patience Counter: 210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1114 \tTraining Loss: 0.061821 \tValidation Loss: 0.148428\n",
      "Earlystopping Patience Counter: 211\n",
      "Epoch: 1115 \tTraining Loss: 0.063310 \tValidation Loss: 0.152060\n",
      "Earlystopping Patience Counter: 212\n",
      "Epoch: 1116 \tTraining Loss: 0.063766 \tValidation Loss: 0.149143\n",
      "Earlystopping Patience Counter: 213\n",
      "Epoch: 1117 \tTraining Loss: 0.062545 \tValidation Loss: 0.149499\n",
      "Earlystopping Patience Counter: 214\n",
      "Epoch: 1118 \tTraining Loss: 0.062054 \tValidation Loss: 0.148397\n",
      "Earlystopping Patience Counter: 215\n",
      "Epoch: 1119 \tTraining Loss: 0.062745 \tValidation Loss: 0.147965\n",
      "Earlystopping Patience Counter: 216\n",
      "Epoch: 1120 \tTraining Loss: 0.062685 \tValidation Loss: 0.148506\n",
      "Earlystopping Patience Counter: 217\n",
      "Epoch: 1121 \tTraining Loss: 0.063008 \tValidation Loss: 0.153038\n",
      "Earlystopping Patience Counter: 218\n",
      "Epoch: 1122 \tTraining Loss: 0.062875 \tValidation Loss: 0.148052\n",
      "Earlystopping Patience Counter: 219\n",
      "Epoch: 1123 \tTraining Loss: 0.061977 \tValidation Loss: 0.149635\n",
      "Earlystopping Patience Counter: 220\n",
      "Epoch: 1124 \tTraining Loss: 0.061506 \tValidation Loss: 0.149104\n",
      "Earlystopping Patience Counter: 221\n",
      "Epoch: 1125 \tTraining Loss: 0.060949 \tValidation Loss: 0.149360\n",
      "Earlystopping Patience Counter: 222\n",
      "Epoch: 1126 \tTraining Loss: 0.065315 \tValidation Loss: 0.158935\n",
      "Earlystopping Patience Counter: 223\n",
      "Epoch: 1127 \tTraining Loss: 0.061997 \tValidation Loss: 0.151247\n",
      "Earlystopping Patience Counter: 224\n",
      "Epoch: 1128 \tTraining Loss: 0.063041 \tValidation Loss: 0.150517\n",
      "Earlystopping Patience Counter: 225\n",
      "Epoch: 1129 \tTraining Loss: 0.060873 \tValidation Loss: 0.150016\n",
      "Earlystopping Patience Counter: 226\n",
      "Epoch: 1130 \tTraining Loss: 0.061569 \tValidation Loss: 0.150126\n",
      "Earlystopping Patience Counter: 227\n",
      "Epoch: 1131 \tTraining Loss: 0.061456 \tValidation Loss: 0.149661\n",
      "Earlystopping Patience Counter: 228\n",
      "Epoch: 1132 \tTraining Loss: 0.060588 \tValidation Loss: 0.148859\n",
      "Earlystopping Patience Counter: 229\n",
      "Epoch: 1133 \tTraining Loss: 0.061190 \tValidation Loss: 0.148964\n",
      "Earlystopping Patience Counter: 230\n",
      "Epoch: 1134 \tTraining Loss: 0.060851 \tValidation Loss: 0.149321\n",
      "Earlystopping Patience Counter: 231\n",
      "Epoch: 1135 \tTraining Loss: 0.060796 \tValidation Loss: 0.150516\n",
      "Earlystopping Patience Counter: 232\n",
      "Epoch: 1136 \tTraining Loss: 0.060867 \tValidation Loss: 0.152696\n",
      "Earlystopping Patience Counter: 233\n",
      "Epoch: 1137 \tTraining Loss: 0.060454 \tValidation Loss: 0.151868\n",
      "Earlystopping Patience Counter: 234\n",
      "Epoch: 1138 \tTraining Loss: 0.060908 \tValidation Loss: 0.150242\n",
      "Earlystopping Patience Counter: 235\n",
      "Epoch: 1139 \tTraining Loss: 0.060906 \tValidation Loss: 0.152372\n",
      "Earlystopping Patience Counter: 236\n",
      "Epoch: 1140 \tTraining Loss: 0.060737 \tValidation Loss: 0.149049\n",
      "Earlystopping Patience Counter: 237\n",
      "Epoch: 1141 \tTraining Loss: 0.059559 \tValidation Loss: 0.152707\n",
      "Earlystopping Patience Counter: 238\n",
      "Epoch: 1142 \tTraining Loss: 0.061555 \tValidation Loss: 0.150000\n",
      "Earlystopping Patience Counter: 239\n",
      "Epoch: 1143 \tTraining Loss: 0.062126 \tValidation Loss: 0.155282\n",
      "Earlystopping Patience Counter: 240\n",
      "Epoch: 1144 \tTraining Loss: 0.060605 \tValidation Loss: 0.149972\n",
      "Earlystopping Patience Counter: 241\n",
      "Epoch: 1145 \tTraining Loss: 0.060166 \tValidation Loss: 0.149705\n",
      "Earlystopping Patience Counter: 242\n",
      "Epoch: 1146 \tTraining Loss: 0.059958 \tValidation Loss: 0.148726\n",
      "Earlystopping Patience Counter: 243\n",
      "Epoch: 1147 \tTraining Loss: 0.059641 \tValidation Loss: 0.149130\n",
      "Earlystopping Patience Counter: 244\n",
      "Epoch: 1148 \tTraining Loss: 0.060294 \tValidation Loss: 0.149086\n",
      "Earlystopping Patience Counter: 245\n",
      "Epoch: 1149 \tTraining Loss: 0.059783 \tValidation Loss: 0.149710\n",
      "Earlystopping Patience Counter: 246\n",
      "Epoch: 1150 \tTraining Loss: 0.061158 \tValidation Loss: 0.150613\n",
      "Earlystopping Patience Counter: 247\n",
      "Epoch: 1151 \tTraining Loss: 0.059983 \tValidation Loss: 0.154458\n",
      "Earlystopping Patience Counter: 248\n",
      "Epoch: 1152 \tTraining Loss: 0.059150 \tValidation Loss: 0.152517\n",
      "Earlystopping Patience Counter: 249\n",
      "Epoch: 1153 \tTraining Loss: 0.059953 \tValidation Loss: 0.150368\n",
      "Earlystopping Patience Counter: 250\n",
      "Epoch: 1154 \tTraining Loss: 0.060932 \tValidation Loss: 0.151442\n",
      "Earlystopping Patience Counter: 251\n",
      "Epoch: 1155 \tTraining Loss: 0.059796 \tValidation Loss: 0.151775\n",
      "Earlystopping Patience Counter: 252\n",
      "Epoch: 1156 \tTraining Loss: 0.059415 \tValidation Loss: 0.149883\n",
      "Earlystopping Patience Counter: 253\n",
      "Epoch: 1157 \tTraining Loss: 0.059663 \tValidation Loss: 0.149482\n",
      "Earlystopping Patience Counter: 254\n",
      "Epoch: 1158 \tTraining Loss: 0.059777 \tValidation Loss: 0.150425\n",
      "Earlystopping Patience Counter: 255\n",
      "Epoch: 1159 \tTraining Loss: 0.062028 \tValidation Loss: 0.151494\n",
      "Earlystopping Patience Counter: 256\n",
      "Epoch: 1160 \tTraining Loss: 0.059660 \tValidation Loss: 0.149656\n",
      "Earlystopping Patience Counter: 257\n",
      "Epoch: 1161 \tTraining Loss: 0.059441 \tValidation Loss: 0.150213\n",
      "Earlystopping Patience Counter: 258\n",
      "Epoch: 1162 \tTraining Loss: 0.059106 \tValidation Loss: 0.149903\n",
      "Earlystopping Patience Counter: 259\n",
      "Epoch: 1163 \tTraining Loss: 0.061352 \tValidation Loss: 0.153244\n",
      "Earlystopping Patience Counter: 260\n",
      "Epoch: 1164 \tTraining Loss: 0.059223 \tValidation Loss: 0.150047\n",
      "Earlystopping Patience Counter: 261\n",
      "Epoch: 1165 \tTraining Loss: 0.061451 \tValidation Loss: 0.150156\n",
      "Earlystopping Patience Counter: 262\n",
      "Epoch: 1166 \tTraining Loss: 0.059133 \tValidation Loss: 0.150107\n",
      "Earlystopping Patience Counter: 263\n",
      "Epoch: 1167 \tTraining Loss: 0.059406 \tValidation Loss: 0.149368\n",
      "Earlystopping Patience Counter: 264\n",
      "Epoch: 1168 \tTraining Loss: 0.059863 \tValidation Loss: 0.151657\n",
      "Earlystopping Patience Counter: 265\n",
      "Epoch: 1169 \tTraining Loss: 0.058904 \tValidation Loss: 0.152118\n",
      "Earlystopping Patience Counter: 266\n",
      "Epoch: 1170 \tTraining Loss: 0.058090 \tValidation Loss: 0.154007\n",
      "Earlystopping Patience Counter: 267\n",
      "Epoch: 1171 \tTraining Loss: 0.058665 \tValidation Loss: 0.152722\n",
      "Earlystopping Patience Counter: 268\n",
      "Epoch: 1172 \tTraining Loss: 0.058303 \tValidation Loss: 0.149853\n",
      "Earlystopping Patience Counter: 269\n",
      "Epoch: 1173 \tTraining Loss: 0.058585 \tValidation Loss: 0.150641\n",
      "Earlystopping Patience Counter: 270\n",
      "Epoch: 1174 \tTraining Loss: 0.058587 \tValidation Loss: 0.151047\n",
      "Earlystopping Patience Counter: 271\n",
      "Epoch: 1175 \tTraining Loss: 0.058549 \tValidation Loss: 0.152989\n",
      "Earlystopping Patience Counter: 272\n",
      "Epoch: 1176 \tTraining Loss: 0.059012 \tValidation Loss: 0.151210\n",
      "Earlystopping Patience Counter: 273\n",
      "Epoch: 1177 \tTraining Loss: 0.058162 \tValidation Loss: 0.150960\n",
      "Earlystopping Patience Counter: 274\n",
      "Epoch: 1178 \tTraining Loss: 0.059144 \tValidation Loss: 0.153789\n",
      "Earlystopping Patience Counter: 275\n",
      "Epoch: 1179 \tTraining Loss: 0.059855 \tValidation Loss: 0.151325\n",
      "Earlystopping Patience Counter: 276\n",
      "Epoch: 1180 \tTraining Loss: 0.058605 \tValidation Loss: 0.150343\n",
      "Earlystopping Patience Counter: 277\n",
      "Epoch: 1181 \tTraining Loss: 0.058645 \tValidation Loss: 0.152094\n",
      "Earlystopping Patience Counter: 278\n",
      "Epoch: 1182 \tTraining Loss: 0.058329 \tValidation Loss: 0.150130\n",
      "Earlystopping Patience Counter: 279\n",
      "Epoch: 1183 \tTraining Loss: 0.058520 \tValidation Loss: 0.151258\n",
      "Earlystopping Patience Counter: 280\n",
      "Epoch: 1184 \tTraining Loss: 0.058251 \tValidation Loss: 0.152299\n",
      "Earlystopping Patience Counter: 281\n",
      "Epoch: 1185 \tTraining Loss: 0.057936 \tValidation Loss: 0.151892\n",
      "Earlystopping Patience Counter: 282\n",
      "Epoch: 1186 \tTraining Loss: 0.058063 \tValidation Loss: 0.152175\n",
      "Earlystopping Patience Counter: 283\n",
      "Epoch: 1187 \tTraining Loss: 0.059053 \tValidation Loss: 0.150830\n",
      "Earlystopping Patience Counter: 284\n",
      "Epoch: 1188 \tTraining Loss: 0.058187 \tValidation Loss: 0.149662\n",
      "Earlystopping Patience Counter: 285\n",
      "Epoch: 1189 \tTraining Loss: 0.058363 \tValidation Loss: 0.150789\n",
      "Earlystopping Patience Counter: 286\n",
      "Epoch: 1190 \tTraining Loss: 0.060119 \tValidation Loss: 0.156981\n",
      "Earlystopping Patience Counter: 287\n",
      "Epoch: 1191 \tTraining Loss: 0.057978 \tValidation Loss: 0.150200\n",
      "Earlystopping Patience Counter: 288\n",
      "Epoch: 1192 \tTraining Loss: 0.058167 \tValidation Loss: 0.150803\n",
      "Earlystopping Patience Counter: 289\n",
      "Epoch: 1193 \tTraining Loss: 0.057459 \tValidation Loss: 0.160670\n",
      "Earlystopping Patience Counter: 290\n",
      "Epoch: 1194 \tTraining Loss: 0.059150 \tValidation Loss: 0.153112\n",
      "Earlystopping Patience Counter: 291\n",
      "Epoch: 1195 \tTraining Loss: 0.064333 \tValidation Loss: 0.167743\n",
      "Earlystopping Patience Counter: 292\n",
      "Epoch: 1196 \tTraining Loss: 0.059362 \tValidation Loss: 0.151164\n",
      "Earlystopping Patience Counter: 293\n",
      "Epoch: 1197 \tTraining Loss: 0.057757 \tValidation Loss: 0.152172\n",
      "Earlystopping Patience Counter: 294\n",
      "Epoch: 1198 \tTraining Loss: 0.061337 \tValidation Loss: 0.170090\n",
      "Earlystopping Patience Counter: 295\n",
      "Epoch: 1199 \tTraining Loss: 0.058241 \tValidation Loss: 0.150680\n",
      "Earlystopping Patience Counter: 296\n",
      "Epoch: 1200 \tTraining Loss: 0.057298 \tValidation Loss: 0.153207\n",
      "Earlystopping Patience Counter: 297\n",
      "Epoch: 1201 \tTraining Loss: 0.056796 \tValidation Loss: 0.150494\n",
      "Earlystopping Patience Counter: 298\n",
      "Epoch: 1202 \tTraining Loss: 0.057061 \tValidation Loss: 0.151824\n",
      "Earlystopping Patience Counter: 299\n",
      "Epoch: 1203 \tTraining Loss: 0.059394 \tValidation Loss: 0.151075\n",
      "Earlystopping Patience Counter: 300\n",
      "Epoch: 1204 \tTraining Loss: 0.057712 \tValidation Loss: 0.152714\n",
      "Earlystopping Patience Counter: 301\n",
      "Epoch: 1205 \tTraining Loss: 0.057242 \tValidation Loss: 0.151356\n",
      "Earlystopping Patience Counter: 302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1206 \tTraining Loss: 0.057398 \tValidation Loss: 0.153173\n",
      "Earlystopping Patience Counter: 303\n",
      "Epoch: 1207 \tTraining Loss: 0.057164 \tValidation Loss: 0.150770\n",
      "Earlystopping Patience Counter: 304\n",
      "Epoch: 1208 \tTraining Loss: 0.056854 \tValidation Loss: 0.151680\n",
      "Earlystopping Patience Counter: 305\n",
      "Epoch: 1209 \tTraining Loss: 0.056720 \tValidation Loss: 0.150535\n",
      "Earlystopping Patience Counter: 306\n",
      "Epoch: 1210 \tTraining Loss: 0.056936 \tValidation Loss: 0.149744\n",
      "Earlystopping Patience Counter: 307\n",
      "Epoch: 1211 \tTraining Loss: 0.057724 \tValidation Loss: 0.152367\n",
      "Earlystopping Patience Counter: 308\n",
      "Epoch: 1212 \tTraining Loss: 0.057928 \tValidation Loss: 0.152031\n",
      "Earlystopping Patience Counter: 309\n",
      "Epoch: 1213 \tTraining Loss: 0.056439 \tValidation Loss: 0.150583\n",
      "Earlystopping Patience Counter: 310\n",
      "Epoch: 1214 \tTraining Loss: 0.056977 \tValidation Loss: 0.152521\n",
      "Earlystopping Patience Counter: 311\n",
      "Epoch: 1215 \tTraining Loss: 0.057354 \tValidation Loss: 0.153809\n",
      "Earlystopping Patience Counter: 312\n",
      "Epoch: 1216 \tTraining Loss: 0.056357 \tValidation Loss: 0.151588\n",
      "Earlystopping Patience Counter: 313\n",
      "Epoch: 1217 \tTraining Loss: 0.056196 \tValidation Loss: 0.150620\n",
      "Earlystopping Patience Counter: 314\n",
      "Epoch: 1218 \tTraining Loss: 0.056491 \tValidation Loss: 0.150183\n",
      "Earlystopping Patience Counter: 315\n",
      "Epoch: 1219 \tTraining Loss: 0.056242 \tValidation Loss: 0.152259\n",
      "Earlystopping Patience Counter: 316\n",
      "Epoch: 1220 \tTraining Loss: 0.057734 \tValidation Loss: 0.150402\n",
      "Earlystopping Patience Counter: 317\n",
      "Epoch: 1221 \tTraining Loss: 0.056599 \tValidation Loss: 0.151348\n",
      "Earlystopping Patience Counter: 318\n",
      "Epoch: 1222 \tTraining Loss: 0.055886 \tValidation Loss: 0.150905\n",
      "Earlystopping Patience Counter: 319\n",
      "Epoch: 1223 \tTraining Loss: 0.056360 \tValidation Loss: 0.150404\n",
      "Earlystopping Patience Counter: 320\n",
      "Epoch: 1224 \tTraining Loss: 0.056103 \tValidation Loss: 0.152792\n",
      "Earlystopping Patience Counter: 321\n",
      "Epoch: 1225 \tTraining Loss: 0.055759 \tValidation Loss: 0.152411\n",
      "Earlystopping Patience Counter: 322\n",
      "Epoch: 1226 \tTraining Loss: 0.055866 \tValidation Loss: 0.152244\n",
      "Earlystopping Patience Counter: 323\n",
      "Epoch: 1227 \tTraining Loss: 0.055679 \tValidation Loss: 0.151053\n",
      "Earlystopping Patience Counter: 324\n",
      "Epoch: 1228 \tTraining Loss: 0.055943 \tValidation Loss: 0.152813\n",
      "Earlystopping Patience Counter: 325\n",
      "Epoch: 1229 \tTraining Loss: 0.055673 \tValidation Loss: 0.150869\n",
      "Earlystopping Patience Counter: 326\n",
      "Epoch: 1230 \tTraining Loss: 0.057778 \tValidation Loss: 0.151064\n",
      "Earlystopping Patience Counter: 327\n",
      "Epoch: 1231 \tTraining Loss: 0.056445 \tValidation Loss: 0.155539\n",
      "Earlystopping Patience Counter: 328\n",
      "Epoch: 1232 \tTraining Loss: 0.058451 \tValidation Loss: 0.153934\n",
      "Earlystopping Patience Counter: 329\n",
      "Epoch: 1233 \tTraining Loss: 0.055823 \tValidation Loss: 0.150485\n",
      "Earlystopping Patience Counter: 330\n",
      "Epoch: 1234 \tTraining Loss: 0.056007 \tValidation Loss: 0.155301\n",
      "Earlystopping Patience Counter: 331\n",
      "Epoch: 1235 \tTraining Loss: 0.054711 \tValidation Loss: 0.151454\n",
      "Earlystopping Patience Counter: 332\n",
      "Epoch: 1236 \tTraining Loss: 0.056229 \tValidation Loss: 0.156469\n",
      "Earlystopping Patience Counter: 333\n",
      "Epoch: 1237 \tTraining Loss: 0.055494 \tValidation Loss: 0.152678\n",
      "Earlystopping Patience Counter: 334\n",
      "Epoch: 1238 \tTraining Loss: 0.055504 \tValidation Loss: 0.152181\n",
      "Earlystopping Patience Counter: 335\n",
      "Epoch: 1239 \tTraining Loss: 0.055151 \tValidation Loss: 0.152749\n",
      "Earlystopping Patience Counter: 336\n",
      "Epoch: 1240 \tTraining Loss: 0.055027 \tValidation Loss: 0.152832\n",
      "Earlystopping Patience Counter: 337\n",
      "Epoch: 1241 \tTraining Loss: 0.059770 \tValidation Loss: 0.151139\n",
      "Earlystopping Patience Counter: 338\n",
      "Epoch: 1242 \tTraining Loss: 0.055532 \tValidation Loss: 0.149704\n",
      "Earlystopping Patience Counter: 339\n",
      "Epoch: 1243 \tTraining Loss: 0.056197 \tValidation Loss: 0.154940\n",
      "Earlystopping Patience Counter: 340\n",
      "Epoch: 1244 \tTraining Loss: 0.055409 \tValidation Loss: 0.154771\n",
      "Earlystopping Patience Counter: 341\n",
      "Epoch: 1245 \tTraining Loss: 0.055043 \tValidation Loss: 0.152151\n",
      "Earlystopping Patience Counter: 342\n",
      "Epoch: 1246 \tTraining Loss: 0.054695 \tValidation Loss: 0.152604\n",
      "Earlystopping Patience Counter: 343\n",
      "Epoch: 1247 \tTraining Loss: 0.056288 \tValidation Loss: 0.151367\n",
      "Earlystopping Patience Counter: 344\n",
      "Epoch: 1248 \tTraining Loss: 0.055178 \tValidation Loss: 0.152967\n",
      "Earlystopping Patience Counter: 345\n",
      "Epoch: 1249 \tTraining Loss: 0.054640 \tValidation Loss: 0.151454\n",
      "Earlystopping Patience Counter: 346\n",
      "Epoch: 1250 \tTraining Loss: 0.055010 \tValidation Loss: 0.153804\n",
      "Earlystopping Patience Counter: 347\n",
      "Epoch: 1251 \tTraining Loss: 0.054149 \tValidation Loss: 0.152827\n",
      "Earlystopping Patience Counter: 348\n",
      "Epoch: 1252 \tTraining Loss: 0.054751 \tValidation Loss: 0.156098\n",
      "Earlystopping Patience Counter: 349\n",
      "Epoch: 1253 \tTraining Loss: 0.055132 \tValidation Loss: 0.153778\n",
      "Earlystopping Patience Counter: 350\n",
      "Epoch: 1254 \tTraining Loss: 0.054872 \tValidation Loss: 0.152540\n",
      "Earlystopping Patience Counter: 351\n",
      "Epoch: 1255 \tTraining Loss: 0.054742 \tValidation Loss: 0.153265\n",
      "Earlystopping Patience Counter: 352\n",
      "Epoch: 1256 \tTraining Loss: 0.054587 \tValidation Loss: 0.153089\n",
      "Earlystopping Patience Counter: 353\n",
      "Epoch: 1257 \tTraining Loss: 0.054199 \tValidation Loss: 0.152792\n",
      "Earlystopping Patience Counter: 354\n",
      "Epoch: 1258 \tTraining Loss: 0.054879 \tValidation Loss: 0.153953\n",
      "Earlystopping Patience Counter: 355\n",
      "Epoch: 1259 \tTraining Loss: 0.055066 \tValidation Loss: 0.152987\n",
      "Earlystopping Patience Counter: 356\n",
      "Epoch: 1260 \tTraining Loss: 0.054222 \tValidation Loss: 0.152456\n",
      "Earlystopping Patience Counter: 357\n",
      "Epoch: 1261 \tTraining Loss: 0.054322 \tValidation Loss: 0.153058\n",
      "Earlystopping Patience Counter: 358\n",
      "Epoch: 1262 \tTraining Loss: 0.054022 \tValidation Loss: 0.152915\n",
      "Earlystopping Patience Counter: 359\n",
      "Epoch: 1263 \tTraining Loss: 0.054526 \tValidation Loss: 0.151768\n",
      "Earlystopping Patience Counter: 360\n",
      "Epoch: 1264 \tTraining Loss: 0.053430 \tValidation Loss: 0.153829\n",
      "Earlystopping Patience Counter: 361\n",
      "Epoch: 1265 \tTraining Loss: 0.054129 \tValidation Loss: 0.151801\n",
      "Earlystopping Patience Counter: 362\n",
      "Epoch: 1266 \tTraining Loss: 0.054436 \tValidation Loss: 0.150943\n",
      "Earlystopping Patience Counter: 363\n",
      "Epoch: 1267 \tTraining Loss: 0.053859 \tValidation Loss: 0.152717\n",
      "Earlystopping Patience Counter: 364\n",
      "Epoch: 1268 \tTraining Loss: 0.053802 \tValidation Loss: 0.151223\n",
      "Earlystopping Patience Counter: 365\n",
      "Epoch: 1269 \tTraining Loss: 0.054460 \tValidation Loss: 0.152751\n",
      "Earlystopping Patience Counter: 366\n",
      "Epoch: 1270 \tTraining Loss: 0.053905 \tValidation Loss: 0.151824\n",
      "Earlystopping Patience Counter: 367\n",
      "Epoch: 1271 \tTraining Loss: 0.053400 \tValidation Loss: 0.152470\n",
      "Earlystopping Patience Counter: 368\n",
      "Epoch: 1272 \tTraining Loss: 0.053307 \tValidation Loss: 0.152466\n",
      "Earlystopping Patience Counter: 369\n",
      "Epoch: 1273 \tTraining Loss: 0.052898 \tValidation Loss: 0.152523\n",
      "Earlystopping Patience Counter: 370\n",
      "Epoch: 1274 \tTraining Loss: 0.053415 \tValidation Loss: 0.152558\n",
      "Earlystopping Patience Counter: 371\n",
      "Epoch: 1275 \tTraining Loss: 0.054684 \tValidation Loss: 0.154601\n",
      "Earlystopping Patience Counter: 372\n",
      "Epoch: 1276 \tTraining Loss: 0.053569 \tValidation Loss: 0.152442\n",
      "Earlystopping Patience Counter: 373\n",
      "Epoch: 1277 \tTraining Loss: 0.053051 \tValidation Loss: 0.152101\n",
      "Earlystopping Patience Counter: 374\n",
      "Epoch: 1278 \tTraining Loss: 0.053453 \tValidation Loss: 0.156494\n",
      "Earlystopping Patience Counter: 375\n",
      "Epoch: 1279 \tTraining Loss: 0.053020 \tValidation Loss: 0.155792\n",
      "Earlystopping Patience Counter: 376\n",
      "Epoch: 1280 \tTraining Loss: 0.053334 \tValidation Loss: 0.153111\n",
      "Earlystopping Patience Counter: 377\n",
      "Epoch: 1281 \tTraining Loss: 0.053072 \tValidation Loss: 0.151786\n",
      "Earlystopping Patience Counter: 378\n",
      "Epoch: 1282 \tTraining Loss: 0.053075 \tValidation Loss: 0.153638\n",
      "Earlystopping Patience Counter: 379\n",
      "Epoch: 1283 \tTraining Loss: 0.053528 \tValidation Loss: 0.154162\n",
      "Earlystopping Patience Counter: 380\n",
      "Epoch: 1284 \tTraining Loss: 0.052856 \tValidation Loss: 0.155865\n",
      "Earlystopping Patience Counter: 381\n",
      "Epoch: 1285 \tTraining Loss: 0.061438 \tValidation Loss: 0.153975\n",
      "Earlystopping Patience Counter: 382\n",
      "Epoch: 1286 \tTraining Loss: 0.053150 \tValidation Loss: 0.153504\n",
      "Earlystopping Patience Counter: 383\n",
      "Epoch: 1287 \tTraining Loss: 0.053079 \tValidation Loss: 0.152512\n",
      "Earlystopping Patience Counter: 384\n",
      "Epoch: 1288 \tTraining Loss: 0.053247 \tValidation Loss: 0.154481\n",
      "Earlystopping Patience Counter: 385\n",
      "Epoch: 1289 \tTraining Loss: 0.056275 \tValidation Loss: 0.154331\n",
      "Earlystopping Patience Counter: 386\n",
      "Epoch: 1290 \tTraining Loss: 0.052312 \tValidation Loss: 0.153055\n",
      "Earlystopping Patience Counter: 387\n",
      "Epoch: 1291 \tTraining Loss: 0.051458 \tValidation Loss: 0.158993\n",
      "Earlystopping Patience Counter: 388\n",
      "Epoch: 1292 \tTraining Loss: 0.054055 \tValidation Loss: 0.152723\n",
      "Earlystopping Patience Counter: 389\n",
      "Epoch: 1293 \tTraining Loss: 0.052409 \tValidation Loss: 0.155022\n",
      "Earlystopping Patience Counter: 390\n",
      "Epoch: 1294 \tTraining Loss: 0.052328 \tValidation Loss: 0.152171\n",
      "Earlystopping Patience Counter: 391\n",
      "Epoch: 1295 \tTraining Loss: 0.052561 \tValidation Loss: 0.153481\n",
      "Earlystopping Patience Counter: 392\n",
      "Epoch: 1296 \tTraining Loss: 0.051754 \tValidation Loss: 0.153940\n",
      "Earlystopping Patience Counter: 393\n",
      "Epoch: 1297 \tTraining Loss: 0.055472 \tValidation Loss: 0.158911\n",
      "Earlystopping Patience Counter: 394\n",
      "Epoch: 1298 \tTraining Loss: 0.052684 \tValidation Loss: 0.153790\n",
      "Earlystopping Patience Counter: 395\n",
      "Epoch: 1299 \tTraining Loss: 0.052473 \tValidation Loss: 0.153316\n",
      "Earlystopping Patience Counter: 396\n",
      "Epoch: 1300 \tTraining Loss: 0.060100 \tValidation Loss: 0.160600\n",
      "Earlystopping Patience Counter: 397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1301 \tTraining Loss: 0.052724 \tValidation Loss: 0.156399\n",
      "Earlystopping Patience Counter: 398\n",
      "Epoch: 1302 \tTraining Loss: 0.051959 \tValidation Loss: 0.153244\n",
      "Earlystopping Patience Counter: 399\n",
      "Epoch: 1303 \tTraining Loss: 0.053280 \tValidation Loss: 0.153265\n",
      "Earlystopping Patience Counter: 400\n",
      "Epoch: 1304 \tTraining Loss: 0.051823 \tValidation Loss: 0.154956\n",
      "Earlystopping Patience Counter: 401\n",
      "Epoch: 1305 \tTraining Loss: 0.052430 \tValidation Loss: 0.153253\n",
      "Earlystopping Patience Counter: 402\n",
      "Epoch: 1306 \tTraining Loss: 0.052642 \tValidation Loss: 0.156764\n",
      "Earlystopping Patience Counter: 403\n",
      "Epoch: 1307 \tTraining Loss: 0.051613 \tValidation Loss: 0.158038\n",
      "Earlystopping Patience Counter: 404\n",
      "Epoch: 1308 \tTraining Loss: 0.050891 \tValidation Loss: 0.155558\n",
      "Earlystopping Patience Counter: 405\n",
      "Epoch: 1309 \tTraining Loss: 0.051921 \tValidation Loss: 0.154556\n",
      "Earlystopping Patience Counter: 406\n",
      "Epoch: 1310 \tTraining Loss: 0.053036 \tValidation Loss: 0.156625\n",
      "Earlystopping Patience Counter: 407\n",
      "Epoch: 1311 \tTraining Loss: 0.052130 \tValidation Loss: 0.154749\n",
      "Earlystopping Patience Counter: 408\n",
      "Epoch: 1312 \tTraining Loss: 0.051953 \tValidation Loss: 0.155121\n",
      "Earlystopping Patience Counter: 409\n",
      "Epoch: 1313 \tTraining Loss: 0.051782 \tValidation Loss: 0.154121\n",
      "Earlystopping Patience Counter: 410\n",
      "Epoch: 1314 \tTraining Loss: 0.051659 \tValidation Loss: 0.153851\n",
      "Earlystopping Patience Counter: 411\n",
      "Epoch: 1315 \tTraining Loss: 0.050613 \tValidation Loss: 0.155889\n",
      "Earlystopping Patience Counter: 412\n",
      "Epoch: 1316 \tTraining Loss: 0.053011 \tValidation Loss: 0.152386\n",
      "Earlystopping Patience Counter: 413\n",
      "Epoch: 1317 \tTraining Loss: 0.051148 \tValidation Loss: 0.156369\n",
      "Earlystopping Patience Counter: 414\n",
      "Epoch: 1318 \tTraining Loss: 0.053003 \tValidation Loss: 0.153580\n",
      "Earlystopping Patience Counter: 415\n",
      "Epoch: 1319 \tTraining Loss: 0.053064 \tValidation Loss: 0.163196\n",
      "Earlystopping Patience Counter: 416\n",
      "Epoch: 1320 \tTraining Loss: 0.051844 \tValidation Loss: 0.153534\n",
      "Earlystopping Patience Counter: 417\n",
      "Epoch: 1321 \tTraining Loss: 0.050824 \tValidation Loss: 0.155294\n",
      "Earlystopping Patience Counter: 418\n",
      "Epoch: 1322 \tTraining Loss: 0.051204 \tValidation Loss: 0.154786\n",
      "Earlystopping Patience Counter: 419\n",
      "Epoch: 1323 \tTraining Loss: 0.053478 \tValidation Loss: 0.156425\n",
      "Earlystopping Patience Counter: 420\n",
      "Epoch: 1324 \tTraining Loss: 0.050919 \tValidation Loss: 0.156205\n",
      "Earlystopping Patience Counter: 421\n",
      "Epoch: 1325 \tTraining Loss: 0.050649 \tValidation Loss: 0.156282\n",
      "Earlystopping Patience Counter: 422\n",
      "Epoch: 1326 \tTraining Loss: 0.050726 \tValidation Loss: 0.155143\n",
      "Earlystopping Patience Counter: 423\n",
      "Epoch: 1327 \tTraining Loss: 0.050784 \tValidation Loss: 0.154793\n",
      "Earlystopping Patience Counter: 424\n",
      "Epoch: 1328 \tTraining Loss: 0.050359 \tValidation Loss: 0.155134\n",
      "Earlystopping Patience Counter: 425\n",
      "Epoch: 1329 \tTraining Loss: 0.051551 \tValidation Loss: 0.154699\n",
      "Earlystopping Patience Counter: 426\n",
      "Epoch: 1330 \tTraining Loss: 0.052801 \tValidation Loss: 0.152962\n",
      "Earlystopping Patience Counter: 427\n",
      "Epoch: 1331 \tTraining Loss: 0.051130 \tValidation Loss: 0.153190\n",
      "Earlystopping Patience Counter: 428\n",
      "Epoch: 1332 \tTraining Loss: 0.053297 \tValidation Loss: 0.155801\n",
      "Earlystopping Patience Counter: 429\n",
      "Epoch: 1333 \tTraining Loss: 0.051350 \tValidation Loss: 0.153884\n",
      "Earlystopping Patience Counter: 430\n",
      "Epoch: 1334 \tTraining Loss: 0.050774 \tValidation Loss: 0.156022\n",
      "Earlystopping Patience Counter: 431\n",
      "Epoch: 1335 \tTraining Loss: 0.050224 \tValidation Loss: 0.154009\n",
      "Earlystopping Patience Counter: 432\n",
      "Epoch: 1336 \tTraining Loss: 0.050263 \tValidation Loss: 0.154260\n",
      "Earlystopping Patience Counter: 433\n",
      "Epoch: 1337 \tTraining Loss: 0.051215 \tValidation Loss: 0.158561\n",
      "Earlystopping Patience Counter: 434\n",
      "Epoch: 1338 \tTraining Loss: 0.050705 \tValidation Loss: 0.153324\n",
      "Earlystopping Patience Counter: 435\n",
      "Epoch: 1339 \tTraining Loss: 0.049674 \tValidation Loss: 0.153818\n",
      "Earlystopping Patience Counter: 436\n",
      "Epoch: 1340 \tTraining Loss: 0.050695 \tValidation Loss: 0.155796\n",
      "Earlystopping Patience Counter: 437\n",
      "Epoch: 1341 \tTraining Loss: 0.050347 \tValidation Loss: 0.154925\n",
      "Earlystopping Patience Counter: 438\n",
      "Epoch: 1342 \tTraining Loss: 0.050023 \tValidation Loss: 0.154535\n",
      "Earlystopping Patience Counter: 439\n",
      "Epoch: 1343 \tTraining Loss: 0.050433 \tValidation Loss: 0.155411\n",
      "Earlystopping Patience Counter: 440\n",
      "Epoch: 1344 \tTraining Loss: 0.050162 \tValidation Loss: 0.154972\n",
      "Earlystopping Patience Counter: 441\n",
      "Epoch: 1345 \tTraining Loss: 0.049943 \tValidation Loss: 0.158378\n",
      "Earlystopping Patience Counter: 442\n",
      "Epoch: 1346 \tTraining Loss: 0.049511 \tValidation Loss: 0.154635\n",
      "Earlystopping Patience Counter: 443\n",
      "Epoch: 1347 \tTraining Loss: 0.049650 \tValidation Loss: 0.156398\n",
      "Earlystopping Patience Counter: 444\n",
      "Epoch: 1348 \tTraining Loss: 0.049863 \tValidation Loss: 0.156670\n",
      "Earlystopping Patience Counter: 445\n",
      "Epoch: 1349 \tTraining Loss: 0.048877 \tValidation Loss: 0.163060\n",
      "Earlystopping Patience Counter: 446\n",
      "Epoch: 1350 \tTraining Loss: 0.049455 \tValidation Loss: 0.154886\n",
      "Earlystopping Patience Counter: 447\n",
      "Epoch: 1351 \tTraining Loss: 0.049885 \tValidation Loss: 0.156740\n",
      "Earlystopping Patience Counter: 448\n",
      "Epoch: 1352 \tTraining Loss: 0.049798 \tValidation Loss: 0.156953\n",
      "Earlystopping Patience Counter: 449\n",
      "Epoch: 1353 \tTraining Loss: 0.049306 \tValidation Loss: 0.157145\n",
      "Earlystopping Patience Counter: 450\n",
      "Epoch: 1354 \tTraining Loss: 0.048624 \tValidation Loss: 0.154971\n",
      "Earlystopping Patience Counter: 451\n",
      "Epoch: 1355 \tTraining Loss: 0.049757 \tValidation Loss: 0.155579\n",
      "Earlystopping Patience Counter: 452\n",
      "Epoch: 1356 \tTraining Loss: 0.049460 \tValidation Loss: 0.155550\n",
      "Earlystopping Patience Counter: 453\n",
      "Epoch: 1357 \tTraining Loss: 0.049065 \tValidation Loss: 0.156354\n",
      "Earlystopping Patience Counter: 454\n",
      "Epoch: 1358 \tTraining Loss: 0.049540 \tValidation Loss: 0.158664\n",
      "Earlystopping Patience Counter: 455\n",
      "Epoch: 1359 \tTraining Loss: 0.049905 \tValidation Loss: 0.157183\n",
      "Earlystopping Patience Counter: 456\n",
      "Epoch: 1360 \tTraining Loss: 0.049244 \tValidation Loss: 0.158752\n",
      "Earlystopping Patience Counter: 457\n",
      "Epoch: 1361 \tTraining Loss: 0.049289 \tValidation Loss: 0.156899\n",
      "Earlystopping Patience Counter: 458\n",
      "Epoch: 1362 \tTraining Loss: 0.049058 \tValidation Loss: 0.158792\n",
      "Earlystopping Patience Counter: 459\n",
      "Epoch: 1363 \tTraining Loss: 0.048869 \tValidation Loss: 0.157022\n",
      "Earlystopping Patience Counter: 460\n",
      "Epoch: 1364 \tTraining Loss: 0.048711 \tValidation Loss: 0.155095\n",
      "Earlystopping Patience Counter: 461\n",
      "Epoch: 1365 \tTraining Loss: 0.050054 \tValidation Loss: 0.156174\n",
      "Earlystopping Patience Counter: 462\n",
      "Epoch: 1366 \tTraining Loss: 0.048611 \tValidation Loss: 0.159407\n",
      "Earlystopping Patience Counter: 463\n",
      "Epoch: 1367 \tTraining Loss: 0.050223 \tValidation Loss: 0.161440\n",
      "Earlystopping Patience Counter: 464\n",
      "Epoch: 1368 \tTraining Loss: 0.048801 \tValidation Loss: 0.160142\n",
      "Earlystopping Patience Counter: 465\n",
      "Epoch: 1369 \tTraining Loss: 0.048337 \tValidation Loss: 0.158042\n",
      "Earlystopping Patience Counter: 466\n",
      "Epoch: 1370 \tTraining Loss: 0.048725 \tValidation Loss: 0.157127\n",
      "Earlystopping Patience Counter: 467\n",
      "Epoch: 1371 \tTraining Loss: 0.048651 \tValidation Loss: 0.155171\n",
      "Earlystopping Patience Counter: 468\n",
      "Epoch: 1372 \tTraining Loss: 0.048547 \tValidation Loss: 0.155465\n",
      "Earlystopping Patience Counter: 469\n",
      "Epoch: 1373 \tTraining Loss: 0.049145 \tValidation Loss: 0.156604\n",
      "Earlystopping Patience Counter: 470\n",
      "Epoch: 1374 \tTraining Loss: 0.048824 \tValidation Loss: 0.157004\n",
      "Earlystopping Patience Counter: 471\n",
      "Epoch: 1375 \tTraining Loss: 0.048110 \tValidation Loss: 0.155219\n",
      "Earlystopping Patience Counter: 472\n",
      "Epoch: 1376 \tTraining Loss: 0.049297 \tValidation Loss: 0.159705\n",
      "Earlystopping Patience Counter: 473\n",
      "Epoch: 1377 \tTraining Loss: 0.050047 \tValidation Loss: 0.156987\n",
      "Earlystopping Patience Counter: 474\n",
      "Epoch: 1378 \tTraining Loss: 0.049315 \tValidation Loss: 0.156715\n",
      "Earlystopping Patience Counter: 475\n",
      "Epoch: 1379 \tTraining Loss: 0.048322 \tValidation Loss: 0.156060\n",
      "Earlystopping Patience Counter: 476\n",
      "Epoch: 1380 \tTraining Loss: 0.048586 \tValidation Loss: 0.158282\n",
      "Earlystopping Patience Counter: 477\n",
      "Epoch: 1381 \tTraining Loss: 0.048584 \tValidation Loss: 0.156954\n",
      "Earlystopping Patience Counter: 478\n",
      "Epoch: 1382 \tTraining Loss: 0.048393 \tValidation Loss: 0.157055\n",
      "Earlystopping Patience Counter: 479\n",
      "Epoch: 1383 \tTraining Loss: 0.049180 \tValidation Loss: 0.172391\n",
      "Earlystopping Patience Counter: 480\n",
      "Epoch: 1384 \tTraining Loss: 0.050080 \tValidation Loss: 0.158213\n",
      "Earlystopping Patience Counter: 481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1385 \tTraining Loss: 0.048106 \tValidation Loss: 0.155201\n",
      "Earlystopping Patience Counter: 482\n",
      "Epoch: 1386 \tTraining Loss: 0.048941 \tValidation Loss: 0.154925\n",
      "Earlystopping Patience Counter: 483\n",
      "Epoch: 1387 \tTraining Loss: 0.048412 \tValidation Loss: 0.156004\n",
      "Earlystopping Patience Counter: 484\n",
      "Epoch: 1388 \tTraining Loss: 0.048087 \tValidation Loss: 0.155392\n",
      "Earlystopping Patience Counter: 485\n",
      "Epoch: 1389 \tTraining Loss: 0.048042 \tValidation Loss: 0.156861\n",
      "Earlystopping Patience Counter: 486\n",
      "Epoch: 1390 \tTraining Loss: 0.048245 \tValidation Loss: 0.158526\n",
      "Earlystopping Patience Counter: 487\n",
      "Epoch: 1391 \tTraining Loss: 0.048080 \tValidation Loss: 0.155705\n",
      "Earlystopping Patience Counter: 488\n",
      "Epoch: 1392 \tTraining Loss: 0.048648 \tValidation Loss: 0.158168\n",
      "Earlystopping Patience Counter: 489\n",
      "Epoch: 1393 \tTraining Loss: 0.048258 \tValidation Loss: 0.157865\n",
      "Earlystopping Patience Counter: 490\n",
      "Epoch: 1394 \tTraining Loss: 0.047592 \tValidation Loss: 0.156028\n",
      "Earlystopping Patience Counter: 491\n",
      "Epoch: 1395 \tTraining Loss: 0.047569 \tValidation Loss: 0.157611\n",
      "Earlystopping Patience Counter: 492\n",
      "Epoch: 1396 \tTraining Loss: 0.048251 \tValidation Loss: 0.158613\n",
      "Earlystopping Patience Counter: 493\n",
      "Epoch: 1397 \tTraining Loss: 0.047913 \tValidation Loss: 0.158094\n",
      "Earlystopping Patience Counter: 494\n",
      "Epoch: 1398 \tTraining Loss: 0.047599 \tValidation Loss: 0.157386\n",
      "Earlystopping Patience Counter: 495\n",
      "Epoch: 1399 \tTraining Loss: 0.046931 \tValidation Loss: 0.157596\n",
      "Earlystopping Patience Counter: 496\n",
      "Epoch: 1400 \tTraining Loss: 0.047594 \tValidation Loss: 0.156698\n",
      "Earlystopping Patience Counter: 497\n",
      "Epoch: 1401 \tTraining Loss: 0.047092 \tValidation Loss: 0.156858\n",
      "Earlystopping Patience Counter: 498\n",
      "Epoch: 1402 \tTraining Loss: 0.047185 \tValidation Loss: 0.160936\n",
      "Earlystopping Patience Counter: 499\n",
      "Epoch: 1403 \tTraining Loss: 0.047531 \tValidation Loss: 0.156735\n",
      "Earlystopping Patience Counter: 500\n",
      "Epoch: 1404 \tTraining Loss: 0.047378 \tValidation Loss: 0.156448\n",
      "Earlystopping Patience Counter: 501\n",
      "Epoch: 1405 \tTraining Loss: 0.047297 \tValidation Loss: 0.158597\n",
      "Earlystopping Patience Counter: 502\n",
      "Epoch: 1406 \tTraining Loss: 0.046792 \tValidation Loss: 0.159973\n",
      "Earlystopping Patience Counter: 503\n",
      "Epoch: 1407 \tTraining Loss: 0.047790 \tValidation Loss: 0.156204\n",
      "Earlystopping Patience Counter: 504\n",
      "Epoch: 1408 \tTraining Loss: 0.047114 \tValidation Loss: 0.157972\n",
      "Earlystopping Patience Counter: 505\n",
      "Epoch: 1409 \tTraining Loss: 0.046759 \tValidation Loss: 0.162800\n",
      "Earlystopping Patience Counter: 506\n",
      "Epoch: 1410 \tTraining Loss: 0.047128 \tValidation Loss: 0.158021\n",
      "Earlystopping Patience Counter: 507\n",
      "Epoch: 1411 \tTraining Loss: 0.046697 \tValidation Loss: 0.156787\n",
      "Earlystopping Patience Counter: 508\n",
      "Epoch: 1412 \tTraining Loss: 0.047485 \tValidation Loss: 0.160176\n",
      "Earlystopping Patience Counter: 509\n",
      "Epoch: 1413 \tTraining Loss: 0.046935 \tValidation Loss: 0.157942\n",
      "Earlystopping Patience Counter: 510\n",
      "Epoch: 1414 \tTraining Loss: 0.046760 \tValidation Loss: 0.159570\n",
      "Earlystopping Patience Counter: 511\n",
      "Epoch: 1415 \tTraining Loss: 0.046522 \tValidation Loss: 0.160362\n",
      "Earlystopping Patience Counter: 512\n",
      "Epoch: 1416 \tTraining Loss: 0.047291 \tValidation Loss: 0.157301\n",
      "Earlystopping Patience Counter: 513\n",
      "Epoch: 1417 \tTraining Loss: 0.049231 \tValidation Loss: 0.157295\n",
      "Earlystopping Patience Counter: 514\n",
      "Epoch: 1418 \tTraining Loss: 0.046783 \tValidation Loss: 0.157797\n",
      "Earlystopping Patience Counter: 515\n",
      "Epoch: 1419 \tTraining Loss: 0.046719 \tValidation Loss: 0.158070\n",
      "Earlystopping Patience Counter: 516\n",
      "Epoch: 1420 \tTraining Loss: 0.046752 \tValidation Loss: 0.161161\n",
      "Earlystopping Patience Counter: 517\n",
      "Epoch: 1421 \tTraining Loss: 0.046405 \tValidation Loss: 0.156448\n",
      "Earlystopping Patience Counter: 518\n",
      "Epoch: 1422 \tTraining Loss: 0.047447 \tValidation Loss: 0.159210\n",
      "Earlystopping Patience Counter: 519\n",
      "Epoch: 1423 \tTraining Loss: 0.047162 \tValidation Loss: 0.156409\n",
      "Earlystopping Patience Counter: 520\n",
      "Epoch: 1424 \tTraining Loss: 0.047481 \tValidation Loss: 0.157995\n",
      "Earlystopping Patience Counter: 521\n",
      "Epoch: 1425 \tTraining Loss: 0.046260 \tValidation Loss: 0.156316\n",
      "Earlystopping Patience Counter: 522\n",
      "Epoch: 1426 \tTraining Loss: 0.045938 \tValidation Loss: 0.164858\n",
      "Earlystopping Patience Counter: 523\n",
      "Epoch: 1427 \tTraining Loss: 0.048208 \tValidation Loss: 0.162017\n",
      "Earlystopping Patience Counter: 524\n",
      "Epoch: 1428 \tTraining Loss: 0.046112 \tValidation Loss: 0.157195\n",
      "Earlystopping Patience Counter: 525\n",
      "Epoch: 1429 \tTraining Loss: 0.046742 \tValidation Loss: 0.160901\n",
      "Earlystopping Patience Counter: 526\n",
      "Epoch: 1430 \tTraining Loss: 0.045882 \tValidation Loss: 0.158252\n",
      "Earlystopping Patience Counter: 527\n",
      "Epoch: 1431 \tTraining Loss: 0.047120 \tValidation Loss: 0.157064\n",
      "Earlystopping Patience Counter: 528\n",
      "Epoch: 1432 \tTraining Loss: 0.046132 \tValidation Loss: 0.158264\n",
      "Earlystopping Patience Counter: 529\n",
      "Epoch: 1433 \tTraining Loss: 0.045149 \tValidation Loss: 0.165985\n",
      "Earlystopping Patience Counter: 530\n",
      "Epoch: 1434 \tTraining Loss: 0.045949 \tValidation Loss: 0.161190\n",
      "Earlystopping Patience Counter: 531\n",
      "Epoch: 1435 \tTraining Loss: 0.045515 \tValidation Loss: 0.162801\n",
      "Earlystopping Patience Counter: 532\n",
      "Epoch: 1436 \tTraining Loss: 0.045098 \tValidation Loss: 0.165763\n",
      "Earlystopping Patience Counter: 533\n",
      "Epoch: 1437 \tTraining Loss: 0.045630 \tValidation Loss: 0.158487\n",
      "Earlystopping Patience Counter: 534\n",
      "Epoch: 1438 \tTraining Loss: 0.045883 \tValidation Loss: 0.157074\n",
      "Earlystopping Patience Counter: 535\n",
      "Epoch: 1439 \tTraining Loss: 0.046488 \tValidation Loss: 0.158446\n",
      "Earlystopping Patience Counter: 536\n",
      "Epoch: 1440 \tTraining Loss: 0.045922 \tValidation Loss: 0.158020\n",
      "Earlystopping Patience Counter: 537\n",
      "Epoch: 1441 \tTraining Loss: 0.045613 \tValidation Loss: 0.157152\n",
      "Earlystopping Patience Counter: 538\n",
      "Epoch: 1442 \tTraining Loss: 0.045432 \tValidation Loss: 0.158727\n",
      "Earlystopping Patience Counter: 539\n",
      "Epoch: 1443 \tTraining Loss: 0.045537 \tValidation Loss: 0.157515\n",
      "Earlystopping Patience Counter: 540\n",
      "Epoch: 1444 \tTraining Loss: 0.046317 \tValidation Loss: 0.157756\n",
      "Earlystopping Patience Counter: 541\n",
      "Epoch: 1445 \tTraining Loss: 0.045904 \tValidation Loss: 0.157698\n",
      "Earlystopping Patience Counter: 542\n",
      "Epoch: 1446 \tTraining Loss: 0.045138 \tValidation Loss: 0.158895\n",
      "Earlystopping Patience Counter: 543\n",
      "Epoch: 1447 \tTraining Loss: 0.045217 \tValidation Loss: 0.157096\n",
      "Earlystopping Patience Counter: 544\n",
      "Epoch: 1448 \tTraining Loss: 0.045081 \tValidation Loss: 0.164036\n",
      "Earlystopping Patience Counter: 545\n",
      "Epoch: 1449 \tTraining Loss: 0.047574 \tValidation Loss: 0.166380\n",
      "Earlystopping Patience Counter: 546\n",
      "Epoch: 1450 \tTraining Loss: 0.045983 \tValidation Loss: 0.158499\n",
      "Earlystopping Patience Counter: 547\n",
      "Epoch: 1451 \tTraining Loss: 0.045071 \tValidation Loss: 0.157134\n",
      "Earlystopping Patience Counter: 548\n",
      "Epoch: 1452 \tTraining Loss: 0.044756 \tValidation Loss: 0.159361\n",
      "Earlystopping Patience Counter: 549\n",
      "Epoch: 1453 \tTraining Loss: 0.045143 \tValidation Loss: 0.157710\n",
      "Earlystopping Patience Counter: 550\n",
      "Epoch: 1454 \tTraining Loss: 0.045964 \tValidation Loss: 0.157282\n",
      "Earlystopping Patience Counter: 551\n",
      "Epoch: 1455 \tTraining Loss: 0.045447 \tValidation Loss: 0.159188\n",
      "Earlystopping Patience Counter: 552\n",
      "Epoch: 1456 \tTraining Loss: 0.047081 \tValidation Loss: 0.170418\n",
      "Earlystopping Patience Counter: 553\n",
      "Epoch: 1457 \tTraining Loss: 0.045909 \tValidation Loss: 0.158849\n",
      "Earlystopping Patience Counter: 554\n",
      "Epoch: 1458 \tTraining Loss: 0.045260 \tValidation Loss: 0.157778\n",
      "Earlystopping Patience Counter: 555\n",
      "Epoch: 1459 \tTraining Loss: 0.044675 \tValidation Loss: 0.159004\n",
      "Earlystopping Patience Counter: 556\n",
      "Epoch: 1460 \tTraining Loss: 0.045033 \tValidation Loss: 0.157167\n",
      "Earlystopping Patience Counter: 557\n",
      "Epoch: 1461 \tTraining Loss: 0.044309 \tValidation Loss: 0.162103\n",
      "Earlystopping Patience Counter: 558\n",
      "Epoch: 1462 \tTraining Loss: 0.045473 \tValidation Loss: 0.157673\n",
      "Earlystopping Patience Counter: 559\n",
      "Epoch: 1463 \tTraining Loss: 0.044770 \tValidation Loss: 0.159742\n",
      "Earlystopping Patience Counter: 560\n",
      "Epoch: 1464 \tTraining Loss: 0.044951 \tValidation Loss: 0.161479\n",
      "Earlystopping Patience Counter: 561\n",
      "Epoch: 1465 \tTraining Loss: 0.044915 \tValidation Loss: 0.160862\n",
      "Earlystopping Patience Counter: 562\n",
      "Epoch: 1466 \tTraining Loss: 0.044456 \tValidation Loss: 0.158865\n",
      "Earlystopping Patience Counter: 563\n",
      "Epoch: 1467 \tTraining Loss: 0.043871 \tValidation Loss: 0.161802\n",
      "Earlystopping Patience Counter: 564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1468 \tTraining Loss: 0.044489 \tValidation Loss: 0.158128\n",
      "Earlystopping Patience Counter: 565\n",
      "Epoch: 1469 \tTraining Loss: 0.044750 \tValidation Loss: 0.159325\n",
      "Earlystopping Patience Counter: 566\n",
      "Epoch: 1470 \tTraining Loss: 0.044651 \tValidation Loss: 0.159568\n",
      "Earlystopping Patience Counter: 567\n",
      "Epoch: 1471 \tTraining Loss: 0.044941 \tValidation Loss: 0.159432\n",
      "Earlystopping Patience Counter: 568\n",
      "Epoch: 1472 \tTraining Loss: 0.044727 \tValidation Loss: 0.160939\n",
      "Earlystopping Patience Counter: 569\n",
      "Epoch: 1473 \tTraining Loss: 0.045259 \tValidation Loss: 0.161631\n",
      "Earlystopping Patience Counter: 570\n",
      "Epoch: 1474 \tTraining Loss: 0.045237 \tValidation Loss: 0.158994\n",
      "Earlystopping Patience Counter: 571\n",
      "Epoch: 1475 \tTraining Loss: 0.044353 \tValidation Loss: 0.159704\n",
      "Earlystopping Patience Counter: 572\n",
      "Epoch: 1476 \tTraining Loss: 0.045130 \tValidation Loss: 0.161356\n",
      "Earlystopping Patience Counter: 573\n",
      "Epoch: 1477 \tTraining Loss: 0.044028 \tValidation Loss: 0.162709\n",
      "Earlystopping Patience Counter: 574\n",
      "Epoch: 1478 \tTraining Loss: 0.045225 \tValidation Loss: 0.161521\n",
      "Earlystopping Patience Counter: 575\n",
      "Epoch: 1479 \tTraining Loss: 0.047465 \tValidation Loss: 0.159097\n",
      "Earlystopping Patience Counter: 576\n",
      "Epoch: 1480 \tTraining Loss: 0.044123 \tValidation Loss: 0.172595\n",
      "Earlystopping Patience Counter: 577\n",
      "Epoch: 1481 \tTraining Loss: 0.044684 \tValidation Loss: 0.159710\n",
      "Earlystopping Patience Counter: 578\n",
      "Epoch: 1482 \tTraining Loss: 0.043951 \tValidation Loss: 0.160307\n",
      "Earlystopping Patience Counter: 579\n",
      "Epoch: 1483 \tTraining Loss: 0.043980 \tValidation Loss: 0.158664\n",
      "Earlystopping Patience Counter: 580\n",
      "Epoch: 1484 \tTraining Loss: 0.045186 \tValidation Loss: 0.166977\n",
      "Earlystopping Patience Counter: 581\n",
      "Epoch: 1485 \tTraining Loss: 0.044342 \tValidation Loss: 0.161065\n",
      "Earlystopping Patience Counter: 582\n",
      "Epoch: 1486 \tTraining Loss: 0.044683 \tValidation Loss: 0.166572\n",
      "Earlystopping Patience Counter: 583\n",
      "Epoch: 1487 \tTraining Loss: 0.044142 \tValidation Loss: 0.159547\n",
      "Earlystopping Patience Counter: 584\n",
      "Epoch: 1488 \tTraining Loss: 0.044460 \tValidation Loss: 0.164262\n",
      "Earlystopping Patience Counter: 585\n",
      "Epoch: 1489 \tTraining Loss: 0.043612 \tValidation Loss: 0.159373\n",
      "Earlystopping Patience Counter: 586\n",
      "Epoch: 1490 \tTraining Loss: 0.043343 \tValidation Loss: 0.159515\n",
      "Earlystopping Patience Counter: 587\n",
      "Epoch: 1491 \tTraining Loss: 0.044048 \tValidation Loss: 0.162911\n",
      "Earlystopping Patience Counter: 588\n",
      "Epoch: 1492 \tTraining Loss: 0.043700 \tValidation Loss: 0.161356\n",
      "Earlystopping Patience Counter: 589\n",
      "Epoch: 1493 \tTraining Loss: 0.043260 \tValidation Loss: 0.160449\n",
      "Earlystopping Patience Counter: 590\n",
      "Epoch: 1494 \tTraining Loss: 0.043400 \tValidation Loss: 0.159901\n",
      "Earlystopping Patience Counter: 591\n",
      "Epoch: 1495 \tTraining Loss: 0.045375 \tValidation Loss: 0.159217\n",
      "Earlystopping Patience Counter: 592\n",
      "Epoch: 1496 \tTraining Loss: 0.043189 \tValidation Loss: 0.159634\n",
      "Earlystopping Patience Counter: 593\n",
      "Epoch: 1497 \tTraining Loss: 0.043225 \tValidation Loss: 0.163970\n",
      "Earlystopping Patience Counter: 594\n",
      "Epoch: 1498 \tTraining Loss: 0.042857 \tValidation Loss: 0.159398\n",
      "Earlystopping Patience Counter: 595\n",
      "Epoch: 1499 \tTraining Loss: 0.043894 \tValidation Loss: 0.162249\n",
      "Earlystopping Patience Counter: 596\n",
      "Epoch: 1500 \tTraining Loss: 0.043949 \tValidation Loss: 0.161309\n",
      "Earlystopping Patience Counter: 597\n",
      "Epoch: 1501 \tTraining Loss: 0.043372 \tValidation Loss: 0.161628\n",
      "Earlystopping Patience Counter: 598\n",
      "Epoch: 1502 \tTraining Loss: 0.042052 \tValidation Loss: 0.160131\n",
      "Earlystopping Patience Counter: 599\n",
      "Epoch: 1503 \tTraining Loss: 0.043248 \tValidation Loss: 0.160698\n",
      "Earlystopping Patience Counter: 600\n",
      "Epoch: 1504 \tTraining Loss: 0.044982 \tValidation Loss: 0.168662\n",
      "Earlystopping Patience Counter: 601\n",
      "Epoch: 1505 \tTraining Loss: 0.043296 \tValidation Loss: 0.159972\n",
      "Earlystopping Patience Counter: 602\n",
      "Epoch: 1506 \tTraining Loss: 0.042846 \tValidation Loss: 0.161920\n",
      "Earlystopping Patience Counter: 603\n",
      "Epoch: 1507 \tTraining Loss: 0.042217 \tValidation Loss: 0.165892\n",
      "Earlystopping Patience Counter: 604\n",
      "Epoch: 1508 \tTraining Loss: 0.042811 \tValidation Loss: 0.159729\n",
      "Earlystopping Patience Counter: 605\n",
      "Epoch: 1509 \tTraining Loss: 0.043165 \tValidation Loss: 0.160660\n",
      "Earlystopping Patience Counter: 606\n",
      "Epoch: 1510 \tTraining Loss: 0.044045 \tValidation Loss: 0.160129\n",
      "Earlystopping Patience Counter: 607\n",
      "Epoch: 1511 \tTraining Loss: 0.043029 \tValidation Loss: 0.159588\n",
      "Earlystopping Patience Counter: 608\n",
      "Epoch: 1512 \tTraining Loss: 0.043049 \tValidation Loss: 0.160226\n",
      "Earlystopping Patience Counter: 609\n",
      "Epoch: 1513 \tTraining Loss: 0.042587 \tValidation Loss: 0.163734\n",
      "Earlystopping Patience Counter: 610\n",
      "Epoch: 1514 \tTraining Loss: 0.042474 \tValidation Loss: 0.162340\n",
      "Earlystopping Patience Counter: 611\n",
      "Epoch: 1515 \tTraining Loss: 0.042709 \tValidation Loss: 0.162783\n",
      "Earlystopping Patience Counter: 612\n",
      "Epoch: 1516 \tTraining Loss: 0.042802 \tValidation Loss: 0.164042\n",
      "Earlystopping Patience Counter: 613\n",
      "Epoch: 1517 \tTraining Loss: 0.042853 \tValidation Loss: 0.161779\n",
      "Earlystopping Patience Counter: 614\n",
      "Epoch: 1518 \tTraining Loss: 0.042561 \tValidation Loss: 0.162480\n",
      "Earlystopping Patience Counter: 615\n",
      "Epoch: 1519 \tTraining Loss: 0.042991 \tValidation Loss: 0.161669\n",
      "Earlystopping Patience Counter: 616\n",
      "Epoch: 1520 \tTraining Loss: 0.042221 \tValidation Loss: 0.160446\n",
      "Earlystopping Patience Counter: 617\n",
      "Epoch: 1521 \tTraining Loss: 0.042499 \tValidation Loss: 0.161614\n",
      "Earlystopping Patience Counter: 618\n",
      "Epoch: 1522 \tTraining Loss: 0.041794 \tValidation Loss: 0.164517\n",
      "Earlystopping Patience Counter: 619\n",
      "Epoch: 1523 \tTraining Loss: 0.042736 \tValidation Loss: 0.164548\n",
      "Earlystopping Patience Counter: 620\n",
      "Epoch: 1524 \tTraining Loss: 0.042536 \tValidation Loss: 0.162235\n",
      "Earlystopping Patience Counter: 621\n",
      "Epoch: 1525 \tTraining Loss: 0.042641 \tValidation Loss: 0.162433\n",
      "Earlystopping Patience Counter: 622\n",
      "Epoch: 1526 \tTraining Loss: 0.042073 \tValidation Loss: 0.161379\n",
      "Earlystopping Patience Counter: 623\n",
      "Epoch: 1527 \tTraining Loss: 0.042642 \tValidation Loss: 0.161066\n",
      "Earlystopping Patience Counter: 624\n",
      "Epoch: 1528 \tTraining Loss: 0.042257 \tValidation Loss: 0.160607\n",
      "Earlystopping Patience Counter: 625\n",
      "Epoch: 1529 \tTraining Loss: 0.042093 \tValidation Loss: 0.163719\n",
      "Earlystopping Patience Counter: 626\n",
      "Epoch: 1530 \tTraining Loss: 0.042549 \tValidation Loss: 0.166669\n",
      "Earlystopping Patience Counter: 627\n",
      "Epoch: 1531 \tTraining Loss: 0.042083 \tValidation Loss: 0.164486\n",
      "Earlystopping Patience Counter: 628\n",
      "Epoch: 1532 \tTraining Loss: 0.041720 \tValidation Loss: 0.161108\n",
      "Earlystopping Patience Counter: 629\n",
      "Epoch: 1533 \tTraining Loss: 0.041712 \tValidation Loss: 0.163388\n",
      "Earlystopping Patience Counter: 630\n",
      "Epoch: 1534 \tTraining Loss: 0.042063 \tValidation Loss: 0.164944\n",
      "Earlystopping Patience Counter: 631\n",
      "Epoch: 1535 \tTraining Loss: 0.041826 \tValidation Loss: 0.167968\n",
      "Earlystopping Patience Counter: 632\n",
      "Epoch: 1536 \tTraining Loss: 0.041660 \tValidation Loss: 0.161640\n",
      "Earlystopping Patience Counter: 633\n",
      "Epoch: 1537 \tTraining Loss: 0.041587 \tValidation Loss: 0.163033\n",
      "Earlystopping Patience Counter: 634\n",
      "Epoch: 1538 \tTraining Loss: 0.041699 \tValidation Loss: 0.162767\n",
      "Earlystopping Patience Counter: 635\n",
      "Epoch: 1539 \tTraining Loss: 0.042387 \tValidation Loss: 0.161744\n",
      "Earlystopping Patience Counter: 636\n",
      "Epoch: 1540 \tTraining Loss: 0.041802 \tValidation Loss: 0.161739\n",
      "Earlystopping Patience Counter: 637\n",
      "Epoch: 1541 \tTraining Loss: 0.041701 \tValidation Loss: 0.160248\n",
      "Earlystopping Patience Counter: 638\n",
      "Epoch: 1542 \tTraining Loss: 0.042235 \tValidation Loss: 0.162458\n",
      "Earlystopping Patience Counter: 639\n",
      "Epoch: 1543 \tTraining Loss: 0.042253 \tValidation Loss: 0.169357\n",
      "Earlystopping Patience Counter: 640\n",
      "Epoch: 1544 \tTraining Loss: 0.041978 \tValidation Loss: 0.160997\n",
      "Earlystopping Patience Counter: 641\n",
      "Epoch: 1545 \tTraining Loss: 0.041538 \tValidation Loss: 0.160905\n",
      "Earlystopping Patience Counter: 642\n",
      "Epoch: 1546 \tTraining Loss: 0.041448 \tValidation Loss: 0.166344\n",
      "Earlystopping Patience Counter: 643\n",
      "Epoch: 1547 \tTraining Loss: 0.041549 \tValidation Loss: 0.163454\n",
      "Earlystopping Patience Counter: 644\n",
      "Epoch: 1548 \tTraining Loss: 0.041809 \tValidation Loss: 0.160910\n",
      "Earlystopping Patience Counter: 645\n",
      "Epoch: 1549 \tTraining Loss: 0.041329 \tValidation Loss: 0.164078\n",
      "Earlystopping Patience Counter: 646\n",
      "Epoch: 1550 \tTraining Loss: 0.041172 \tValidation Loss: 0.163324\n",
      "Earlystopping Patience Counter: 647\n",
      "Epoch: 1551 \tTraining Loss: 0.041426 \tValidation Loss: 0.161189\n",
      "Earlystopping Patience Counter: 648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1552 \tTraining Loss: 0.041505 \tValidation Loss: 0.161445\n",
      "Earlystopping Patience Counter: 649\n",
      "Epoch: 1553 \tTraining Loss: 0.041167 \tValidation Loss: 0.164511\n",
      "Earlystopping Patience Counter: 650\n",
      "Epoch: 1554 \tTraining Loss: 0.040693 \tValidation Loss: 0.161273\n",
      "Earlystopping Patience Counter: 651\n",
      "Epoch: 1555 \tTraining Loss: 0.041085 \tValidation Loss: 0.162192\n",
      "Earlystopping Patience Counter: 652\n",
      "Epoch: 1556 \tTraining Loss: 0.041573 \tValidation Loss: 0.162342\n",
      "Earlystopping Patience Counter: 653\n",
      "Epoch: 1557 \tTraining Loss: 0.041042 \tValidation Loss: 0.161999\n",
      "Earlystopping Patience Counter: 654\n",
      "Epoch: 1558 \tTraining Loss: 0.041203 \tValidation Loss: 0.161849\n",
      "Earlystopping Patience Counter: 655\n",
      "Epoch: 1559 \tTraining Loss: 0.040968 \tValidation Loss: 0.161733\n",
      "Earlystopping Patience Counter: 656\n",
      "Epoch: 1560 \tTraining Loss: 0.040631 \tValidation Loss: 0.166692\n",
      "Earlystopping Patience Counter: 657\n",
      "Epoch: 1561 \tTraining Loss: 0.040562 \tValidation Loss: 0.162983\n",
      "Earlystopping Patience Counter: 658\n",
      "Epoch: 1562 \tTraining Loss: 0.040934 \tValidation Loss: 0.161331\n",
      "Earlystopping Patience Counter: 659\n",
      "Epoch: 1563 \tTraining Loss: 0.044745 \tValidation Loss: 0.160402\n",
      "Earlystopping Patience Counter: 660\n",
      "Epoch: 1564 \tTraining Loss: 0.041354 \tValidation Loss: 0.160428\n",
      "Earlystopping Patience Counter: 661\n",
      "Epoch: 1565 \tTraining Loss: 0.040491 \tValidation Loss: 0.160332\n",
      "Earlystopping Patience Counter: 662\n",
      "Epoch: 1566 \tTraining Loss: 0.040534 \tValidation Loss: 0.164576\n",
      "Earlystopping Patience Counter: 663\n",
      "Epoch: 1567 \tTraining Loss: 0.040510 \tValidation Loss: 0.165155\n",
      "Earlystopping Patience Counter: 664\n",
      "Epoch: 1568 \tTraining Loss: 0.040746 \tValidation Loss: 0.166541\n",
      "Earlystopping Patience Counter: 665\n",
      "Epoch: 1569 \tTraining Loss: 0.040877 \tValidation Loss: 0.162459\n",
      "Earlystopping Patience Counter: 666\n",
      "Epoch: 1570 \tTraining Loss: 0.040763 \tValidation Loss: 0.164875\n",
      "Earlystopping Patience Counter: 667\n",
      "Epoch: 1571 \tTraining Loss: 0.041086 \tValidation Loss: 0.162697\n",
      "Earlystopping Patience Counter: 668\n",
      "Epoch: 1572 \tTraining Loss: 0.040705 \tValidation Loss: 0.166115\n",
      "Earlystopping Patience Counter: 669\n",
      "Epoch: 1573 \tTraining Loss: 0.040579 \tValidation Loss: 0.165388\n",
      "Earlystopping Patience Counter: 670\n",
      "Epoch: 1574 \tTraining Loss: 0.040780 \tValidation Loss: 0.162233\n",
      "Earlystopping Patience Counter: 671\n",
      "Epoch: 1575 \tTraining Loss: 0.040185 \tValidation Loss: 0.161950\n",
      "Earlystopping Patience Counter: 672\n",
      "Epoch: 1576 \tTraining Loss: 0.040766 \tValidation Loss: 0.163151\n",
      "Earlystopping Patience Counter: 673\n",
      "Epoch: 1577 \tTraining Loss: 0.040280 \tValidation Loss: 0.163465\n",
      "Earlystopping Patience Counter: 674\n",
      "Epoch: 1578 \tTraining Loss: 0.040902 \tValidation Loss: 0.163221\n",
      "Earlystopping Patience Counter: 675\n",
      "Epoch: 1579 \tTraining Loss: 0.041104 \tValidation Loss: 0.161535\n",
      "Earlystopping Patience Counter: 676\n",
      "Epoch: 1580 \tTraining Loss: 0.041070 \tValidation Loss: 0.161353\n",
      "Earlystopping Patience Counter: 677\n",
      "Epoch: 1581 \tTraining Loss: 0.040484 \tValidation Loss: 0.161835\n",
      "Earlystopping Patience Counter: 678\n",
      "Epoch: 1582 \tTraining Loss: 0.040304 \tValidation Loss: 0.163287\n",
      "Earlystopping Patience Counter: 679\n",
      "Epoch: 1583 \tTraining Loss: 0.040305 \tValidation Loss: 0.163151\n",
      "Earlystopping Patience Counter: 680\n",
      "Epoch: 1584 \tTraining Loss: 0.040910 \tValidation Loss: 0.162384\n",
      "Earlystopping Patience Counter: 681\n",
      "Epoch: 1585 \tTraining Loss: 0.040820 \tValidation Loss: 0.162142\n",
      "Earlystopping Patience Counter: 682\n",
      "Epoch: 1586 \tTraining Loss: 0.039839 \tValidation Loss: 0.166699\n",
      "Earlystopping Patience Counter: 683\n",
      "Epoch: 1587 \tTraining Loss: 0.040036 \tValidation Loss: 0.164582\n",
      "Earlystopping Patience Counter: 684\n",
      "Epoch: 1588 \tTraining Loss: 0.039495 \tValidation Loss: 0.166884\n",
      "Earlystopping Patience Counter: 685\n",
      "Epoch: 1589 \tTraining Loss: 0.040334 \tValidation Loss: 0.163697\n",
      "Earlystopping Patience Counter: 686\n",
      "Epoch: 1590 \tTraining Loss: 0.040403 \tValidation Loss: 0.164423\n",
      "Earlystopping Patience Counter: 687\n",
      "Epoch: 1591 \tTraining Loss: 0.039748 \tValidation Loss: 0.166797\n",
      "Earlystopping Patience Counter: 688\n",
      "Epoch: 1592 \tTraining Loss: 0.039451 \tValidation Loss: 0.165145\n",
      "Earlystopping Patience Counter: 689\n",
      "Epoch: 1593 \tTraining Loss: 0.039579 \tValidation Loss: 0.162793\n",
      "Earlystopping Patience Counter: 690\n",
      "Epoch: 1594 \tTraining Loss: 0.039694 \tValidation Loss: 0.164444\n",
      "Earlystopping Patience Counter: 691\n",
      "Epoch: 1595 \tTraining Loss: 0.039687 \tValidation Loss: 0.162826\n",
      "Earlystopping Patience Counter: 692\n",
      "Epoch: 1596 \tTraining Loss: 0.039600 \tValidation Loss: 0.163871\n",
      "Earlystopping Patience Counter: 693\n",
      "Epoch: 1597 \tTraining Loss: 0.039362 \tValidation Loss: 0.162462\n",
      "Earlystopping Patience Counter: 694\n",
      "Epoch: 1598 \tTraining Loss: 0.039693 \tValidation Loss: 0.166852\n",
      "Earlystopping Patience Counter: 695\n",
      "Epoch: 1599 \tTraining Loss: 0.039698 \tValidation Loss: 0.166256\n",
      "Earlystopping Patience Counter: 696\n",
      "Epoch: 1600 \tTraining Loss: 0.040580 \tValidation Loss: 0.164199\n",
      "Earlystopping Patience Counter: 697\n",
      "Epoch: 1601 \tTraining Loss: 0.039448 \tValidation Loss: 0.164062\n",
      "Earlystopping Patience Counter: 698\n",
      "Epoch: 1602 \tTraining Loss: 0.039468 \tValidation Loss: 0.163661\n",
      "Earlystopping Patience Counter: 699\n",
      "Epoch: 1603 \tTraining Loss: 0.039284 \tValidation Loss: 0.166768\n",
      "Earlystopping Patience Counter: 700\n",
      "Epoch: 1604 \tTraining Loss: 0.039133 \tValidation Loss: 0.162277\n",
      "Earlystopping Patience Counter: 701\n",
      "Epoch: 1605 \tTraining Loss: 0.039122 \tValidation Loss: 0.163781\n",
      "Earlystopping Patience Counter: 702\n",
      "Epoch: 1606 \tTraining Loss: 0.039204 \tValidation Loss: 0.162131\n",
      "Earlystopping Patience Counter: 703\n",
      "Epoch: 1607 \tTraining Loss: 0.039175 \tValidation Loss: 0.162698\n",
      "Earlystopping Patience Counter: 704\n",
      "Epoch: 1608 \tTraining Loss: 0.039471 \tValidation Loss: 0.163818\n",
      "Earlystopping Patience Counter: 705\n",
      "Epoch: 1609 \tTraining Loss: 0.039420 \tValidation Loss: 0.162793\n",
      "Earlystopping Patience Counter: 706\n",
      "Epoch: 1610 \tTraining Loss: 0.039480 \tValidation Loss: 0.165434\n",
      "Earlystopping Patience Counter: 707\n",
      "Epoch: 1611 \tTraining Loss: 0.039104 \tValidation Loss: 0.164358\n",
      "Earlystopping Patience Counter: 708\n",
      "Epoch: 1612 \tTraining Loss: 0.039420 \tValidation Loss: 0.166494\n",
      "Earlystopping Patience Counter: 709\n",
      "Epoch: 1613 \tTraining Loss: 0.038865 \tValidation Loss: 0.163787\n",
      "Earlystopping Patience Counter: 710\n",
      "Epoch: 1614 \tTraining Loss: 0.039071 \tValidation Loss: 0.165592\n",
      "Earlystopping Patience Counter: 711\n",
      "Epoch: 1615 \tTraining Loss: 0.038910 \tValidation Loss: 0.166725\n",
      "Earlystopping Patience Counter: 712\n",
      "Epoch: 1616 \tTraining Loss: 0.038591 \tValidation Loss: 0.163192\n",
      "Earlystopping Patience Counter: 713\n",
      "Epoch: 1617 \tTraining Loss: 0.039147 \tValidation Loss: 0.164727\n",
      "Earlystopping Patience Counter: 714\n",
      "Epoch: 1618 \tTraining Loss: 0.038803 \tValidation Loss: 0.168874\n",
      "Earlystopping Patience Counter: 715\n",
      "Epoch: 1619 \tTraining Loss: 0.038639 \tValidation Loss: 0.164215\n",
      "Earlystopping Patience Counter: 716\n",
      "Epoch: 1620 \tTraining Loss: 0.039029 \tValidation Loss: 0.164838\n",
      "Earlystopping Patience Counter: 717\n",
      "Epoch: 1621 \tTraining Loss: 0.039007 \tValidation Loss: 0.165690\n",
      "Earlystopping Patience Counter: 718\n",
      "Epoch: 1622 \tTraining Loss: 0.038976 \tValidation Loss: 0.164625\n",
      "Earlystopping Patience Counter: 719\n",
      "Epoch: 1623 \tTraining Loss: 0.038547 \tValidation Loss: 0.166522\n",
      "Earlystopping Patience Counter: 720\n",
      "Epoch: 1624 \tTraining Loss: 0.038596 \tValidation Loss: 0.164654\n",
      "Earlystopping Patience Counter: 721\n",
      "Epoch: 1625 \tTraining Loss: 0.038397 \tValidation Loss: 0.170248\n",
      "Earlystopping Patience Counter: 722\n",
      "Epoch: 1626 \tTraining Loss: 0.038501 \tValidation Loss: 0.164357\n",
      "Earlystopping Patience Counter: 723\n",
      "Epoch: 1627 \tTraining Loss: 0.038499 \tValidation Loss: 0.164287\n",
      "Earlystopping Patience Counter: 724\n",
      "Epoch: 1628 \tTraining Loss: 0.038836 \tValidation Loss: 0.166019\n",
      "Earlystopping Patience Counter: 725\n",
      "Epoch: 1629 \tTraining Loss: 0.038534 \tValidation Loss: 0.168444\n",
      "Earlystopping Patience Counter: 726\n",
      "Epoch: 1630 \tTraining Loss: 0.038803 \tValidation Loss: 0.164037\n",
      "Earlystopping Patience Counter: 727\n",
      "Epoch: 1631 \tTraining Loss: 0.038655 \tValidation Loss: 0.164462\n",
      "Earlystopping Patience Counter: 728\n",
      "Epoch: 1632 \tTraining Loss: 0.038328 \tValidation Loss: 0.163848\n",
      "Earlystopping Patience Counter: 729\n",
      "Epoch: 1633 \tTraining Loss: 0.039005 \tValidation Loss: 0.163725\n",
      "Earlystopping Patience Counter: 730\n",
      "Epoch: 1634 \tTraining Loss: 0.038458 \tValidation Loss: 0.166572\n",
      "Earlystopping Patience Counter: 731\n",
      "Epoch: 1635 \tTraining Loss: 0.038259 \tValidation Loss: 0.166759\n",
      "Earlystopping Patience Counter: 732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1636 \tTraining Loss: 0.038276 \tValidation Loss: 0.164452\n",
      "Earlystopping Patience Counter: 733\n",
      "Epoch: 1637 \tTraining Loss: 0.038574 \tValidation Loss: 0.165359\n",
      "Earlystopping Patience Counter: 734\n",
      "Epoch: 1638 \tTraining Loss: 0.038003 \tValidation Loss: 0.167933\n",
      "Earlystopping Patience Counter: 735\n",
      "Epoch: 1639 \tTraining Loss: 0.037774 \tValidation Loss: 0.164131\n",
      "Earlystopping Patience Counter: 736\n",
      "Epoch: 1640 \tTraining Loss: 0.038315 \tValidation Loss: 0.164996\n",
      "Earlystopping Patience Counter: 737\n",
      "Epoch: 1641 \tTraining Loss: 0.044919 \tValidation Loss: 0.177657\n",
      "Earlystopping Patience Counter: 738\n",
      "Epoch: 1642 \tTraining Loss: 0.038550 \tValidation Loss: 0.166403\n",
      "Earlystopping Patience Counter: 739\n",
      "Epoch: 1643 \tTraining Loss: 0.038050 \tValidation Loss: 0.167151\n",
      "Earlystopping Patience Counter: 740\n",
      "Epoch: 1644 \tTraining Loss: 0.040156 \tValidation Loss: 0.175432\n",
      "Earlystopping Patience Counter: 741\n",
      "Epoch: 1645 \tTraining Loss: 0.039130 \tValidation Loss: 0.167988\n",
      "Earlystopping Patience Counter: 742\n",
      "Epoch: 1646 \tTraining Loss: 0.037892 \tValidation Loss: 0.165213\n",
      "Earlystopping Patience Counter: 743\n",
      "Epoch: 1647 \tTraining Loss: 0.038336 \tValidation Loss: 0.163795\n",
      "Earlystopping Patience Counter: 744\n",
      "Epoch: 1648 \tTraining Loss: 0.037601 \tValidation Loss: 0.169567\n",
      "Earlystopping Patience Counter: 745\n",
      "Epoch: 1649 \tTraining Loss: 0.037872 \tValidation Loss: 0.164169\n",
      "Earlystopping Patience Counter: 746\n",
      "Epoch: 1650 \tTraining Loss: 0.037740 \tValidation Loss: 0.164989\n",
      "Earlystopping Patience Counter: 747\n",
      "Epoch: 1651 \tTraining Loss: 0.037952 \tValidation Loss: 0.166364\n",
      "Earlystopping Patience Counter: 748\n",
      "Epoch: 1652 \tTraining Loss: 0.037308 \tValidation Loss: 0.167581\n",
      "Earlystopping Patience Counter: 749\n",
      "Epoch: 1653 \tTraining Loss: 0.038107 \tValidation Loss: 0.165774\n",
      "Earlystopping Patience Counter: 750\n",
      "Epoch: 1654 \tTraining Loss: 0.037676 \tValidation Loss: 0.164782\n",
      "Earlystopping Patience Counter: 751\n",
      "Epoch: 1655 \tTraining Loss: 0.037595 \tValidation Loss: 0.168918\n",
      "Earlystopping Patience Counter: 752\n",
      "Epoch: 1656 \tTraining Loss: 0.037728 \tValidation Loss: 0.165051\n",
      "Earlystopping Patience Counter: 753\n",
      "Epoch: 1657 \tTraining Loss: 0.037475 \tValidation Loss: 0.166098\n",
      "Earlystopping Patience Counter: 754\n",
      "Epoch: 1658 \tTraining Loss: 0.038086 \tValidation Loss: 0.164277\n",
      "Earlystopping Patience Counter: 755\n",
      "Epoch: 1659 \tTraining Loss: 0.037459 \tValidation Loss: 0.164598\n",
      "Earlystopping Patience Counter: 756\n",
      "Epoch: 1660 \tTraining Loss: 0.037395 \tValidation Loss: 0.170502\n",
      "Earlystopping Patience Counter: 757\n",
      "Epoch: 1661 \tTraining Loss: 0.037558 \tValidation Loss: 0.166078\n",
      "Earlystopping Patience Counter: 758\n",
      "Epoch: 1662 \tTraining Loss: 0.037350 \tValidation Loss: 0.172278\n",
      "Earlystopping Patience Counter: 759\n",
      "Epoch: 1663 \tTraining Loss: 0.037713 \tValidation Loss: 0.166590\n",
      "Earlystopping Patience Counter: 760\n",
      "Epoch: 1664 \tTraining Loss: 0.037001 \tValidation Loss: 0.168548\n",
      "Earlystopping Patience Counter: 761\n",
      "Epoch: 1665 \tTraining Loss: 0.037167 \tValidation Loss: 0.165883\n",
      "Earlystopping Patience Counter: 762\n",
      "Epoch: 1666 \tTraining Loss: 0.037071 \tValidation Loss: 0.169445\n",
      "Earlystopping Patience Counter: 763\n",
      "Epoch: 1667 \tTraining Loss: 0.037283 \tValidation Loss: 0.165986\n",
      "Earlystopping Patience Counter: 764\n",
      "Epoch: 1668 \tTraining Loss: 0.037245 \tValidation Loss: 0.166745\n",
      "Earlystopping Patience Counter: 765\n",
      "Epoch: 1669 \tTraining Loss: 0.036999 \tValidation Loss: 0.165742\n",
      "Earlystopping Patience Counter: 766\n",
      "Epoch: 1670 \tTraining Loss: 0.037690 \tValidation Loss: 0.166363\n",
      "Earlystopping Patience Counter: 767\n",
      "Epoch: 1671 \tTraining Loss: 0.037142 \tValidation Loss: 0.166379\n",
      "Earlystopping Patience Counter: 768\n",
      "Epoch: 1672 \tTraining Loss: 0.036888 \tValidation Loss: 0.164878\n",
      "Earlystopping Patience Counter: 769\n",
      "Epoch: 1673 \tTraining Loss: 0.036972 \tValidation Loss: 0.170558\n",
      "Earlystopping Patience Counter: 770\n",
      "Epoch: 1674 \tTraining Loss: 0.037335 \tValidation Loss: 0.165856\n",
      "Earlystopping Patience Counter: 771\n",
      "Epoch: 1675 \tTraining Loss: 0.037058 \tValidation Loss: 0.172311\n",
      "Earlystopping Patience Counter: 772\n",
      "Epoch: 1676 \tTraining Loss: 0.036707 \tValidation Loss: 0.165370\n",
      "Earlystopping Patience Counter: 773\n",
      "Epoch: 1677 \tTraining Loss: 0.036820 \tValidation Loss: 0.166607\n",
      "Earlystopping Patience Counter: 774\n",
      "Epoch: 1678 \tTraining Loss: 0.036690 \tValidation Loss: 0.166304\n",
      "Earlystopping Patience Counter: 775\n",
      "Epoch: 1679 \tTraining Loss: 0.036722 \tValidation Loss: 0.165787\n",
      "Earlystopping Patience Counter: 776\n",
      "Epoch: 1680 \tTraining Loss: 0.037490 \tValidation Loss: 0.167247\n",
      "Earlystopping Patience Counter: 777\n",
      "Epoch: 1681 \tTraining Loss: 0.036811 \tValidation Loss: 0.167375\n",
      "Earlystopping Patience Counter: 778\n",
      "Epoch: 1682 \tTraining Loss: 0.037029 \tValidation Loss: 0.167594\n",
      "Earlystopping Patience Counter: 779\n",
      "Epoch: 1683 \tTraining Loss: 0.035518 \tValidation Loss: 0.169223\n",
      "Earlystopping Patience Counter: 780\n",
      "Epoch: 1684 \tTraining Loss: 0.036591 \tValidation Loss: 0.169400\n",
      "Earlystopping Patience Counter: 781\n",
      "Epoch: 1685 \tTraining Loss: 0.036988 \tValidation Loss: 0.169595\n",
      "Earlystopping Patience Counter: 782\n",
      "Epoch: 1686 \tTraining Loss: 0.036362 \tValidation Loss: 0.170311\n",
      "Earlystopping Patience Counter: 783\n",
      "Epoch: 1687 \tTraining Loss: 0.036479 \tValidation Loss: 0.170305\n",
      "Earlystopping Patience Counter: 784\n",
      "Epoch: 1688 \tTraining Loss: 0.036645 \tValidation Loss: 0.168234\n",
      "Earlystopping Patience Counter: 785\n",
      "Epoch: 1689 \tTraining Loss: 0.036364 \tValidation Loss: 0.169687\n",
      "Earlystopping Patience Counter: 786\n",
      "Epoch: 1690 \tTraining Loss: 0.036464 \tValidation Loss: 0.168264\n",
      "Earlystopping Patience Counter: 787\n",
      "Epoch: 1691 \tTraining Loss: 0.037293 \tValidation Loss: 0.167271\n",
      "Earlystopping Patience Counter: 788\n",
      "Epoch: 1692 \tTraining Loss: 0.039145 \tValidation Loss: 0.166372\n",
      "Earlystopping Patience Counter: 789\n",
      "Epoch: 1693 \tTraining Loss: 0.036417 \tValidation Loss: 0.169439\n",
      "Earlystopping Patience Counter: 790\n",
      "Epoch: 1694 \tTraining Loss: 0.036157 \tValidation Loss: 0.167153\n",
      "Earlystopping Patience Counter: 791\n",
      "Epoch: 1695 \tTraining Loss: 0.036378 \tValidation Loss: 0.167280\n",
      "Earlystopping Patience Counter: 792\n",
      "Epoch: 1696 \tTraining Loss: 0.036424 \tValidation Loss: 0.169263\n",
      "Earlystopping Patience Counter: 793\n",
      "Epoch: 1697 \tTraining Loss: 0.036357 \tValidation Loss: 0.166850\n",
      "Earlystopping Patience Counter: 794\n",
      "Epoch: 1698 \tTraining Loss: 0.041264 \tValidation Loss: 0.197672\n",
      "Earlystopping Patience Counter: 795\n",
      "Epoch: 1699 \tTraining Loss: 0.037231 \tValidation Loss: 0.166953\n",
      "Earlystopping Patience Counter: 796\n",
      "Epoch: 1700 \tTraining Loss: 0.036813 \tValidation Loss: 0.165752\n",
      "Earlystopping Patience Counter: 797\n",
      "Epoch: 1701 \tTraining Loss: 0.038918 \tValidation Loss: 0.165944\n",
      "Earlystopping Patience Counter: 798\n",
      "Epoch: 1702 \tTraining Loss: 0.036766 \tValidation Loss: 0.168693\n",
      "Earlystopping Patience Counter: 799\n",
      "Epoch: 1703 \tTraining Loss: 0.035936 \tValidation Loss: 0.166885\n",
      "Earlystopping Patience Counter: 800\n",
      "Epoch: 1704 \tTraining Loss: 0.036641 \tValidation Loss: 0.169905\n",
      "Earlystopping Patience Counter: 801\n",
      "Epoch: 1705 \tTraining Loss: 0.035790 \tValidation Loss: 0.169381\n",
      "Earlystopping Patience Counter: 802\n",
      "Epoch: 1706 \tTraining Loss: 0.039011 \tValidation Loss: 0.167017\n",
      "Earlystopping Patience Counter: 803\n",
      "Epoch: 1707 \tTraining Loss: 0.035931 \tValidation Loss: 0.167606\n",
      "Earlystopping Patience Counter: 804\n",
      "Epoch: 1708 \tTraining Loss: 0.035995 \tValidation Loss: 0.168890\n",
      "Earlystopping Patience Counter: 805\n",
      "Epoch: 1709 \tTraining Loss: 0.035547 \tValidation Loss: 0.165941\n",
      "Earlystopping Patience Counter: 806\n",
      "Epoch: 1710 \tTraining Loss: 0.036523 \tValidation Loss: 0.165146\n",
      "Earlystopping Patience Counter: 807\n",
      "Epoch: 1711 \tTraining Loss: 0.036061 \tValidation Loss: 0.175136\n",
      "Earlystopping Patience Counter: 808\n",
      "Epoch: 1712 \tTraining Loss: 0.035589 \tValidation Loss: 0.168120\n",
      "Earlystopping Patience Counter: 809\n",
      "Epoch: 1713 \tTraining Loss: 0.035812 \tValidation Loss: 0.166642\n",
      "Earlystopping Patience Counter: 810\n",
      "Epoch: 1714 \tTraining Loss: 0.035417 \tValidation Loss: 0.171922\n",
      "Earlystopping Patience Counter: 811\n",
      "Epoch: 1715 \tTraining Loss: 0.037867 \tValidation Loss: 0.171595\n",
      "Earlystopping Patience Counter: 812\n",
      "Epoch: 1716 \tTraining Loss: 0.036448 \tValidation Loss: 0.169491\n",
      "Earlystopping Patience Counter: 813\n",
      "Epoch: 1717 \tTraining Loss: 0.035506 \tValidation Loss: 0.169588\n",
      "Earlystopping Patience Counter: 814\n",
      "Epoch: 1718 \tTraining Loss: 0.035565 \tValidation Loss: 0.169882\n",
      "Earlystopping Patience Counter: 815\n",
      "Epoch: 1719 \tTraining Loss: 0.035267 \tValidation Loss: 0.173686\n",
      "Earlystopping Patience Counter: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1720 \tTraining Loss: 0.035787 \tValidation Loss: 0.173557\n",
      "Earlystopping Patience Counter: 817\n",
      "Epoch: 1721 \tTraining Loss: 0.035909 \tValidation Loss: 0.172312\n",
      "Earlystopping Patience Counter: 818\n",
      "Epoch: 1722 \tTraining Loss: 0.035140 \tValidation Loss: 0.169981\n",
      "Earlystopping Patience Counter: 819\n",
      "Epoch: 1723 \tTraining Loss: 0.035677 \tValidation Loss: 0.167494\n",
      "Earlystopping Patience Counter: 820\n",
      "Epoch: 1724 \tTraining Loss: 0.036068 \tValidation Loss: 0.168470\n",
      "Earlystopping Patience Counter: 821\n",
      "Epoch: 1725 \tTraining Loss: 0.035515 \tValidation Loss: 0.169700\n",
      "Earlystopping Patience Counter: 822\n",
      "Epoch: 1726 \tTraining Loss: 0.035190 \tValidation Loss: 0.168123\n",
      "Earlystopping Patience Counter: 823\n",
      "Epoch: 1727 \tTraining Loss: 0.035204 \tValidation Loss: 0.168246\n",
      "Earlystopping Patience Counter: 824\n",
      "Epoch: 1728 \tTraining Loss: 0.034986 \tValidation Loss: 0.168461\n",
      "Earlystopping Patience Counter: 825\n",
      "Epoch: 1729 \tTraining Loss: 0.034766 \tValidation Loss: 0.171516\n",
      "Earlystopping Patience Counter: 826\n",
      "Epoch: 1730 \tTraining Loss: 0.035367 \tValidation Loss: 0.172616\n",
      "Earlystopping Patience Counter: 827\n",
      "Epoch: 1731 \tTraining Loss: 0.035138 \tValidation Loss: 0.167801\n",
      "Earlystopping Patience Counter: 828\n",
      "Epoch: 1732 \tTraining Loss: 0.035184 \tValidation Loss: 0.168412\n",
      "Earlystopping Patience Counter: 829\n",
      "Epoch: 1733 \tTraining Loss: 0.035047 \tValidation Loss: 0.170684\n",
      "Earlystopping Patience Counter: 830\n",
      "Epoch: 1734 \tTraining Loss: 0.037482 \tValidation Loss: 0.167221\n",
      "Earlystopping Patience Counter: 831\n",
      "Epoch: 1735 \tTraining Loss: 0.035560 \tValidation Loss: 0.169334\n",
      "Earlystopping Patience Counter: 832\n",
      "Epoch: 1736 \tTraining Loss: 0.034672 \tValidation Loss: 0.167934\n",
      "Earlystopping Patience Counter: 833\n",
      "Epoch: 1737 \tTraining Loss: 0.035152 \tValidation Loss: 0.169475\n",
      "Earlystopping Patience Counter: 834\n",
      "Epoch: 1738 \tTraining Loss: 0.038388 \tValidation Loss: 0.188670\n",
      "Earlystopping Patience Counter: 835\n",
      "Epoch: 1739 \tTraining Loss: 0.035477 \tValidation Loss: 0.168958\n",
      "Earlystopping Patience Counter: 836\n",
      "Epoch: 1740 \tTraining Loss: 0.034800 \tValidation Loss: 0.168882\n",
      "Earlystopping Patience Counter: 837\n",
      "Epoch: 1741 \tTraining Loss: 0.035057 \tValidation Loss: 0.171508\n",
      "Earlystopping Patience Counter: 838\n",
      "Epoch: 1742 \tTraining Loss: 0.034172 \tValidation Loss: 0.168475\n",
      "Earlystopping Patience Counter: 839\n",
      "Epoch: 1743 \tTraining Loss: 0.035573 \tValidation Loss: 0.167673\n",
      "Earlystopping Patience Counter: 840\n",
      "Epoch: 1744 \tTraining Loss: 0.034947 \tValidation Loss: 0.168417\n",
      "Earlystopping Patience Counter: 841\n",
      "Epoch: 1745 \tTraining Loss: 0.040025 \tValidation Loss: 0.192977\n",
      "Earlystopping Patience Counter: 842\n",
      "Epoch: 1746 \tTraining Loss: 0.036822 \tValidation Loss: 0.170777\n",
      "Earlystopping Patience Counter: 843\n",
      "Epoch: 1747 \tTraining Loss: 0.034673 \tValidation Loss: 0.170347\n",
      "Earlystopping Patience Counter: 844\n",
      "Epoch: 1748 \tTraining Loss: 0.034291 \tValidation Loss: 0.174274\n",
      "Earlystopping Patience Counter: 845\n",
      "Epoch: 1749 \tTraining Loss: 0.034604 \tValidation Loss: 0.172158\n",
      "Earlystopping Patience Counter: 846\n",
      "Epoch: 1750 \tTraining Loss: 0.034333 \tValidation Loss: 0.169282\n",
      "Earlystopping Patience Counter: 847\n",
      "Epoch: 1751 \tTraining Loss: 0.034619 \tValidation Loss: 0.169977\n",
      "Earlystopping Patience Counter: 848\n",
      "Epoch: 1752 \tTraining Loss: 0.034310 \tValidation Loss: 0.169932\n",
      "Earlystopping Patience Counter: 849\n",
      "Epoch: 1753 \tTraining Loss: 0.037195 \tValidation Loss: 0.171583\n",
      "Earlystopping Patience Counter: 850\n",
      "Epoch: 1754 \tTraining Loss: 0.034851 \tValidation Loss: 0.170344\n",
      "Earlystopping Patience Counter: 851\n",
      "Epoch: 1755 \tTraining Loss: 0.034261 \tValidation Loss: 0.169595\n",
      "Earlystopping Patience Counter: 852\n",
      "Epoch: 1756 \tTraining Loss: 0.033940 \tValidation Loss: 0.169302\n",
      "Earlystopping Patience Counter: 853\n",
      "Epoch: 1757 \tTraining Loss: 0.033616 \tValidation Loss: 0.169327\n",
      "Earlystopping Patience Counter: 854\n",
      "Epoch: 1758 \tTraining Loss: 0.034037 \tValidation Loss: 0.170925\n",
      "Earlystopping Patience Counter: 855\n",
      "Epoch: 1759 \tTraining Loss: 0.033562 \tValidation Loss: 0.170373\n",
      "Earlystopping Patience Counter: 856\n",
      "Epoch: 1760 \tTraining Loss: 0.034405 \tValidation Loss: 0.170991\n",
      "Earlystopping Patience Counter: 857\n",
      "Epoch: 1761 \tTraining Loss: 0.034390 \tValidation Loss: 0.176423\n",
      "Earlystopping Patience Counter: 858\n",
      "Epoch: 1762 \tTraining Loss: 0.035794 \tValidation Loss: 0.169464\n",
      "Earlystopping Patience Counter: 859\n",
      "Epoch: 1763 \tTraining Loss: 0.033470 \tValidation Loss: 0.171029\n",
      "Earlystopping Patience Counter: 860\n",
      "Epoch: 1764 \tTraining Loss: 0.033955 \tValidation Loss: 0.171127\n",
      "Earlystopping Patience Counter: 861\n",
      "Epoch: 1765 \tTraining Loss: 0.033468 \tValidation Loss: 0.177250\n",
      "Earlystopping Patience Counter: 862\n",
      "Epoch: 1766 \tTraining Loss: 0.033985 \tValidation Loss: 0.172424\n",
      "Earlystopping Patience Counter: 863\n",
      "Epoch: 1767 \tTraining Loss: 0.033835 \tValidation Loss: 0.170719\n",
      "Earlystopping Patience Counter: 864\n",
      "Epoch: 1768 \tTraining Loss: 0.033895 \tValidation Loss: 0.169579\n",
      "Earlystopping Patience Counter: 865\n",
      "Epoch: 1769 \tTraining Loss: 0.034564 \tValidation Loss: 0.168811\n",
      "Earlystopping Patience Counter: 866\n",
      "Epoch: 1770 \tTraining Loss: 0.033752 \tValidation Loss: 0.169302\n",
      "Earlystopping Patience Counter: 867\n",
      "Epoch: 1771 \tTraining Loss: 0.033630 \tValidation Loss: 0.169147\n",
      "Earlystopping Patience Counter: 868\n",
      "Epoch: 1772 \tTraining Loss: 0.033723 \tValidation Loss: 0.169956\n",
      "Earlystopping Patience Counter: 869\n",
      "Epoch: 1773 \tTraining Loss: 0.033340 \tValidation Loss: 0.169135\n",
      "Earlystopping Patience Counter: 870\n",
      "Epoch: 1774 \tTraining Loss: 0.033501 \tValidation Loss: 0.171993\n",
      "Earlystopping Patience Counter: 871\n",
      "Epoch: 1775 \tTraining Loss: 0.033528 \tValidation Loss: 0.170443\n",
      "Earlystopping Patience Counter: 872\n",
      "Epoch: 1776 \tTraining Loss: 0.034206 \tValidation Loss: 0.175513\n",
      "Earlystopping Patience Counter: 873\n",
      "Epoch: 1777 \tTraining Loss: 0.035208 \tValidation Loss: 0.179487\n",
      "Earlystopping Patience Counter: 874\n",
      "Epoch: 1778 \tTraining Loss: 0.033532 \tValidation Loss: 0.169930\n",
      "Earlystopping Patience Counter: 875\n",
      "Epoch: 1779 \tTraining Loss: 0.036568 \tValidation Loss: 0.183728\n",
      "Earlystopping Patience Counter: 876\n",
      "Epoch: 1780 \tTraining Loss: 0.034741 \tValidation Loss: 0.173788\n",
      "Earlystopping Patience Counter: 877\n",
      "Epoch: 1781 \tTraining Loss: 0.033673 \tValidation Loss: 0.173123\n",
      "Earlystopping Patience Counter: 878\n",
      "Epoch: 1782 \tTraining Loss: 0.033343 \tValidation Loss: 0.169540\n",
      "Earlystopping Patience Counter: 879\n",
      "Epoch: 1783 \tTraining Loss: 0.033613 \tValidation Loss: 0.169566\n",
      "Earlystopping Patience Counter: 880\n",
      "Epoch: 1784 \tTraining Loss: 0.032673 \tValidation Loss: 0.180443\n",
      "Earlystopping Patience Counter: 881\n",
      "Epoch: 1785 \tTraining Loss: 0.033484 \tValidation Loss: 0.170923\n",
      "Earlystopping Patience Counter: 882\n",
      "Epoch: 1786 \tTraining Loss: 0.034364 \tValidation Loss: 0.175622\n",
      "Earlystopping Patience Counter: 883\n",
      "Epoch: 1787 \tTraining Loss: 0.033663 \tValidation Loss: 0.172660\n",
      "Earlystopping Patience Counter: 884\n",
      "Epoch: 1788 \tTraining Loss: 0.033013 \tValidation Loss: 0.175284\n",
      "Earlystopping Patience Counter: 885\n",
      "Epoch: 1789 \tTraining Loss: 0.033413 \tValidation Loss: 0.169097\n",
      "Earlystopping Patience Counter: 886\n",
      "Epoch: 1790 \tTraining Loss: 0.033234 \tValidation Loss: 0.170058\n",
      "Earlystopping Patience Counter: 887\n",
      "Epoch: 1791 \tTraining Loss: 0.033227 \tValidation Loss: 0.175471\n",
      "Earlystopping Patience Counter: 888\n",
      "Epoch: 1792 \tTraining Loss: 0.033113 \tValidation Loss: 0.170979\n",
      "Earlystopping Patience Counter: 889\n",
      "Epoch: 1793 \tTraining Loss: 0.033808 \tValidation Loss: 0.169834\n",
      "Earlystopping Patience Counter: 890\n",
      "Epoch: 1794 \tTraining Loss: 0.033499 \tValidation Loss: 0.173810\n",
      "Earlystopping Patience Counter: 891\n",
      "Epoch: 1795 \tTraining Loss: 0.033055 \tValidation Loss: 0.171556\n",
      "Earlystopping Patience Counter: 892\n",
      "Epoch: 1796 \tTraining Loss: 0.033351 \tValidation Loss: 0.170505\n",
      "Earlystopping Patience Counter: 893\n",
      "Epoch: 1797 \tTraining Loss: 0.032769 \tValidation Loss: 0.171712\n",
      "Earlystopping Patience Counter: 894\n",
      "Epoch: 1798 \tTraining Loss: 0.032907 \tValidation Loss: 0.171109\n",
      "Earlystopping Patience Counter: 895\n",
      "Epoch: 1799 \tTraining Loss: 0.033046 \tValidation Loss: 0.171040\n",
      "Earlystopping Patience Counter: 896\n",
      "Epoch: 1800 \tTraining Loss: 0.033296 \tValidation Loss: 0.172143\n",
      "Earlystopping Patience Counter: 897\n",
      "Epoch: 1801 \tTraining Loss: 0.032518 \tValidation Loss: 0.170522\n",
      "Earlystopping Patience Counter: 898\n",
      "Epoch: 1802 \tTraining Loss: 0.033258 \tValidation Loss: 0.170571\n",
      "Earlystopping Patience Counter: 899\n",
      "Epoch: 1803 \tTraining Loss: 0.032411 \tValidation Loss: 0.170762\n",
      "Earlystopping Patience Counter: 900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1804 \tTraining Loss: 0.032743 \tValidation Loss: 0.171532\n",
      "Earlystopping Patience Counter: 901\n",
      "Epoch: 1805 \tTraining Loss: 0.032533 \tValidation Loss: 0.171206\n",
      "Earlystopping Patience Counter: 902\n",
      "Epoch: 1806 \tTraining Loss: 0.034629 \tValidation Loss: 0.171282\n",
      "Earlystopping Patience Counter: 903\n",
      "Epoch: 1807 \tTraining Loss: 0.033320 \tValidation Loss: 0.172514\n",
      "Earlystopping Patience Counter: 904\n",
      "Epoch: 1808 \tTraining Loss: 0.032810 \tValidation Loss: 0.173641\n",
      "Earlystopping Patience Counter: 905\n",
      "Epoch: 1809 \tTraining Loss: 0.032440 \tValidation Loss: 0.170370\n",
      "Earlystopping Patience Counter: 906\n",
      "Epoch: 1810 \tTraining Loss: 0.032413 \tValidation Loss: 0.171531\n",
      "Earlystopping Patience Counter: 907\n",
      "Epoch: 1811 \tTraining Loss: 0.032463 \tValidation Loss: 0.173404\n",
      "Earlystopping Patience Counter: 908\n",
      "Epoch: 1812 \tTraining Loss: 0.032385 \tValidation Loss: 0.170745\n",
      "Earlystopping Patience Counter: 909\n",
      "Epoch: 1813 \tTraining Loss: 0.032756 \tValidation Loss: 0.174520\n",
      "Earlystopping Patience Counter: 910\n",
      "Epoch: 1814 \tTraining Loss: 0.032688 \tValidation Loss: 0.171392\n",
      "Earlystopping Patience Counter: 911\n",
      "Epoch: 1815 \tTraining Loss: 0.032330 \tValidation Loss: 0.175066\n",
      "Earlystopping Patience Counter: 912\n",
      "Epoch: 1816 \tTraining Loss: 0.032375 \tValidation Loss: 0.175490\n",
      "Earlystopping Patience Counter: 913\n",
      "Epoch: 1817 \tTraining Loss: 0.032523 \tValidation Loss: 0.173580\n",
      "Earlystopping Patience Counter: 914\n",
      "Epoch: 1818 \tTraining Loss: 0.032802 \tValidation Loss: 0.172648\n",
      "Earlystopping Patience Counter: 915\n",
      "Epoch: 1819 \tTraining Loss: 0.032039 \tValidation Loss: 0.172103\n",
      "Earlystopping Patience Counter: 916\n",
      "Epoch: 1820 \tTraining Loss: 0.033224 \tValidation Loss: 0.174641\n",
      "Earlystopping Patience Counter: 917\n",
      "Epoch: 1821 \tTraining Loss: 0.032787 \tValidation Loss: 0.170508\n",
      "Earlystopping Patience Counter: 918\n",
      "Epoch: 1822 \tTraining Loss: 0.032974 \tValidation Loss: 0.172755\n",
      "Earlystopping Patience Counter: 919\n",
      "Epoch: 1823 \tTraining Loss: 0.032400 \tValidation Loss: 0.172012\n",
      "Earlystopping Patience Counter: 920\n",
      "Epoch: 1824 \tTraining Loss: 0.032236 \tValidation Loss: 0.172103\n",
      "Earlystopping Patience Counter: 921\n",
      "Epoch: 1825 \tTraining Loss: 0.031635 \tValidation Loss: 0.173094\n",
      "Earlystopping Patience Counter: 922\n",
      "Epoch: 1826 \tTraining Loss: 0.032114 \tValidation Loss: 0.172841\n",
      "Earlystopping Patience Counter: 923\n",
      "Epoch: 1827 \tTraining Loss: 0.032252 \tValidation Loss: 0.173322\n",
      "Earlystopping Patience Counter: 924\n",
      "Epoch: 1828 \tTraining Loss: 0.032325 \tValidation Loss: 0.170995\n",
      "Earlystopping Patience Counter: 925\n",
      "Epoch: 1829 \tTraining Loss: 0.031762 \tValidation Loss: 0.177970\n",
      "Earlystopping Patience Counter: 926\n",
      "Epoch: 1830 \tTraining Loss: 0.031428 \tValidation Loss: 0.172853\n",
      "Earlystopping Patience Counter: 927\n",
      "Epoch: 1831 \tTraining Loss: 0.031859 \tValidation Loss: 0.173615\n",
      "Earlystopping Patience Counter: 928\n",
      "Epoch: 1832 \tTraining Loss: 0.031736 \tValidation Loss: 0.173649\n",
      "Earlystopping Patience Counter: 929\n",
      "Epoch: 1833 \tTraining Loss: 0.031897 \tValidation Loss: 0.170757\n",
      "Earlystopping Patience Counter: 930\n",
      "Epoch: 1834 \tTraining Loss: 0.032201 \tValidation Loss: 0.176033\n",
      "Earlystopping Patience Counter: 931\n",
      "Epoch: 1835 \tTraining Loss: 0.032259 \tValidation Loss: 0.175034\n",
      "Earlystopping Patience Counter: 932\n",
      "Epoch: 1836 \tTraining Loss: 0.031160 \tValidation Loss: 0.171297\n",
      "Earlystopping Patience Counter: 933\n",
      "Epoch: 1837 \tTraining Loss: 0.031567 \tValidation Loss: 0.171542\n",
      "Earlystopping Patience Counter: 934\n",
      "Epoch: 1838 \tTraining Loss: 0.031733 \tValidation Loss: 0.172013\n",
      "Earlystopping Patience Counter: 935\n",
      "Epoch: 1839 \tTraining Loss: 0.031839 \tValidation Loss: 0.172992\n",
      "Earlystopping Patience Counter: 936\n",
      "Epoch: 1840 \tTraining Loss: 0.031855 \tValidation Loss: 0.174642\n",
      "Earlystopping Patience Counter: 937\n",
      "Epoch: 1841 \tTraining Loss: 0.034253 \tValidation Loss: 0.173668\n",
      "Earlystopping Patience Counter: 938\n",
      "Epoch: 1842 \tTraining Loss: 0.031415 \tValidation Loss: 0.173897\n",
      "Earlystopping Patience Counter: 939\n",
      "Epoch: 1843 \tTraining Loss: 0.031901 \tValidation Loss: 0.174033\n",
      "Earlystopping Patience Counter: 940\n",
      "Epoch: 1844 \tTraining Loss: 0.031717 \tValidation Loss: 0.170818\n",
      "Earlystopping Patience Counter: 941\n",
      "Epoch: 1845 \tTraining Loss: 0.031878 \tValidation Loss: 0.173577\n",
      "Earlystopping Patience Counter: 942\n",
      "Epoch: 1846 \tTraining Loss: 0.031050 \tValidation Loss: 0.180858\n",
      "Earlystopping Patience Counter: 943\n",
      "Epoch: 1847 \tTraining Loss: 0.031588 \tValidation Loss: 0.176224\n",
      "Earlystopping Patience Counter: 944\n",
      "Epoch: 1848 \tTraining Loss: 0.034576 \tValidation Loss: 0.170017\n",
      "Earlystopping Patience Counter: 945\n",
      "Epoch: 1849 \tTraining Loss: 0.031650 \tValidation Loss: 0.177971\n",
      "Earlystopping Patience Counter: 946\n",
      "Epoch: 1850 \tTraining Loss: 0.031868 \tValidation Loss: 0.174299\n",
      "Earlystopping Patience Counter: 947\n",
      "Epoch: 1851 \tTraining Loss: 0.032134 \tValidation Loss: 0.174397\n",
      "Earlystopping Patience Counter: 948\n",
      "Epoch: 1852 \tTraining Loss: 0.031163 \tValidation Loss: 0.177292\n",
      "Earlystopping Patience Counter: 949\n",
      "Epoch: 1853 \tTraining Loss: 0.031405 \tValidation Loss: 0.175373\n",
      "Earlystopping Patience Counter: 950\n",
      "Epoch: 1854 \tTraining Loss: 0.031426 \tValidation Loss: 0.172962\n",
      "Earlystopping Patience Counter: 951\n",
      "Epoch: 1855 \tTraining Loss: 0.031001 \tValidation Loss: 0.174832\n",
      "Earlystopping Patience Counter: 952\n",
      "Epoch: 1856 \tTraining Loss: 0.031041 \tValidation Loss: 0.172278\n",
      "Earlystopping Patience Counter: 953\n",
      "Epoch: 1857 \tTraining Loss: 0.031290 \tValidation Loss: 0.177378\n",
      "Earlystopping Patience Counter: 954\n",
      "Epoch: 1858 \tTraining Loss: 0.031026 \tValidation Loss: 0.179080\n",
      "Earlystopping Patience Counter: 955\n",
      "Epoch: 1859 \tTraining Loss: 0.031400 \tValidation Loss: 0.179265\n",
      "Earlystopping Patience Counter: 956\n",
      "Epoch: 1860 \tTraining Loss: 0.030846 \tValidation Loss: 0.176764\n",
      "Earlystopping Patience Counter: 957\n",
      "Epoch: 1861 \tTraining Loss: 0.031290 \tValidation Loss: 0.173819\n",
      "Earlystopping Patience Counter: 958\n",
      "Epoch: 1862 \tTraining Loss: 0.030902 \tValidation Loss: 0.172518\n",
      "Earlystopping Patience Counter: 959\n",
      "Epoch: 1863 \tTraining Loss: 0.031466 \tValidation Loss: 0.175895\n",
      "Earlystopping Patience Counter: 960\n",
      "Epoch: 1864 \tTraining Loss: 0.031184 \tValidation Loss: 0.174390\n",
      "Earlystopping Patience Counter: 961\n",
      "Epoch: 1865 \tTraining Loss: 0.030835 \tValidation Loss: 0.174064\n",
      "Earlystopping Patience Counter: 962\n",
      "Epoch: 1866 \tTraining Loss: 0.030889 \tValidation Loss: 0.174591\n",
      "Earlystopping Patience Counter: 963\n",
      "Epoch: 1867 \tTraining Loss: 0.031692 \tValidation Loss: 0.178876\n",
      "Earlystopping Patience Counter: 964\n",
      "Epoch: 1868 \tTraining Loss: 0.031520 \tValidation Loss: 0.171562\n",
      "Earlystopping Patience Counter: 965\n",
      "Epoch: 1869 \tTraining Loss: 0.031254 \tValidation Loss: 0.174063\n",
      "Earlystopping Patience Counter: 966\n",
      "Epoch: 1870 \tTraining Loss: 0.030468 \tValidation Loss: 0.178875\n",
      "Earlystopping Patience Counter: 967\n",
      "Epoch: 1871 \tTraining Loss: 0.031079 \tValidation Loss: 0.179370\n",
      "Earlystopping Patience Counter: 968\n",
      "Epoch: 1872 \tTraining Loss: 0.031192 \tValidation Loss: 0.176491\n",
      "Earlystopping Patience Counter: 969\n",
      "Epoch: 1873 \tTraining Loss: 0.030629 \tValidation Loss: 0.173592\n",
      "Earlystopping Patience Counter: 970\n",
      "Epoch: 1874 \tTraining Loss: 0.032123 \tValidation Loss: 0.172902\n",
      "Earlystopping Patience Counter: 971\n",
      "Epoch: 1875 \tTraining Loss: 0.031048 \tValidation Loss: 0.172157\n",
      "Earlystopping Patience Counter: 972\n",
      "Epoch: 1876 \tTraining Loss: 0.030912 \tValidation Loss: 0.175399\n",
      "Earlystopping Patience Counter: 973\n",
      "Epoch: 1877 \tTraining Loss: 0.030282 \tValidation Loss: 0.176344\n",
      "Earlystopping Patience Counter: 974\n",
      "Epoch: 1878 \tTraining Loss: 0.030402 \tValidation Loss: 0.173379\n",
      "Earlystopping Patience Counter: 975\n",
      "Epoch: 1879 \tTraining Loss: 0.030480 \tValidation Loss: 0.173403\n",
      "Earlystopping Patience Counter: 976\n",
      "Epoch: 1880 \tTraining Loss: 0.031044 \tValidation Loss: 0.177556\n",
      "Earlystopping Patience Counter: 977\n",
      "Epoch: 1881 \tTraining Loss: 0.030801 \tValidation Loss: 0.171950\n",
      "Earlystopping Patience Counter: 978\n",
      "Epoch: 1882 \tTraining Loss: 0.030871 \tValidation Loss: 0.174022\n",
      "Earlystopping Patience Counter: 979\n",
      "Epoch: 1883 \tTraining Loss: 0.030108 \tValidation Loss: 0.173698\n",
      "Earlystopping Patience Counter: 980\n",
      "Epoch: 1884 \tTraining Loss: 0.030533 \tValidation Loss: 0.174989\n",
      "Earlystopping Patience Counter: 981\n",
      "Epoch: 1885 \tTraining Loss: 0.030419 \tValidation Loss: 0.175160\n",
      "Earlystopping Patience Counter: 982\n",
      "Epoch: 1886 \tTraining Loss: 0.030114 \tValidation Loss: 0.173092\n",
      "Earlystopping Patience Counter: 983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1887 \tTraining Loss: 0.030259 \tValidation Loss: 0.176466\n",
      "Earlystopping Patience Counter: 984\n",
      "Epoch: 1888 \tTraining Loss: 0.030246 \tValidation Loss: 0.174322\n",
      "Earlystopping Patience Counter: 985\n",
      "Epoch: 1889 \tTraining Loss: 0.030427 \tValidation Loss: 0.174199\n",
      "Earlystopping Patience Counter: 986\n",
      "Epoch: 1890 \tTraining Loss: 0.030082 \tValidation Loss: 0.181006\n",
      "Earlystopping Patience Counter: 987\n",
      "Epoch: 1891 \tTraining Loss: 0.030394 \tValidation Loss: 0.174922\n",
      "Earlystopping Patience Counter: 988\n",
      "Epoch: 1892 \tTraining Loss: 0.030054 \tValidation Loss: 0.181079\n",
      "Earlystopping Patience Counter: 989\n",
      "Epoch: 1893 \tTraining Loss: 0.030991 \tValidation Loss: 0.176741\n",
      "Earlystopping Patience Counter: 990\n",
      "Epoch: 1894 \tTraining Loss: 0.030132 \tValidation Loss: 0.178621\n",
      "Earlystopping Patience Counter: 991\n",
      "Epoch: 1895 \tTraining Loss: 0.030296 \tValidation Loss: 0.174889\n",
      "Earlystopping Patience Counter: 992\n",
      "Epoch: 1896 \tTraining Loss: 0.030115 \tValidation Loss: 0.174386\n",
      "Earlystopping Patience Counter: 993\n",
      "Epoch: 1897 \tTraining Loss: 0.029804 \tValidation Loss: 0.174526\n",
      "Earlystopping Patience Counter: 994\n",
      "Epoch: 1898 \tTraining Loss: 0.029904 \tValidation Loss: 0.180188\n",
      "Earlystopping Patience Counter: 995\n",
      "Epoch: 1899 \tTraining Loss: 0.030392 \tValidation Loss: 0.172869\n",
      "Earlystopping Patience Counter: 996\n",
      "Epoch: 1900 \tTraining Loss: 0.030104 \tValidation Loss: 0.175825\n",
      "Earlystopping Patience Counter: 997\n",
      "Epoch: 1901 \tTraining Loss: 0.029701 \tValidation Loss: 0.175079\n",
      "Earlystopping Patience Counter: 998\n",
      "Epoch: 1902 \tTraining Loss: 0.030036 \tValidation Loss: 0.176599\n",
      "Earlystopping Patience Counter: 999\n",
      "Epoch: 1903 \tTraining Loss: 0.029647 \tValidation Loss: 0.179344\n",
      "Earlystopping Patience Counter: 1000\n",
      "Epoch: 1904 \tTraining Loss: 0.031261 \tValidation Loss: 0.175811\n",
      "Earlystopping Patience Counter: 1001\n",
      "Epoch: 1905 \tTraining Loss: 0.029902 \tValidation Loss: 0.174553\n",
      "Earlystopping Patience Counter: 1002\n",
      "Epoch: 1906 \tTraining Loss: 0.030050 \tValidation Loss: 0.177709\n",
      "Earlystopping Patience Counter: 1003\n",
      "Epoch: 1907 \tTraining Loss: 0.030053 \tValidation Loss: 0.177297\n",
      "Earlystopping Patience Counter: 1004\n",
      "Epoch: 1908 \tTraining Loss: 0.030111 \tValidation Loss: 0.179196\n",
      "Earlystopping Patience Counter: 1005\n",
      "Epoch: 1909 \tTraining Loss: 0.029979 \tValidation Loss: 0.178399\n",
      "Earlystopping Patience Counter: 1006\n",
      "Epoch: 1910 \tTraining Loss: 0.029383 \tValidation Loss: 0.180618\n",
      "Earlystopping Patience Counter: 1007\n",
      "Epoch: 1911 \tTraining Loss: 0.029692 \tValidation Loss: 0.176065\n",
      "Earlystopping Patience Counter: 1008\n",
      "Epoch: 1912 \tTraining Loss: 0.029668 \tValidation Loss: 0.185512\n",
      "Earlystopping Patience Counter: 1009\n",
      "Epoch: 1913 \tTraining Loss: 0.030103 \tValidation Loss: 0.177097\n",
      "Earlystopping Patience Counter: 1010\n",
      "Epoch: 1914 \tTraining Loss: 0.029267 \tValidation Loss: 0.178874\n",
      "Earlystopping Patience Counter: 1011\n",
      "Epoch: 1915 \tTraining Loss: 0.029651 \tValidation Loss: 0.181177\n",
      "Earlystopping Patience Counter: 1012\n",
      "Epoch: 1916 \tTraining Loss: 0.029582 \tValidation Loss: 0.183292\n",
      "Earlystopping Patience Counter: 1013\n",
      "Epoch: 1917 \tTraining Loss: 0.030448 \tValidation Loss: 0.178729\n",
      "Earlystopping Patience Counter: 1014\n",
      "Epoch: 1918 \tTraining Loss: 0.029551 \tValidation Loss: 0.175952\n",
      "Earlystopping Patience Counter: 1015\n",
      "Epoch: 1919 \tTraining Loss: 0.029511 \tValidation Loss: 0.176191\n",
      "Earlystopping Patience Counter: 1016\n",
      "Epoch: 1920 \tTraining Loss: 0.029361 \tValidation Loss: 0.176481\n",
      "Earlystopping Patience Counter: 1017\n",
      "Epoch: 1921 \tTraining Loss: 0.029271 \tValidation Loss: 0.177571\n",
      "Earlystopping Patience Counter: 1018\n",
      "Epoch: 1922 \tTraining Loss: 0.029489 \tValidation Loss: 0.176254\n",
      "Earlystopping Patience Counter: 1019\n",
      "Epoch: 1923 \tTraining Loss: 0.029726 \tValidation Loss: 0.176472\n",
      "Earlystopping Patience Counter: 1020\n",
      "Epoch: 1924 \tTraining Loss: 0.029407 \tValidation Loss: 0.176226\n",
      "Earlystopping Patience Counter: 1021\n",
      "Epoch: 1925 \tTraining Loss: 0.032054 \tValidation Loss: 0.198879\n",
      "Earlystopping Patience Counter: 1022\n",
      "Epoch: 1926 \tTraining Loss: 0.029988 \tValidation Loss: 0.182992\n",
      "Earlystopping Patience Counter: 1023\n",
      "Epoch: 1927 \tTraining Loss: 0.029547 \tValidation Loss: 0.178820\n",
      "Earlystopping Patience Counter: 1024\n",
      "Epoch: 1928 \tTraining Loss: 0.029231 \tValidation Loss: 0.176603\n",
      "Earlystopping Patience Counter: 1025\n",
      "Epoch: 1929 \tTraining Loss: 0.028981 \tValidation Loss: 0.177206\n",
      "Earlystopping Patience Counter: 1026\n",
      "Epoch: 1930 \tTraining Loss: 0.029130 \tValidation Loss: 0.180706\n",
      "Earlystopping Patience Counter: 1027\n",
      "Epoch: 1931 \tTraining Loss: 0.029143 \tValidation Loss: 0.176787\n",
      "Earlystopping Patience Counter: 1028\n",
      "Epoch: 1932 \tTraining Loss: 0.028939 \tValidation Loss: 0.178427\n",
      "Earlystopping Patience Counter: 1029\n",
      "Epoch: 1933 \tTraining Loss: 0.028881 \tValidation Loss: 0.177697\n",
      "Earlystopping Patience Counter: 1030\n",
      "Epoch: 1934 \tTraining Loss: 0.029111 \tValidation Loss: 0.177416\n",
      "Earlystopping Patience Counter: 1031\n",
      "Epoch: 1935 \tTraining Loss: 0.028922 \tValidation Loss: 0.178538\n",
      "Earlystopping Patience Counter: 1032\n",
      "Epoch: 1936 \tTraining Loss: 0.029124 \tValidation Loss: 0.178834\n",
      "Earlystopping Patience Counter: 1033\n",
      "Epoch: 1937 \tTraining Loss: 0.029053 \tValidation Loss: 0.175748\n",
      "Earlystopping Patience Counter: 1034\n",
      "Epoch: 1938 \tTraining Loss: 0.028949 \tValidation Loss: 0.178018\n",
      "Earlystopping Patience Counter: 1035\n",
      "Epoch: 1939 \tTraining Loss: 0.028934 \tValidation Loss: 0.182777\n",
      "Earlystopping Patience Counter: 1036\n",
      "Epoch: 1940 \tTraining Loss: 0.029446 \tValidation Loss: 0.176570\n",
      "Earlystopping Patience Counter: 1037\n",
      "Epoch: 1941 \tTraining Loss: 0.029737 \tValidation Loss: 0.175773\n",
      "Earlystopping Patience Counter: 1038\n",
      "Epoch: 1942 \tTraining Loss: 0.028334 \tValidation Loss: 0.174604\n",
      "Earlystopping Patience Counter: 1039\n",
      "Epoch: 1943 \tTraining Loss: 0.029115 \tValidation Loss: 0.176394\n",
      "Earlystopping Patience Counter: 1040\n",
      "Epoch: 1944 \tTraining Loss: 0.028948 \tValidation Loss: 0.176345\n",
      "Earlystopping Patience Counter: 1041\n",
      "Epoch: 1945 \tTraining Loss: 0.028993 \tValidation Loss: 0.177470\n",
      "Earlystopping Patience Counter: 1042\n",
      "Epoch: 1946 \tTraining Loss: 0.028884 \tValidation Loss: 0.177704\n",
      "Earlystopping Patience Counter: 1043\n",
      "Epoch: 1947 \tTraining Loss: 0.028698 \tValidation Loss: 0.182095\n",
      "Earlystopping Patience Counter: 1044\n",
      "Epoch: 1948 \tTraining Loss: 0.028897 \tValidation Loss: 0.178535\n",
      "Earlystopping Patience Counter: 1045\n",
      "Epoch: 1949 \tTraining Loss: 0.028856 \tValidation Loss: 0.181472\n",
      "Earlystopping Patience Counter: 1046\n",
      "Epoch: 1950 \tTraining Loss: 0.028926 \tValidation Loss: 0.178268\n",
      "Earlystopping Patience Counter: 1047\n",
      "Epoch: 1951 \tTraining Loss: 0.028485 \tValidation Loss: 0.181070\n",
      "Earlystopping Patience Counter: 1048\n",
      "Epoch: 1952 \tTraining Loss: 0.029380 \tValidation Loss: 0.191029\n",
      "Earlystopping Patience Counter: 1049\n",
      "Epoch: 1953 \tTraining Loss: 0.028881 \tValidation Loss: 0.178378\n",
      "Earlystopping Patience Counter: 1050\n",
      "Epoch: 1954 \tTraining Loss: 0.028658 \tValidation Loss: 0.176648\n",
      "Earlystopping Patience Counter: 1051\n",
      "Epoch: 1955 \tTraining Loss: 0.028922 \tValidation Loss: 0.177323\n",
      "Earlystopping Patience Counter: 1052\n",
      "Epoch: 1956 \tTraining Loss: 0.028429 \tValidation Loss: 0.177318\n",
      "Earlystopping Patience Counter: 1053\n",
      "Epoch: 1957 \tTraining Loss: 0.028304 \tValidation Loss: 0.179865\n",
      "Earlystopping Patience Counter: 1054\n",
      "Epoch: 1958 \tTraining Loss: 0.028300 \tValidation Loss: 0.178117\n",
      "Earlystopping Patience Counter: 1055\n",
      "Epoch: 1959 \tTraining Loss: 0.029382 \tValidation Loss: 0.188546\n",
      "Earlystopping Patience Counter: 1056\n",
      "Epoch: 1960 \tTraining Loss: 0.029089 \tValidation Loss: 0.178487\n",
      "Earlystopping Patience Counter: 1057\n",
      "Epoch: 1961 \tTraining Loss: 0.028685 \tValidation Loss: 0.176942\n",
      "Earlystopping Patience Counter: 1058\n",
      "Epoch: 1962 \tTraining Loss: 0.028110 \tValidation Loss: 0.176712\n",
      "Earlystopping Patience Counter: 1059\n",
      "Epoch: 1963 \tTraining Loss: 0.028654 \tValidation Loss: 0.180067\n",
      "Earlystopping Patience Counter: 1060\n",
      "Epoch: 1964 \tTraining Loss: 0.028334 \tValidation Loss: 0.178251\n",
      "Earlystopping Patience Counter: 1061\n",
      "Epoch: 1965 \tTraining Loss: 0.028616 \tValidation Loss: 0.176459\n",
      "Earlystopping Patience Counter: 1062\n",
      "Epoch: 1966 \tTraining Loss: 0.028327 \tValidation Loss: 0.177516\n",
      "Earlystopping Patience Counter: 1063\n",
      "Epoch: 1967 \tTraining Loss: 0.028654 \tValidation Loss: 0.179930\n",
      "Earlystopping Patience Counter: 1064\n",
      "Epoch: 1968 \tTraining Loss: 0.028164 \tValidation Loss: 0.177819\n",
      "Earlystopping Patience Counter: 1065\n",
      "Epoch: 1969 \tTraining Loss: 0.027878 \tValidation Loss: 0.184583\n",
      "Earlystopping Patience Counter: 1066\n",
      "Epoch: 1970 \tTraining Loss: 0.028212 \tValidation Loss: 0.178629\n",
      "Earlystopping Patience Counter: 1067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1971 \tTraining Loss: 0.028477 \tValidation Loss: 0.179961\n",
      "Earlystopping Patience Counter: 1068\n",
      "Epoch: 1972 \tTraining Loss: 0.028028 \tValidation Loss: 0.176685\n",
      "Earlystopping Patience Counter: 1069\n",
      "Epoch: 1973 \tTraining Loss: 0.028065 \tValidation Loss: 0.178179\n",
      "Earlystopping Patience Counter: 1070\n",
      "Epoch: 1974 \tTraining Loss: 0.028956 \tValidation Loss: 0.185959\n",
      "Earlystopping Patience Counter: 1071\n",
      "Epoch: 1975 \tTraining Loss: 0.027928 \tValidation Loss: 0.176770\n",
      "Earlystopping Patience Counter: 1072\n",
      "Epoch: 1976 \tTraining Loss: 0.031066 \tValidation Loss: 0.176959\n",
      "Earlystopping Patience Counter: 1073\n",
      "Epoch: 1977 \tTraining Loss: 0.030672 \tValidation Loss: 0.185412\n",
      "Earlystopping Patience Counter: 1074\n",
      "Epoch: 1978 \tTraining Loss: 0.028254 \tValidation Loss: 0.178004\n",
      "Earlystopping Patience Counter: 1075\n",
      "Epoch: 1979 \tTraining Loss: 0.027788 \tValidation Loss: 0.177517\n",
      "Earlystopping Patience Counter: 1076\n",
      "Epoch: 1980 \tTraining Loss: 0.027949 \tValidation Loss: 0.180741\n",
      "Earlystopping Patience Counter: 1077\n",
      "Epoch: 1981 \tTraining Loss: 0.028087 \tValidation Loss: 0.178400\n",
      "Earlystopping Patience Counter: 1078\n",
      "Epoch: 1982 \tTraining Loss: 0.028000 \tValidation Loss: 0.178828\n",
      "Earlystopping Patience Counter: 1079\n",
      "Epoch: 1983 \tTraining Loss: 0.028118 \tValidation Loss: 0.181748\n",
      "Earlystopping Patience Counter: 1080\n",
      "Epoch: 1984 \tTraining Loss: 0.027882 \tValidation Loss: 0.183602\n",
      "Earlystopping Patience Counter: 1081\n",
      "Epoch: 1985 \tTraining Loss: 0.027600 \tValidation Loss: 0.181160\n",
      "Earlystopping Patience Counter: 1082\n",
      "Epoch: 1986 \tTraining Loss: 0.027710 \tValidation Loss: 0.179717\n",
      "Earlystopping Patience Counter: 1083\n",
      "Epoch: 1987 \tTraining Loss: 0.028057 \tValidation Loss: 0.178349\n",
      "Earlystopping Patience Counter: 1084\n",
      "Epoch: 1988 \tTraining Loss: 0.030431 \tValidation Loss: 0.178342\n",
      "Earlystopping Patience Counter: 1085\n",
      "Epoch: 1989 \tTraining Loss: 0.028391 \tValidation Loss: 0.180688\n",
      "Earlystopping Patience Counter: 1086\n",
      "Epoch: 1990 \tTraining Loss: 0.027522 \tValidation Loss: 0.183693\n",
      "Earlystopping Patience Counter: 1087\n",
      "Epoch: 1991 \tTraining Loss: 0.027844 \tValidation Loss: 0.181516\n",
      "Earlystopping Patience Counter: 1088\n",
      "Epoch: 1992 \tTraining Loss: 0.028960 \tValidation Loss: 0.178874\n",
      "Earlystopping Patience Counter: 1089\n",
      "Epoch: 1993 \tTraining Loss: 0.027867 \tValidation Loss: 0.181983\n",
      "Earlystopping Patience Counter: 1090\n",
      "Epoch: 1994 \tTraining Loss: 0.027619 \tValidation Loss: 0.181922\n",
      "Earlystopping Patience Counter: 1091\n",
      "Epoch: 1995 \tTraining Loss: 0.027651 \tValidation Loss: 0.181679\n",
      "Earlystopping Patience Counter: 1092\n",
      "Epoch: 1996 \tTraining Loss: 0.027461 \tValidation Loss: 0.183451\n",
      "Earlystopping Patience Counter: 1093\n",
      "Epoch: 1997 \tTraining Loss: 0.027393 \tValidation Loss: 0.178578\n",
      "Earlystopping Patience Counter: 1094\n",
      "Epoch: 1998 \tTraining Loss: 0.027501 \tValidation Loss: 0.181331\n",
      "Earlystopping Patience Counter: 1095\n",
      "Epoch: 1999 \tTraining Loss: 0.027435 \tValidation Loss: 0.181274\n",
      "Earlystopping Patience Counter: 1096\n",
      "Epoch: 2000 \tTraining Loss: 0.027399 \tValidation Loss: 0.180823\n",
      "Earlystopping Patience Counter: 1097\n"
     ]
    }
   ],
   "source": [
    "patience_counter = 0\n",
    "best_value_loss = None\n",
    "for epoch in range(epochnum):\n",
    "    train_loss = 0.0\n",
    "    train_count = 0.0\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    # Eğitim verileri üzerinde eğitim yapmak / Training\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_count += 1\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Doğrulama verileri üzerinde test yapmak / Testing\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target.unsqueeze(1).float())\n",
    "            valid_loss += loss.item()\n",
    "    \n",
    "    model.train()\n",
    "    # Loss değerlerini kaydetmek / Saving the Loss values\n",
    "    train_loss = train_loss / train_count\n",
    "    valid_loss = valid_loss / len(valid_loader)\n",
    "        \n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "        epoch + 1, train_loss, valid_loss))\n",
    "    \n",
    "    val_score = valid_loss\n",
    "    if best_value_loss is None:\n",
    "        best_value_loss = val_score # hafızada patience boyu tutmaya başla\n",
    "        torch.save(model.state_dict(), \"checkpoint.pt\")\n",
    "    elif best_value_loss < val_score: # patience counter\n",
    "        patience_counter = patience_counter + 1\n",
    "        print(\"Earlystopping Patience Counter:\",patience_counter)\n",
    "        #if patience_counter == patience:\n",
    "            #break\n",
    "    else:\n",
    "        best_value_loss = val_score\n",
    "        torch.save(model.state_dict(), \"checkpoint.pt\") # to keep the best model\n",
    "        patience_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41d9b456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(train_loss_list, label=\"Training loss\")\n",
    "plt.plot(valid_loss_list, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfbabb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9508\n",
      "F1 score: 0.9500\n",
      "Precision: 0.9704\n",
      "Recall: 0.9304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "model.load_state_dict(torch.load('checkpoint.pt'))\n",
    "\n",
    "preds = []\n",
    "tlabels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predicted = torch.round(outputs)\n",
    "        preds.extend(predicted.detach().cpu().numpy())\n",
    "        tlabels.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(tlabels, preds)\n",
    "f1 = f1_score(tlabels, preds)\n",
    "precision = precision_score(tlabels, preds)\n",
    "recall = recall_score(tlabels, preds)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 score: {f1:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4193bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 32.02 secs\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Elapsed:\", f'{elapsed:.2f}', \"secs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
